{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Embedding Generation Notebook\n","\n","## Objective\n","This notebook demonstrates how to use custom encoder models to generate embeddings from the MNIST dataset. These models are implemented in `encoder_models.py`, and the training processes are defined in `encoder_training.py`.\n","\n","## Workflow\n","1. **Load and Preprocess Data**:\n","   - Load the MNIST dataset for testing the embedding generation process.\n","   - Normalize and prepare the data.\n","2. **Model Selection and Training**:\n","   - Train selected encoder models from `encoder_models.py`.\n","   - Generate embeddings from the bottleneck layer.\n","3. **Feature Extraction**:\n","   - Generate embeddings using matrix factorization (PCA, SVD, NMF) and SIFT.\n","4. **Save Embeddings**:\n","   - Save all embeddings and trained models for reuse.\n","\n","## Models and Methods\n","### Supported Models\n","The following encoder models are available for training and embedding generation. Each model is implemented in `encoder_models.py`:\n","- **Encoder Models**:\n","  - BasicAutoencoder, IntermediateAutoencoder, AdvancedAutoencoder, EnhancedAutoencoder.\n","  - BasicVAE, VAEWithFCDecoder, ImprovedVAE, FlexibleVAE.\n","- **Feature Extraction**:\n","  - PCA, SVD, NMF.\n","  - SIFT, Kernel PCA.\n","\n","#### **Autoencoders**\n","1. **BasicAutoencoder**:\n","   - A simple autoencoder with:\n","     - **Encoder**: Two convolutional layers followed by max-pooling.\n","     - **Decoder**: Two transposed convolutional layers to reconstruct the input.\n","   - Designed for grayscale datasets like MNIST.\n","   - Suitable for basic dimensionality reduction and reconstruction tasks.\n","\n","2. **IntermediateAutoencoder**:\n","   - A deeper autoencoder with:\n","     - **Batch Normalization** for improved stability.\n","     - Additional feature maps for a more expressive latent space.\n","   - Designed for moderately complex embedding tasks requiring better feature extraction.\n","\n","3. **AdvancedAutoencoder**:\n","   - A sophisticated autoencoder with:\n","     - **Skip Connections** to improve gradient flow and reconstruction accuracy.\n","     - **LeakyReLU Activations** and Batch Normalization for robust performance.\n","   - Suitable for high-dimensional or structured data requiring detailed reconstruction.\n","\n","4. **EnhancedAutoencoder**:\n","   - A deeper autoencoder with:\n","     - Additional convolutional layers in the encoder.\n","     - Transposed convolutional layers in the decoder.\n","     - LeakyReLU activations and Batch Normalization for better embedding representation.\n","   - Designed for datasets requiring intricate reconstructions under noisy conditions.\n","\n","#### **Variational Autoencoders (VAEs)**\n","5. **BasicVAE**:\n","   - A simple VAE with:\n","     - **Encoder**: Two convolutional layers and a fully connected layer to parameterize the latent space.\n","     - **Decoder**: Fully connected and transposed convolution layers to reconstruct input images.\n","   - Suitable for generative tasks with simple latent spaces.\n","\n","6. **VAEWithFCDecoder**:\n","   - A VAE with a fully connected decoder for enhanced latent-to-feature mapping.\n","   - Features:\n","     - **Encoder**: Convolutional layers with Batch Normalization.\n","     - **Decoder**: A combination of fully connected and transposed convolutional layers.\n","\n","7. **ImprovedVAE**:\n","   - An advanced VAE with:\n","     - A bottleneck layer for enhanced feature extraction.\n","     - Transposed convolutions for smooth reconstructions.\n","     - KL divergence loss for latent space regularization.\n","   - Designed for datasets requiring expressive latent representations.\n","\n","8. **FlexibleVAE**:\n","   - A flexible VAE that supports dynamic input shapes and optional projection heads for contrastive learning.\n","   - Suitable for embedding tasks with varying input dimensions.\n","\n","9. **ImprovedFlexibleVAE**:\n","   - Combines convolutional and fully connected layers in the encoder.\n","   - Uses transposed convolutions in the decoder for better reconstruction.\n","   - Optional **Projection Head** for self-supervised contrastive learning tasks.\n","\n","#### **Denoising Autoencoders**\n","10. **DenoisingAutoencoder**:\n","    - A denoising autoencoder with:\n","      - **Encoder**: Convolutional layers for feature extraction.\n","      - **Decoder**: Transposed convolutional layers for reconstruction.\n","      - Optional **Projection Head** for contrastive learning.\n","    - Supports two architectures:\n","      - **Basic**: Simpler structure for standard denoising tasks.\n","      - **Strong**: Deeper architecture for challenging noisy datasets.\n","\n","#### **Feature Extraction and Normalizing Flow Models**\n","11. **Matrix Factorization**:\n","    - Embeddings generated using PCA, SVD, and NMF.\n","    - Useful for dimensionality reduction and compact representations.\n","\n","12. **SIFT (Scale-Invariant Feature Transform)**:\n","    - Extracts scale-invariant features from images.\n","    - Pads feature descriptors to ensure consistent dimensionality.\n","\n","13. **Kernel PCA**:\n","    - Nonlinear dimensionality reduction using Kernel PCA with adjustable kernels.\n","\n","14. **Normalizing Flow Models**:\n","    - Transforms embeddings into a latent space using invertible transformations.\n","    - Useful for embedding refinement and generative tasks.\n","\n","\n","**Training**:\n","   - Each model is trained using the corresponding training loop defined in `encoder_training.py`.\n","   - Training includes support for reconstruction loss, KL divergence (for VAE), and optional noise injection.\n","**Embedding Generation**:\n","   - Once the models are trained, embeddings are generated for the MNIST dataset.\n","   - Encodings from the bottleneck layer are extracted for downstream tasks.\n","**Results Storage**:\n","   - Save trained models to `.pth` files.\n","   - Save generated embeddings to `.pt` files for reuse in downstream applications.\n","\n","## Supported Features\n","- **Flexible Model Selection**:\n","  - Choose specific models to train and generate embeddings for, bypassing others if needed.\n","- **Custom Configuration**:\n","  - Easily modify parameters like the bottleneck size (`code_dim`), number of training epochs, and learning rates.\n","\n","## Outputs\n","- Trained models saved as `.pth` files.\n","- Generated embeddings saved as `.pt` files in a structured directory (`./embeddings`).\n","\n","## Notes\n","This notebook is designed for flexibility and reusability. You can:\n","- Add new encoder models in `encoder_models.py`.\n","- Customize training loops in `encoder_training.py`.\n","- Modify this notebook to train specific models or generate embeddings for specific datasets.\n"],"metadata":{"id":"VUQM0eOdRPMH"}},{"cell_type":"code","source":["import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# Mount Google Drive and set repository path\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Repository path (adjust if needed)\n","repo_path = \"/content/drive/MyDrive/GAN-thesis-project\"\n","\n","# Add repository path to sys.path for module imports\n","if repo_path not in sys.path:\n","    sys.path.append(repo_path)\n","\n","# Change working directory to the repository\n","os.chdir(repo_path)\n","\n","# Verify the working directory\n","print(f\"Current working directory: {os.getcwd()}\")\n","\n","# Configuration\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLvDZtTSZFUb","executionInfo":{"status":"ok","timestamp":1737815451633,"user_tz":-210,"elapsed":9905,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"c66e4ef5-b931-467b-e841-be6caefead97"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Current working directory: /content/drive/MyDrive/GAN-thesis-project\n","Using device: cpu\n"]}]},{"cell_type":"code","source":["import inspect\n","\n","# Import the entire modules\n","import src.data_utils as data_utils\n","import src.cl_loss_function as cl_loss\n","import src.losses as losses\n","import src.embeddings.encoder_models as encoder_models\n","import src.embeddings.encoder_training as encoder_training\n","\n","# Function to list functions and classes in a module\n","def list_functions_and_classes(module):\n","    members = inspect.getmembers(module)\n","    functions = [name for name, obj in members if inspect.isfunction(obj)]\n","    classes = [name for name, obj in members if inspect.isclass(obj)]\n","    return functions, classes\n","\n","# Function to print functions and classes in a readable format\n","def print_functions_and_classes(module_name, module):\n","    functions, classes = list_functions_and_classes(module)\n","    print(f\"Module: {module_name}\")\n","    print(\"  Functions:\")\n","    for func in functions:\n","        print(f\"    - {func}\")\n","    print(\"  Classes:\")\n","    for cls in classes:\n","        print(f\"    - {cls}\")\n","    print()  # Add a blank line for separation\n","\n","# Print functions and classes for each module\n","print_functions_and_classes(\"src.data_utils\", data_utils)\n","print_functions_and_classes(\"src.cl_loss_function\", cl_loss)\n","print_functions_and_classes(\"src.losses\", losses)\n","print_functions_and_classes(\"src.embeddings.encoder_models\", encoder_models)\n","print_functions_and_classes(\"src.embeddings.encoder_training\", encoder_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jah7kWk-SpUb","executionInfo":{"status":"ok","timestamp":1737815468867,"user_tz":-210,"elapsed":3954,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"db9788e3-2919-47c4-f37c-2ac732db2c43"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Module: src.data_utils\n","  Functions:\n","    - analyze_embeddings\n","    - analyze_embeddings_v2\n","    - create_dataloader\n","    - create_embedding_loaders\n","    - kurtosis\n","    - load_data\n","    - load_embeddings\n","    - load_mnist_data\n","    - pdist\n","    - preprocess_images\n","    - save_embeddings\n","    - skew\n","    - split_dataset\n","    - train_test_split\n","    - visualize_embeddings\n","  Classes:\n","    - DataLoader\n","    - LocalOutlierFactor\n","    - TensorDataset\n","\n","Module: src.cl_loss_function\n","  Functions:\n","    - augment\n","    - compute_nt_xent_loss_with_augmentation\n","    - compute_triplet_loss_with_augmentation\n","    - contrastive_loss\n","    - hflip\n","    - info_nce_loss\n","    - resize\n","  Classes:\n","    - ContrastiveHead\n","    - DataLoader\n","    - NTXentLoss\n","    - PCA\n","    - TensorDataset\n","    - TripletLoss\n","    - VicRegLoss\n","\n","Module: src.losses\n","  Functions:\n","    - add_noise\n","    - cyclical_beta_schedule\n","    - linear_beta_schedule\n","    - loss_function_dae_ssim\n","    - vae_loss\n","    - vae_ssim_loss\n","  Classes:\n","\n","Module: src.embeddings.encoder_models\n","  Functions:\n","    - apply_dimensionality_reduction\n","    - apply_sift\n","    - init_weights\n","    - log_prob\n","    - process_feature_extraction\n","    - process_matrix_factorization\n","    - refine_embeddings_NF\n","    - train_nf_model\n","  Classes:\n","    - AdvancedAutoencoder\n","    - BasicAutoencoder\n","    - BasicVAE\n","    - DataLoader\n","    - DenoisingAutoencoder\n","    - EnhancedAutoencoder\n","    - FlexibleVAE\n","    - FlowLayer\n","    - ImprovedFlexibleVAE\n","    - ImprovedVAE\n","    - IntermediateAutoencoder\n","    - KernelPCA\n","    - MinMaxScaler\n","    - NMF\n","    - NormalizingFlowModel\n","    - PCA\n","    - ProjectionHead\n","    - SimCLR\n","    - StandardScaler\n","    - TensorDataset\n","    - TruncatedSVD\n","    - tqdm\n","\n","Module: src.embeddings.encoder_training\n","  Functions:\n","    - add_noise\n","    - ssim\n","    - train_autoencoder\n","    - train_dae\n","    - train_simclr\n","    - train_vae\n","  Classes:\n","    - DataLoader\n","    - EarlyStopping\n","    - MinMaxScaler\n","    - StandardScaler\n","    - TensorDataset\n","    - ToTensor\n","    - tqdm\n","\n"]}]},{"cell_type":"code","source":["# Load and Preprocess MNIST Data\n","fraction = 1  # Fraction of the dataset to use\n","batch_size = 64\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=fraction, batch_size=batch_size, shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 30\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 6))\n","for i in range(n):\n","    ax = plt.subplot(3, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n"],"metadata":{"id":"9ByfVYCjeT7P","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"ok","timestamp":1737815473322,"user_tz":-210,"elapsed":2612,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"bac2553e-3dd9-4a84-c913-0fe46b609569"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampled Dataset: (70000, 1, 28, 28) (70000,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x600 with 30 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# def generate_embeddings(model, data_loader, embedding_type, device=\"cpu\"):\n","#     model.eval()  # Set model to evaluation mode\n","#     embeddings = []\n","#     labels = []\n","\n","#     with torch.no_grad():\n","#         for images, label_batch in data_loader:\n","#             images = images.to(device)\n","#             if embedding_type == \"autoencoder\":\n","#                 encoded, _ = model(images)\n","#             elif embedding_type == \"vae\":\n","#                 mu, _, _ = model(images)\n","#                 encoded = mu  # Use the mean of the latent space\n","#             elif embedding_type == \"dae\":\n","#                 _, _, encoded = model(images)\n","#             else:\n","#                 raise ValueError(f\"Embedding type '{embedding_type}' is not recognized.\")\n","\n","#             embeddings.append(encoded.cpu())\n","#             labels.append(label_batch)\n","\n","#     embeddings = torch.cat(embeddings, dim=0)\n","#     labels = torch.cat(labels, dim=0)\n","\n","#     return embeddings, labels"],"metadata":{"id":"lC_8uAUF7t0r","executionInfo":{"status":"ok","timestamp":1737815473322,"user_tz":-210,"elapsed":3,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# import torch.nn.functional as F\n","\n","# class NTXentLoss(nn.Module):\n","#     def __init__(self, temperature=0.5):\n","#         super(NTXentLoss, self).__init__()\n","#         self.temperature = temperature\n","\n","#     def forward(self, z_i, z_j):\n","#         batch_size = z_i.size(0)\n","\n","#         # Flatten the input tensors if they are not already 2D\n","#         z_i = z_i.view(z_i.size(0), -1)  # Shape: (batch_size, embedding_dim)\n","#         z_j = z_j.view(z_j.size(0), -1)  # Shape: (batch_size, embedding_dim)\n","\n","#         # Normalize the embeddings\n","#         z_i = F.normalize(z_i, dim=1)\n","#         z_j = F.normalize(z_j, dim=1)\n","\n","#         # Concatenate the embeddings\n","#         z = torch.cat([z_i, z_j], dim=0)  # Shape: (2 * batch_size, embedding_dim)\n","\n","#         # Compute the similarity matrix\n","#         similarity_matrix = torch.matmul(z, z.T) / self.temperature  # Shape: (2 * batch_size, 2 * batch_size)\n","\n","#         # Mask for positives and negatives\n","#         mask = ~torch.eye(2 * batch_size, device=z.device).bool()\n","#         positives = torch.cat([\n","#             torch.diag(similarity_matrix, batch_size),  # Positive pairs (z_i, z_j)\n","#             torch.diag(similarity_matrix, -batch_size)  # Positive pairs (z_j, z_i)\n","#         ])\n","#         negatives = similarity_matrix.masked_select(mask).view(2 * batch_size, -1)\n","\n","#         # Compute the NT-Xent loss\n","#         numerator = torch.exp(positives)\n","#         denominator = torch.sum(torch.exp(negatives), dim=-1)\n","#         loss = -torch.mean(torch.log(numerator / denominator))\n","\n","#         return loss\n","\n","# class VicRegLoss(nn.Module):\n","#     def __init__(self, lambda_var=25, mu_mean=25, nu_cov=1):\n","#         super(VicRegLoss, self).__init__()\n","#         self.lambda_var = lambda_var\n","#         self.mu_mean = mu_mean\n","#         self.nu_cov = nu_cov\n","\n","#     def forward(self, z1, z2):\n","#         # Flatten z1 and z2 if they are 4D\n","#         if z1.dim() == 4:\n","#             z1 = z1.view(z1.size(0), -1)  # Shape: (batch_size, 1 * 28 * 28)\n","#         if z2.dim() == 4:\n","#             z2 = z2.view(z2.size(0), -1)  # Shape: (batch_size, 1 * 28 * 28)\n","\n","#         # Variance loss\n","#         variance_loss = torch.mean(torch.relu(1 - torch.std(z1, dim=0))) + \\\n","#                         torch.mean(torch.relu(1 - torch.std(z2, dim=0)))\n","\n","#         # Mean loss\n","#         mean_loss = torch.mean((torch.mean(z1, dim=0) - torch.mean(z2, dim=0))**2)\n","\n","#         # Covariance loss\n","#         z1_centered = z1 - z1.mean(dim=0)\n","#         z2_centered = z2 - z2.mean(dim=0)\n","\n","#         covariance_matrix_z1 = torch.mm(z1_centered.T, z1_centered) / (z1.size(0) - 1)\n","#         covariance_matrix_z2 = torch.mm(z2_centered.T, z2_centered) / (z2.size(0) - 1)\n","\n","#         covariance_loss = torch.sum(covariance_matrix_z1 ** 2) - torch.sum(torch.diag(covariance_matrix_z1) ** 2) + \\\n","#                           torch.sum(covariance_matrix_z2 ** 2) - torch.sum(torch.diag(covariance_matrix_z2) ** 2)\n","\n","#         # Total loss\n","#         total_loss = self.lambda_var * variance_loss + \\\n","#                      self.mu_mean * mean_loss + \\\n","#                      self.nu_cov * covariance_loss\n","#         return total_loss\n","\n","# class TripletLoss(nn.Module):\n","#     def __init__(self, margin=1.0):\n","#         super(TripletLoss, self).__init__()\n","#         self.margin = margin\n","#         self.criterion = nn.TripletMarginWithDistanceLoss(\n","#             distance_function=lambda a, b: 1.0 - F.cosine_similarity(a, b),\n","#             margin=self.margin\n","#         )\n","\n","#     def forward(self, anchor, positive, negative):\n","#         return self.criterion(anchor, positive, negative)\n","\n","# class BarlowTwinsLoss(nn.Module):\n","#     def __init__(self, lambda_param=5e-3):\n","#         super(BarlowTwinsLoss, self).__init__()\n","#         self.lambda_param = lambda_param\n","\n","#     def forward(self, z_a, z_b):\n","#         \"\"\"\n","#         Compute the Barlow Twins loss between two sets of embeddings.\n","\n","#         Args:\n","#             z_a (torch.Tensor): First set of embeddings.\n","#             z_b (torch.Tensor): Second set of embeddings.\n","\n","#         Returns:\n","#             torch.Tensor: Computed Barlow Twins loss.\n","#         \"\"\"\n","#         batch_size = z_a.size(0)\n","#         feature_dim = z_a.size(1)\n","\n","#         # Normalize embeddings\n","#         z_a = (z_a - z_a.mean(dim=0)) / z_a.std(dim=0)\n","#         z_b = (z_b - z_b.mean(dim=0)) / z_b.std(dim=0)\n","\n","#         # Compute cross-correlation matrix\n","#         cross_corr = torch.matmul(z_a.T, z_b) / batch_size\n","\n","#         # Loss terms\n","#         invariance_loss = torch.sum((1 - torch.diag(cross_corr)) ** 2)\n","#         redundancy_loss = torch.sum(torch.triu(cross_corr, diagonal=1) ** 2) + torch.sum(torch.tril(cross_corr, diagonal=-1) ** 2)\n","\n","#         # Total loss\n","#         loss = invariance_loss + self.lambda_param * redundancy_loss\n","#         return loss\n","\n","# class BYOLLoss(nn.Module):\n","#     def __init__(self):\n","#         super(BYOLLoss, self).__init__()\n","\n","#     def forward(self, z_a, z_b, predictor):\n","#         \"\"\"\n","#         Compute the BYOL loss between two sets of embeddings.\n","\n","#         Args:\n","#             z_a (torch.Tensor): First set of embeddings.\n","#             z_b (torch.Tensor): Second set of embeddings.\n","#             predictor (nn.Module): Predictor network.\n","\n","#         Returns:\n","#             torch.Tensor: Computed BYOL loss.\n","#         \"\"\"\n","#         # Normalize embeddings\n","#         z_a = F.normalize(z_a, dim=1)\n","#         z_b = F.normalize(z_b, dim=1)\n","\n","#         # Predict z_b from z_a\n","#         p_a = predictor(z_a)\n","#         p_a = F.normalize(p_a, dim=1)\n","\n","#         # Compute MSE loss between predicted and target embeddings\n","#         loss = 2 - 2 * (p_a * z_b).sum(dim=1).mean()\n","#         return loss\n","\n","# class Predictor(nn.Module):\n","#     def __init__(self, input_dim, hidden_dim=512, output_dim=50):\n","#         super(Predictor, self).__init__()\n","#         self.net = nn.Sequential(\n","#             nn.Linear(input_dim, hidden_dim),\n","#             nn.BatchNorm1d(hidden_dim),\n","#             nn.ReLU(),\n","#             nn.Linear(hidden_dim, output_dim),\n","#         )\n","\n","#     def forward(self, x):\n","#         return self.net(x)"],"metadata":{"id":"Y8LPTX8iKf1j","executionInfo":{"status":"ok","timestamp":1737825225851,"user_tz":-210,"elapsed":580,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["from typing import Callable, Optional\n","\n","def train_autoencoder(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    noise_factor: float = 0.0,\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, InfoNCE)\n","    - Triplet loss\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","\n","    Args:\n","        model (nn.Module): The autoencoder model.\n","        data_loader (DataLoader): DataLoader for training data.\n","        loss_fn (Callable): Primary loss function (e.g., reconstruction loss).\n","        optimizer (optim.Optimizer): Optimizer for the model.\n","        epochs (int): Number of epochs to train.\n","        device (str): Device to train on ('cpu' or 'cuda').\n","        noise_factor (float): Factor for adding noise to input images (denoising autoencoder).\n","        scheduler (Optional[optim.lr_scheduler._LRScheduler]): Learning rate scheduler.\n","        contrastive_loss_fn (Optional[Callable]): Contrastive loss function (e.g., NT-Xent, triplet loss).\n","        temperature (float): Temperature parameter for NT-Xent loss.\n","        triplet_data (bool): Whether the data_loader provides triplets (anchor, positive, negative).\n","        augment_fn (Optional[Callable]): Augmentation function for contrastive learning.\n","        patience (int): Number of epochs with no significant improvement before triggering early stopping.\n","        min_delta (float): Minimum change in loss to qualify as an improvement.\n","\n","    Returns:\n","        None: Prints loss values for each epoch.\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            # Add noise if specified\n","            if noise_factor > 0:\n","                noisy_images = images + noise_factor * torch.randn_like(images)\n","                noisy_images = torch.clamp(noisy_images, 0.0, 1.0)\n","                encoded, decoded = model(noisy_images)\n","            else:\n","                encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Handle different contrastive loss functions\n","                    if isinstance(contrastive_loss_fn, NTXentLoss):\n","                        # NT-Xent loss requires temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)\n","                    elif isinstance(contrastive_loss_fn, VicRegLoss):\n","                        # VicReg loss does not require temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    else:\n","                        # Default behavior for other contrastive losses\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break\n","\n","class EarlyStopping:\n","    \"\"\"\n","    Early stopping to stop training when the loss does not improve after a specified number of epochs (patience).\n","    \"\"\"\n","    def __init__(self, patience=5, min_delta=0):\n","        \"\"\"\n","        Args:\n","            patience (int): Number of epochs to wait for improvement before stopping.\n","            min_delta (float): Minimum change in loss to qualify as an improvement.\n","        \"\"\"\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_loss = float('inf')\n","        self.early_stop = False\n","\n","    def __call__(self, current_loss):\n","        \"\"\"\n","        Check if training should stop.\n","\n","        Args:\n","            current_loss (float): Current epoch's loss.\n","        \"\"\"\n","        if current_loss < self.best_loss - self.min_delta:\n","            self.best_loss = current_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True"],"metadata":{"id":"haU_-HAd8kYw","executionInfo":{"status":"ok","timestamp":1737816788489,"user_tz":-210,"elapsed":315,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def train_autoencoder_v2(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    noise_factor: float = 0.0,\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, VicReg, Triplet)\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","\n","    Args:\n","        model (nn.Module): The autoencoder model.\n","        data_loader (DataLoader): DataLoader for training data.\n","        loss_fn (Callable): Primary loss function (e.g., reconstruction loss).\n","        optimizer (optim.Optimizer): Optimizer for the model.\n","        epochs (int): Number of epochs to train.\n","        device (str): Device to train on ('cpu' or 'cuda').\n","        noise_factor (float): Factor for adding noise to input images (denoising autoencoder).\n","        scheduler (Optional[optim.lr_scheduler._LRScheduler]): Learning rate scheduler.\n","        contrastive_loss_fn (Optional[Callable]): Contrastive loss function (e.g., NT-Xent, VicReg, Triplet).\n","        temperature (float): Temperature parameter for NT-Xent loss.\n","        triplet_data (bool): Whether the data_loader provides triplets (anchor, positive, negative).\n","        augment_fn (Optional[Callable]): Augmentation function for contrastive learning.\n","        patience (int): Number of epochs with no significant improvement before triggering early stopping.\n","        min_delta (float): Minimum change in loss to qualify as an improvement.\n","\n","    Returns:\n","        None: Prints loss values for each epoch.\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            # Add noise if specified\n","            if noise_factor > 0:\n","                noisy_images = images + noise_factor * torch.randn_like(images)\n","                noisy_images = torch.clamp(noisy_images, 0.0, 1.0)\n","                encoded, decoded = model(noisy_images)\n","            else:\n","                encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","\n","                    # Flatten embeddings\n","                    encoded = encoded.view(encoded.size(0), -1)\n","                    positive_encoded = positive_encoded.view(positive_encoded.size(0), -1)\n","                    negative_encoded = negative_encoded.view(negative_encoded.size(0), -1)\n","\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Flatten embeddings\n","                    z1 = z1.view(z1.size(0), -1)\n","                    z2 = z2.view(z2.size(0), -1)\n","\n","                    # Handle different contrastive loss functions\n","                    if isinstance(contrastive_loss_fn, NTXentLoss):\n","                        # NT-Xent loss does not require temperature in forward()\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    elif isinstance(contrastive_loss_fn, VicRegLoss):\n","                        # VicReg loss does not require temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    else:\n","                        # Default behavior for other contrastive losses\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break"],"metadata":{"id":"nLgJBbvQ-7Ox","executionInfo":{"status":"ok","timestamp":1737817328544,"user_tz":-210,"elapsed":308,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def train_autoencoder_v3(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    noise_factor: float = 0.0,\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, VicReg, Triplet)\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","\n","    Args:\n","        model (nn.Module): The autoencoder model.\n","        data_loader (DataLoader): DataLoader for training data.\n","        loss_fn (Callable): Primary loss function (e.g., reconstruction loss).\n","        optimizer (optim.Optimizer): Optimizer for the model.\n","        epochs (int): Number of epochs to train.\n","        device (str): Device to train on ('cpu' or 'cuda').\n","        noise_factor (float): Factor for adding noise to input images (denoising autoencoder).\n","        scheduler (Optional[optim.lr_scheduler._LRScheduler]): Learning rate scheduler.\n","        contrastive_loss_fn (Optional[Callable]): Contrastive loss function (e.g., NT-Xent, VicReg, Triplet).\n","        temperature (float): Temperature parameter for NT-Xent loss.\n","        triplet_data (bool): Whether the data_loader provides triplets (anchor, positive, negative).\n","        augment_fn (Optional[Callable]): Augmentation function for contrastive learning.\n","        patience (int): Number of epochs with no significant improvement before triggering early stopping.\n","        min_delta (float): Minimum change in loss to qualify as an improvement.\n","\n","    Returns:\n","        None: Prints loss values for each epoch.\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            # Add noise if specified\n","            if noise_factor > 0:\n","                noisy_images = images + noise_factor * torch.randn_like(images)\n","                noisy_images = torch.clamp(noisy_images, 0.0, 1.0)\n","                encoded, decoded = model(noisy_images)\n","            else:\n","                encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","\n","                    # Flatten embeddings\n","                    encoded = encoded.view(encoded.size(0), -1)\n","                    positive_encoded = positive_encoded.view(positive_encoded.size(0), -1)\n","                    negative_encoded = negative_encoded.view(negative_encoded.size(0), -1)\n","\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Flatten embeddings\n","                    z1 = z1.view(z1.size(0), -1)\n","                    z2 = z2.view(z2.size(0), -1)\n","\n","                    # # Handle different contrastive loss functions\n","                    # if contrastive_loss_fn.__name__ == \"contrastive_loss\":\n","                    #     # Basic contrastive loss\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)\n","                    # elif contrastive_loss_fn.__name__ == \"info_nce_loss\":\n","                    #     # InfoNCE loss\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)\n","                    if isinstance(contrastive_loss_fn, NTXentLoss):\n","                        # NT-Xent loss does not require temperature in forward()\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    elif isinstance(contrastive_loss_fn, VicRegLoss):\n","                        # VicReg loss does not require temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    else:\n","                        # Default behavior for other contrastive losses\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","                    # # Handle all contrastive losses uniformly\n","                    # if hasattr(contrastive_loss_fn, \"temperature\"):\n","                    #     # Pass temperature to loss functions that require it\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                    # else:\n","                    #     # For loss functions that don't use temperature\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break"],"metadata":{"id":"F3V_6-o4COPK","executionInfo":{"status":"ok","timestamp":1737823800237,"user_tz":-210,"elapsed":320,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["import inspect\n","\n","def train_autoencoder_v4(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    predictor: Optional[nn.Module] = None,  # Add predictor for BYOL\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, VicReg, Triplet, Contrastive, InfoNCE, Barlow Twins, BYOL)\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","\n","                    # Flatten embeddings\n","                    encoded = encoded.view(encoded.size(0), -1)\n","                    positive_encoded = positive_encoded.view(positive_encoded.size(0), -1)\n","                    negative_encoded = negative_encoded.view(negative_encoded.size(0), -1)\n","\n","                    # Compute triplet loss\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, Contrastive, InfoNCE, Barlow Twins, BYOL, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Flatten embeddings\n","                    z1 = z1.view(z1.size(0), -1)\n","                    z2 = z2.view(z2.size(0), -1)\n","\n","                    # Handle all contrastive losses uniformly\n","                    if isinstance(contrastive_loss_fn, BYOLLoss):\n","                        # BYOL requires a predictor\n","                        if predictor is None:\n","                            raise ValueError(\"Predictor network must be provided for BYOL loss.\")\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2, predictor)\n","                    else:\n","                        # # Check if the loss function accepts a `temperature` parameter\n","                        # if \"temperature\" in inspect.signature(contrastive_loss_fn.forward).parameters:\n","                        #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                        # else:\n","                        #     contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                        # Check if the loss function accepts a `temperature` parameter\n","                        if \"temperature\" in inspect.signature(contrastive_loss_fn).parameters:\n","                            contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                        else:\n","                            contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break"],"metadata":{"id":"2i3xXINoYQ0g","executionInfo":{"status":"ok","timestamp":1737826310943,"user_tz":-210,"elapsed":348,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["# ------------------------------\n","# Step 1: Define Configuration\n","# ------------------------------\n","\n","# Configuration\n","config = {\n","    \"model_type\": \"autoencoder\",  # Options: \"autoencoder\", \"vae\", \"dae\"\n","    \"model_name\": \"EnhancedAutoencoder\",  # Options: \"BasicAutoencoder\", \"IntermediateAutoencoder\", \"AdvancedAutoencoder\", \"EnhancedAutoencoder\", \"BasicVAE\", \"ImprovedVAE\", \"FlexibleVAE\", \"ImprovedFlexibleVAE\", \"DenoisingAutoencoder\"\n","    \"code_dim\": 50,  # Dimensionality of the embedding\n","    \"loss_type\": \"ntxent\",  # Options: \"mse\", \"vicreg\", \"ntxent\", \"triplet\"\n","    \"noise_factor\": 0.1,  # Noise factor for denoising autoencoders\n","    \"temperature\": 0.5,  # Temperature parameter for NT-Xent loss\n","    \"margin\": 1.0,  # Margin for Triplet Loss\n","    \"epochs\": 100,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-3,\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"save_best\": True,  # Whether to save the best model\n","    \"save_path\": \"best_model.pth\",  # Path to save the best model\n","    \"beta\": 1.0,  # Weight for KL divergence (VAE only)\n","    \"alpha\": 0.5,  # Weight for contrastive or triplet loss\n","    \"fraction\": 0.01,  # Fraction of the dataset to use\n","    \"projection_dim\": None,  # Optional projection head dimension for VAEs\n","    \"strong_architecture\": False,  # Whether to use a deeper architecture for DenoisingAutoencoder\n","    \"input_shape\": (1, 28, 28),  # Input shape for FlexibleVAE and ImprovedFlexibleVAE\n","    \"patience\": 5,\n","    \"min_delta\": 0.001,\n","    \"triplet_data\": False,\n","}\n","\n","# ------------------------------\n","# Step 2: Load and Preprocess Data\n","# ------------------------------\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=config[\"fraction\"], batch_size=config[\"batch_size\"], shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 20\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n","\n","# ------------------------------\n","# Step 3: Initialize Model, Loss, and Optimizer\n","# ------------------------------\n","\n","# Initialize the model\n","model_classes = {\n","    \"BasicAutoencoder\": encoder_models.BasicAutoencoder,\n","    \"IntermediateAutoencoder\": encoder_models.IntermediateAutoencoder,\n","    \"AdvancedAutoencoder\": encoder_models.AdvancedAutoencoder,\n","    \"EnhancedAutoencoder\": encoder_models.EnhancedAutoencoder,\n","    \"BasicVAE\": encoder_models.BasicVAE,\n","    \"ImprovedVAE\": encoder_models.ImprovedVAE,\n","    \"FlexibleVAE\": encoder_models.FlexibleVAE,\n","    \"ImprovedFlexibleVAE\": encoder_models.ImprovedFlexibleVAE,\n","    \"DenoisingAutoencoder\": encoder_models.DenoisingAutoencoder,\n","}\n","\n","# Initialize model with appropriate arguments\n","if config[\"model_name\"] in [\"FlexibleVAE\", \"ImprovedFlexibleVAE\"]:\n","    model = model_classes[config[\"model_name\"]](\n","        input_shape=config[\"input_shape\"],\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"]\n","    ).to(config[\"device\"])\n","elif config[\"model_name\"] == \"DenoisingAutoencoder\":\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"],\n","        strong_architecture=config[\"strong_architecture\"]\n","    ).to(config[\"device\"])\n","else:\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"]\n","    ).to(config[\"device\"])\n","\n","# Define the loss function\n","if config[\"model_type\"] == \"vae\":\n","    criterion = losses.vae_loss  # Use VAE loss for VAEs\n","else:\n","    loss_functions = {\n","        \"mse\": nn.MSELoss(),  # Reconstruction loss\n","        \"vicreg\": VicRegLoss(lambda_var=25, mu_mean=25, nu_cov=1),  # VicReg loss\n","        \"ntxent\": NTXentLoss(temperature=config[\"temperature\"]),\n","        # cl_loss.NTXentLoss(temperature=config[\"temperature\"]),  # NT-Xent loss\n","        \"triplet\": TripletLoss(margin=config[\"margin\"]),  # Triplet loss\n","    }\n","    criterion = loss_functions[config[\"loss_type\"]]\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Define scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","\n","# ------------------------------\n","# Step 4: Train the Model\n","# ------------------------------\n","\n","if config[\"model_type\"] == \"autoencoder\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    train_autoencoder_v3(\n","        model=model,\n","        data_loader=mnist_loader,\n","        loss_fn=criterion,\n","        optimizer=optimizer,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        # noise_factor=config[\"noise_factor\"],\n","        scheduler=scheduler,\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"triplet\"] else None,\n","        # triplet_data=(config[\"loss_type\"] != \"triplet\"),\n","        augment_fn=cl_loss.augment if config[\"loss_type\"] in [\"vicreg\", \"ntxent\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"vae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_vae(\n","        vae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        beta=config[\"beta\"],\n","        alpha=config[\"alpha\"],\n","        temperature=config[\"temperature\"],\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"dae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_dae(\n","        dae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        noise_factor=config[\"noise_factor\"],\n","        alpha=config[\"alpha\"],\n","        temperature=config[\"temperature\"],\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\"] else None,\n","        triplet_loss_fn=criterion if config[\"loss_type\"] == \"triplet\" else None,\n","        ssim_func=losses.ssim if config[\"loss_type\"] == \"ssim\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","# ------------------------------\n","# Step 5: Save Embeddings and Model\n","# ------------------------------\n","\n","# Generate embeddings\n","embeddings, labels = data_utils.generate_embeddings(\n","    model=model,\n","    embedding_type=config[\"model_type\"],\n","    data_loader=mnist_loader,\n","    device=config[\"device\"],\n",")\n","\n","# Define the base storage directory for embeddings\n","base_dir = \"./saved_embeddings\"\n","os.makedirs(base_dir, exist_ok=True)\n","\n","# Ensure a dedicated directory for embeddings\n","embeddings_dir = os.path.join(base_dir, \"embeddings\")\n","os.makedirs(embeddings_dir, exist_ok=True)\n","\n","# Create a unique subdirectory for this embedding type, model, and loss type\n","embedding_subdir = f\"{config['model_type']}_{config['model_name']}_{config['loss_type']}\"\n","embedding_dir = os.path.join(embeddings_dir, embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","# Choose saving format: default is .pt, but .npy can be chosen\n","save_format = \"pt\"  # Change to \"npy\" for NumPy format\n","\n","# Save embeddings with differentiated names based on the model, loss type, and embedding type\n","if save_format == \"pt\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.pt\")\n","    torch.save({\"embeddings\": embeddings, \"labels\": labels}, embedding_file)\n","    print(f\"Embeddings saved in PyTorch format: {embedding_file}\")\n","elif save_format == \"npy\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.npy\")\n","    np.save(embedding_file, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    print(f\"Embeddings saved in NumPy format: {embedding_file}\")\n","else:\n","    raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# Save the model\n","model_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}.pth\")\n","torch.save(model.state_dict(), model_file)\n","print(f\"Model saved: {model_file}\")\n","\n","# ------------------------------\n","# Step 6: Visualize Embeddings\n","# ------------------------------\n","\n","# Visualize embeddings\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":667},"id":"zAKUO7472Gn7","executionInfo":{"status":"error","timestamp":1737824748106,"user_tz":-210,"elapsed":8913,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"4a7676f4-a6d8-4d6d-ed75-13acebe37876"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampled Dataset: (700, 1, 28, 28) (700,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x400 with 20 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training EnhancedAutoencoder with ntxent loss...\n","Epoch [1/100], Train Loss: 8.9189\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-100-56da34e65d77>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"autoencoder\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training {config['model_name']} with {config['loss_type']} loss...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     train_autoencoder_v3(\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-e2c0e6269fd5>\u001b[0m in \u001b[0;36mtrain_autoencoder_v3\u001b[0;34m(model, data_loader, loss_fn, optimizer, epochs, device, noise_factor, scheduler, contrastive_loss_fn, temperature, triplet_data, augment_fn, patience, min_delta)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtotal_loss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# ------------------------------\n","# Step 1: Define Configuration\n","# ------------------------------\n","\n","# Configuration\n","config = {\n","    \"model_type\": \"autoencoder\",  # Options: \"autoencoder\", \"vae\", \"dae\"\n","    \"model_name\": \"EnhancedAutoencoder\",  # Options: \"BasicAutoencoder\", \"IntermediateAutoencoder\", \"AdvancedAutoencoder\", \"EnhancedAutoencoder\", \"BasicVAE\", \"ImprovedVAE\", \"FlexibleVAE\", \"ImprovedFlexibleVAE\", \"DenoisingAutoencoder\"\n","    \"code_dim\": 50,  # Dimensionality of the embedding\n","    \"loss_type\": \"ntxent\",  # Options: \"mse\", \"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"\n","    \"noise_factor\": 0.1,  # Noise factor for denoising autoencoders\n","    \"temperature\": 0.5,  # Temperature parameter for NT-Xent loss\n","    \"margin\": 1.0,  # Margin for Triplet Loss\n","    \"epochs\": 100,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-3,\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"save_best\": True,  # Whether to save the best model\n","    \"save_path\": \"best_model.pth\",  # Path to save the best model\n","    \"beta\": 1.0,  # Weight for KL divergence (VAE only)\n","    \"alpha\": 0.5,  # Weight for contrastive or triplet loss\n","    \"fraction\": 0.01,  # Fraction of the dataset to use\n","    \"projection_dim\": None,  # Optional projection head dimension for VAEs\n","    \"strong_architecture\": False,  # Whether to use a deeper architecture for DenoisingAutoencoder\n","    \"input_shape\": (1, 28, 28),  # Input shape for FlexibleVAE and ImprovedFlexibleVAE\n","    \"patience\": 5,\n","    \"min_delta\": 0.001,\n","    \"triplet_data\": False,\n","}\n","\n","# ------------------------------\n","# Step 2: Load and Preprocess Data\n","# ------------------------------\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=config[\"fraction\"], batch_size=config[\"batch_size\"], shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 20\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n","\n","# ------------------------------\n","# Step 3: Initialize Model, Loss, and Optimizer\n","# ------------------------------\n","\n","# Initialize the model\n","# Initialize the model\n","model_classes = {\n","    \"BasicAutoencoder\": encoder_models.BasicAutoencoder,\n","    \"IntermediateAutoencoder\": encoder_models.IntermediateAutoencoder,\n","    \"AdvancedAutoencoder\": encoder_models.AdvancedAutoencoder,\n","    \"EnhancedAutoencoder\": encoder_models.EnhancedAutoencoder,\n","    \"BasicVAE\": encoder_models.BasicVAE,\n","    \"ImprovedVAE\": encoder_models.ImprovedVAE,\n","    \"FlexibleVAE\": encoder_models.FlexibleVAE,\n","    \"ImprovedFlexibleVAE\": encoder_models.ImprovedFlexibleVAE,\n","    \"DenoisingAutoencoder\": encoder_models.DenoisingAutoencoder,\n","}\n","\n","# Initialize model with appropriate arguments\n","if config[\"model_name\"] in [\"FlexibleVAE\", \"ImprovedFlexibleVAE\"]:\n","    model = model_classes[config[\"model_name\"]](\n","        input_shape=config[\"input_shape\"],\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"]\n","    ).to(config[\"device\"])\n","elif config[\"model_name\"] == \"DenoisingAutoencoder\":\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"],\n","        strong_architecture=config[\"strong_architecture\"]\n","    ).to(config[\"device\"])\n","else:\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"]\n","    ).to(config[\"device\"])\n","\n","# Define the loss function\n","if config[\"model_type\"] == \"vae\":\n","    criterion = losses.vae_loss  # Use VAE loss for VAEs\n","else:\n","    loss_functions = {\n","        \"mse\": nn.MSELoss(),  # Reconstruction loss\n","        \"vicreg\": VicRegLoss(lambda_var=25, mu_mean=25, nu_cov=1),  # VicReg loss\n","        \"ntxent\": NTXentLoss(temperature=config[\"temperature\"]),  # NT-Xent loss\n","        \"triplet\": TripletLoss(margin=config[\"margin\"]),  # Triplet loss\n","        \"contrastive\": cl_loss.contrastive_loss,  # Basic contrastive loss\n","        \"info_nce\": cl_loss.info_nce_loss,  # InfoNCE loss\n","        \"barlow_twins\": BarlowTwinsLoss(lambda_param=5e-3),  # Barlow Twins loss\n","        \"byol\": BYOLLoss(),  # BYOL loss\n","    }\n","    criterion = loss_functions[config[\"loss_type\"]]\n","\n","predictor = Predictor(input_dim=config[\"code_dim\"]).to(config[\"device\"])\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Define scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","\n","# ------------------------------\n","# Step 4: Train the Model\n","# ------------------------------\n","\n","if config[\"model_type\"] == \"autoencoder\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    train_autoencoder_v4(\n","        model=model,\n","        data_loader=mnist_loader,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        optimizer=optimizer,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        scheduler=scheduler,\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        temperature=config[\"temperature\"],  # Pass temperature for NT-Xent, contrastive, and InfoNCE\n","        triplet_data=(config[\"loss_type\"] == \"triplet\"),  # Enable triplet data only for triplet loss\n","        augment_fn=cl_loss.augment if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        predictor=predictor if config[\"loss_type\"] == \"byol\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"vae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_vae(\n","        vae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,  # VAE loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        beta=config[\"beta\"],  # Weight for KL divergence\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"dae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_dae(\n","        dae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        noise_factor=config[\"noise_factor\"],  # Noise factor for denoising\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        triplet_loss_fn=criterion if config[\"loss_type\"] == \"triplet\" else None,\n","        ssim_func=losses.ssim if config[\"loss_type\"] == \"ssim\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","# ------------------------------\n","# Step 5: Save Embeddings and Model\n","# ------------------------------\n","\n","# Generate embeddings\n","embeddings, labels = generate_embeddings(\n","    model=model,\n","    embedding_type=config[\"model_type\"],\n","    data_loader=mnist_loader,\n","    device=config[\"device\"],\n",")\n","\n","# Define the base storage directory for embeddings\n","base_dir = \"./saved_embeddings\"\n","os.makedirs(base_dir, exist_ok=True)\n","\n","# Ensure a dedicated directory for embeddings\n","embeddings_dir = os.path.join(base_dir, \"embeddings\")\n","os.makedirs(embeddings_dir, exist_ok=True)\n","\n","# Create a unique subdirectory for this embedding type, model, and loss type\n","embedding_subdir = f\"{config['model_type']}_{config['model_name']}_{config['loss_type']}\"\n","embedding_dir = os.path.join(embeddings_dir, embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","# Choose saving format: default is .pt, but .npy can be chosen\n","save_format = \"pt\"  # Change to \"npy\" for NumPy format\n","\n","# Save embeddings with differentiated names based on the model, loss type, and embedding type\n","if save_format == \"pt\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.pt\")\n","    torch.save({\"embeddings\": embeddings, \"labels\": labels}, embedding_file)\n","    print(f\"Embeddings saved in PyTorch format: {embedding_file}\")\n","elif save_format == \"npy\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.npy\")\n","    np.save(embedding_file, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    print(f\"Embeddings saved in NumPy format: {embedding_file}\")\n","else:\n","    raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# Save the model\n","model_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}.pth\")\n","torch.save(model.state_dict(), model_file)\n","print(f\"Model saved: {model_file}\")\n","\n","# ------------------------------\n","# Step 6: Visualize Embeddings\n","# ------------------------------\n","\n","# Visualize embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":667},"id":"X4tX6ui8MaS5","executionInfo":{"status":"error","timestamp":1737826417990,"user_tz":-210,"elapsed":10354,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"174e65c8-17a9-4008-8b3b-76f22454d076"},"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampled Dataset: (700, 1, 28, 28) (700,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x400 with 20 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training EnhancedAutoencoder with ntxent loss...\n","Epoch [1/100], Train Loss: 4.5143\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-129-97a87eb4a786>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"autoencoder\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training {config['model_name']} with {config['loss_type']} loss...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     train_autoencoder_v4(\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-122-bda69c1efa0b>\u001b[0m in \u001b[0;36mtrain_autoencoder_v4\u001b[0;34m(model, data_loader, loss_fn, optimizer, epochs, device, scheduler, contrastive_loss_fn, temperature, triplet_data, augment_fn, predictor, patience, min_delta)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mtotal_loss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from src.embeddings.encoder_models import (\n","    process_matrix_factorization,\n","    apply_sift,\n","    process_feature_extraction,\n","    NormalizingFlowModel,\n","    train_nf_model,\n",")\n","\n","# ------------------------------\n","# Configuration Dictionary\n","# ------------------------------\n","\n","config = {\n","    # Save format and paths\n","    \"save_format\": \"pt\",  # Options: \"pt\" (PyTorch) or \"npy\" (NumPy)\n","    \"base_dir\": \"./saved_embeddings\",\n","    \"embeddings_dir\": \"./saved_embeddings/embeddings\",\n","\n","    # Model and loss naming\n","    \"model_name\": \"matrix_factorization\",\n","    \"loss_type\": \"default_loss\",\n","\n","    # Data settings\n","    \"n_components\": 50,  # Number of components for dimensionality reduction\n","    \"n_features\": 50,  # Number of features for SIFT\n","    \"kernel\": \"rbf\",  # Kernel for Kernel PCA\n","\n","    # Normalizing Flow settings\n","    \"num_flows\": 4,\n","    \"num_epochs\": 100,\n","    \"learning_rate\": 1e-3,\n","    \"batch_size\": 128,\n","\n","    # Device (CPU/GPU)\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","}\n","\n","# Ensure valid save format\n","if config[\"save_format\"] not in [\"pt\", \"npy\"]:\n","    print(f\"Invalid save format: {config['save_format']}. Defaulting to 'pt'.\")\n","    config[\"save_format\"] = \"pt\"\n","\n","# Create directories if they don't exist\n","os.makedirs(config[\"base_dir\"], exist_ok=True)\n","os.makedirs(config[\"embeddings_dir\"], exist_ok=True)\n","\n","# ------------------------------\n","# Helper Function to Save Embeddings\n","# ------------------------------\n","\n","def save_embeddings(embeddings, labels, file_path, save_format):\n","    \"\"\"Save embeddings and labels in the specified format.\"\"\"\n","    if save_format == \"pt\":\n","        torch.save({\"embeddings\": embeddings, \"labels\": labels}, file_path)\n","    elif save_format == \"npy\":\n","        np.save(file_path, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    else:\n","        raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# ------------------------------\n","# Step 1: Load Data\n","# ------------------------------\n","\n","# Extract flattened images and labels\n","sampled_x, sampled_y = mnist_loader.dataset.tensors[0].numpy(), mnist_loader.dataset.tensors[1].numpy()\n","\n","# ------------------------------\n","# Step 2: Matrix Factorization\n","# ------------------------------\n","\n","print(\"Processing matrix factorization models (PCA, SVD, NMF)...\")\n","factorized_embeddings, factorized_labels = process_matrix_factorization(\n","    sampled_x, sampled_y, n_components=config[\"n_components\"]\n",")\n","\n","for method, embeddings in factorized_embeddings.items():\n","    embedding_subdir = f\"matrix_factorization_{method}\"\n","    embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","    os.makedirs(embedding_dir, exist_ok=True)\n","\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_{method}_embeddings.{config['save_format']}\")\n","    save_embeddings(embeddings, factorized_labels, embedding_file, config[\"save_format\"])\n","    print(f\"{method} embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 3: SIFT Features\n","# ------------------------------\n","\n","print(\"Processing SIFT features...\")\n","sift_features = apply_sift(sampled_x, n_features=config[\"n_features\"])\n","sift_labels = torch.tensor(sampled_y, dtype=torch.long)\n","\n","embedding_subdir = \"sift_features\"\n","embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_sift_embeddings.{config['save_format']}\")\n","save_embeddings(sift_features, sift_labels, embedding_file, config[\"save_format\"])\n","print(f\"SIFT embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 4: Kernel PCA\n","# ------------------------------\n","\n","print(\"Processing Kernel PCA...\")\n","kernel_pca_features, kernel_pca_labels = process_feature_extraction(\n","    sampled_x, sampled_y, n_features=config[\"n_features\"], kernel=config[\"kernel\"], n_components=config[\"n_components\"]\n",")\n","\n","for method, embeddings in kernel_pca_features.items():\n","    embedding_subdir = f\"kernel_pca_{method}\"\n","    embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","    os.makedirs(embedding_dir, exist_ok=True)\n","\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_kernel_pca_{method}_embeddings.{config['save_format']}\")\n","    save_embeddings(embeddings, kernel_pca_labels, embedding_file, config[\"save_format\"])\n","    print(f\"{method} Kernel PCA embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 5: Normalizing Flow\n","# ------------------------------\n","\n","print(\"Processing Normalizing Flow...\")\n","for method, embeddings in factorized_embeddings.items():\n","    # Initialize and train Normalizing Flow model\n","    input_dim = embeddings.size(1)\n","    nf_model = NormalizingFlowModel(input_dim=input_dim, num_flows=config[\"num_flows\"]).to(config[\"device\"])\n","    trained_nf_model = train_nf_model(\n","        nf_model, embeddings, num_epochs=config[\"num_epochs\"], lr=config[\"learning_rate\"], batch_size=config[\"batch_size\"]\n","    )\n","\n","    # Refine embeddings\n","    with torch.no_grad():\n","        refined_embeddings, _ = trained_nf_model(embeddings)\n","\n","        embedding_subdir = f\"normalizing_flow_{method}\"\n","        embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","        os.makedirs(embedding_dir, exist_ok=True)\n","\n","        embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_normalizing_flow_{method}_refined_embeddings.{config['save_format']}\")\n","        save_embeddings(refined_embeddings, factorized_labels, embedding_file, config[\"save_format\"])\n","        print(f\"{method} refined embeddings (Normalizing Flow) saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","print(\"Feature extraction and normalizing flow processing complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvEe15hwu6wG","outputId":"8d813de4-a583-4242-f469-205fc33229f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing matrix factorization models (PCA, SVD, NMF)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1742: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["PCA embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_PCA/matrix_factorization_default_loss_PCA_embeddings.pt\n","SVD embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_SVD/matrix_factorization_default_loss_SVD_embeddings.pt\n","NMF embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_NMF/matrix_factorization_default_loss_NMF_embeddings.pt\n","Processing SIFT features...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mf82IvkVxtrP"},"execution_count":null,"outputs":[]}]}