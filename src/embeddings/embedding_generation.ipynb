{"cells":[{"cell_type":"markdown","metadata":{"id":"VUQM0eOdRPMH"},"source":["# Embedding Generation Notebook\n","\n","## Objective\n","This notebook demonstrates how to use custom encoder models to generate embeddings from the MNIST dataset. These models are implemented in `encoder_models.py`, and the training processes are defined in `encoder_training.py`.\n","\n","## Workflow\n","1. **Load and Preprocess Data**:\n","   - Load the MNIST dataset for testing the embedding generation process.\n","   - Normalize and prepare the data.\n","2. **Model Selection and Training**:\n","   - Train selected encoder models from `encoder_models.py`.\n","   - Generate embeddings from the bottleneck layer.\n","3. **Feature Extraction**:\n","   - Generate embeddings using matrix factorization (PCA, SVD, NMF) and SIFT.\n","4. **Save Embeddings**:\n","   - Save all embeddings and trained models for reuse.\n","\n","## Models and Methods\n","### Supported Models\n","The following encoder models are available for training and embedding generation. Each model is implemented in `encoder_models.py`:\n","- **Encoder Models**:\n","  - BasicAutoencoder, IntermediateAutoencoder, AdvancedAutoencoder, EnhancedAutoencoder.\n","  - BasicVAE, VAEWithFCDecoder, ImprovedVAE, FlexibleVAE.\n","- **Feature Extraction**:\n","  - PCA, SVD, NMF.\n","  - SIFT, Kernel PCA.\n","\n","#### **Autoencoders**\n","1. **BasicAutoencoder**:\n","   - A simple autoencoder with:\n","     - **Encoder**: Two convolutional layers followed by max-pooling.\n","     - **Decoder**: Two transposed convolutional layers to reconstruct the input.\n","   - Designed for grayscale datasets like MNIST.\n","   - Suitable for basic dimensionality reduction and reconstruction tasks.\n","\n","2. **IntermediateAutoencoder**:\n","   - A deeper autoencoder with:\n","     - **Batch Normalization** for improved stability.\n","     - Additional feature maps for a more expressive latent space.\n","   - Designed for moderately complex embedding tasks requiring better feature extraction.\n","\n","3. **AdvancedAutoencoder**:\n","   - A sophisticated autoencoder with:\n","     - **Skip Connections** to improve gradient flow and reconstruction accuracy.\n","     - **LeakyReLU Activations** and Batch Normalization for robust performance.\n","   - Suitable for high-dimensional or structured data requiring detailed reconstruction.\n","\n","4. **EnhancedAutoencoder**:\n","   - A deeper autoencoder with:\n","     - Additional convolutional layers in the encoder.\n","     - Transposed convolutional layers in the decoder.\n","     - LeakyReLU activations and Batch Normalization for better embedding representation.\n","   - Designed for datasets requiring intricate reconstructions under noisy conditions.\n","\n","#### **Variational Autoencoders (VAEs)**\n","5. **BasicVAE**:\n","   - A simple VAE with:\n","     - **Encoder**: Two convolutional layers and a fully connected layer to parameterize the latent space.\n","     - **Decoder**: Fully connected and transposed convolution layers to reconstruct input images.\n","   - Suitable for generative tasks with simple latent spaces.\n","\n","6. **VAEWithFCDecoder**:\n","   - A VAE with a fully connected decoder for enhanced latent-to-feature mapping.\n","   - Features:\n","     - **Encoder**: Convolutional layers with Batch Normalization.\n","     - **Decoder**: A combination of fully connected and transposed convolutional layers.\n","\n","7. **ImprovedVAE**:\n","   - An advanced VAE with:\n","     - A bottleneck layer for enhanced feature extraction.\n","     - Transposed convolutions for smooth reconstructions.\n","     - KL divergence loss for latent space regularization.\n","   - Designed for datasets requiring expressive latent representations.\n","\n","8. **FlexibleVAE**:\n","   - A flexible VAE that supports dynamic input shapes and optional projection heads for contrastive learning.\n","   - Suitable for embedding tasks with varying input dimensions.\n","\n","9. **ImprovedFlexibleVAE**:\n","   - Combines convolutional and fully connected layers in the encoder.\n","   - Uses transposed convolutions in the decoder for better reconstruction.\n","   - Optional **Projection Head** for self-supervised contrastive learning tasks.\n","\n","#### **Denoising Autoencoders**\n","10. **DenoisingAutoencoder**:\n","    - A denoising autoencoder with:\n","      - **Encoder**: Convolutional layers for feature extraction.\n","      - **Decoder**: Transposed convolutional layers for reconstruction.\n","      - Optional **Projection Head** for contrastive learning.\n","    - Supports two architectures:\n","      - **Basic**: Simpler structure for standard denoising tasks.\n","      - **Strong**: Deeper architecture for challenging noisy datasets.\n","\n","#### **Feature Extraction and Normalizing Flow Models**\n","11. **Matrix Factorization**:\n","    - Embeddings generated using PCA, SVD, and NMF.\n","    - Useful for dimensionality reduction and compact representations.\n","\n","12. **SIFT (Scale-Invariant Feature Transform)**:\n","    - Extracts scale-invariant features from images.\n","    - Pads feature descriptors to ensure consistent dimensionality.\n","\n","13. **Kernel PCA**:\n","    - Nonlinear dimensionality reduction using Kernel PCA with adjustable kernels.\n","\n","14. **Normalizing Flow Models**:\n","    - Transforms embeddings into a latent space using invertible transformations.\n","    - Useful for embedding refinement and generative tasks.\n","\n","\n","**Training**:\n","   - Each model is trained using the corresponding training loop defined in `encoder_training.py`.\n","   - Training includes support for reconstruction loss, KL divergence (for VAE), and optional noise injection.\n","**Embedding Generation**:\n","   - Once the models are trained, embeddings are generated for the MNIST dataset.\n","   - Encodings from the bottleneck layer are extracted for downstream tasks.\n","**Results Storage**:\n","   - Save trained models to `.pth` files.\n","   - Save generated embeddings to `.pt` files for reuse in downstream applications.\n","\n","## Supported Features\n","- **Flexible Model Selection**:\n","  - Choose specific models to train and generate embeddings for, bypassing others if needed.\n","- **Custom Configuration**:\n","  - Easily modify parameters like the bottleneck size (`code_dim`), number of training epochs, and learning rates.\n","\n","## Outputs\n","- Trained models saved as `.pth` files.\n","- Generated embeddings saved as `.pt` files in a structured directory (`./embeddings`).\n","\n","## Notes\n","This notebook is designed for flexibility and reusability. You can:\n","- Add new encoder models in `encoder_models.py`.\n","- Customize training loops in `encoder_training.py`.\n","- Modify this notebook to train specific models or generate embeddings for specific datasets.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8597,"status":"ok","timestamp":1737906924120,"user":{"displayName":"Farshad H","userId":"17155898055621377416"},"user_tz":-210},"id":"XLvDZtTSZFUb","outputId":"79ec8cdf-bd2c-46bf-fc3f-39932be7d2dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Current working directory: /content/drive/MyDrive/GAN-thesis-project\n","Using device: cuda\n"]}],"source":["import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# Mount Google Drive and set repository path\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Repository path (adjust if needed)\n","repo_path = \"/content/drive/MyDrive/GAN-thesis-project\"\n","\n","# Add repository path to sys.path for module imports\n","if repo_path not in sys.path:\n","    sys.path.append(repo_path)\n","\n","# Change working directory to the repository\n","os.chdir(repo_path)\n","\n","# Verify the working directory\n","print(f\"Current working directory: {os.getcwd()}\")\n","\n","# Configuration\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3619,"status":"ok","timestamp":1737906927714,"user":{"displayName":"Farshad H","userId":"17155898055621377416"},"user_tz":-210},"id":"Jah7kWk-SpUb","outputId":"4aa13e81-6909-4df7-aa85-fd88dbe16e2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Module: src.data_utils\n","  Functions:\n","    - analyze_embeddings\n","    - analyze_embeddings_v2\n","    - create_dataloader\n","    - create_embedding_loaders\n","    - generate_embeddings\n","    - kurtosis\n","    - load_data\n","    - load_embeddings\n","    - load_mnist_data\n","    - pdist\n","    - preprocess_images\n","    - save_embeddings\n","    - skew\n","    - split_dataset\n","    - train_test_split\n","    - visualize_embeddings\n","  Classes:\n","    - DataLoader\n","    - LocalOutlierFactor\n","    - TensorDataset\n","\n","Module: src.cl_loss_function\n","  Functions:\n","    - augment\n","    - compute_nt_xent_loss_with_augmentation\n","    - compute_triplet_loss_with_augmentation\n","    - contrastive_loss\n","    - hflip\n","    - info_nce_loss\n","    - resize\n","  Classes:\n","    - BYOLLoss\n","    - BarlowTwinsLoss\n","    - ContrastiveHead\n","    - DataLoader\n","    - NTXentLoss\n","    - PCA\n","    - Predictor\n","    - TensorDataset\n","    - TripletLoss\n","    - VicRegLoss\n","\n","Module: src.losses\n","  Functions:\n","    - add_noise\n","    - cyclical_beta_schedule\n","    - linear_beta_schedule\n","    - loss_function_dae_ssim\n","    - vae_loss\n","    - vae_ssim_loss\n","  Classes:\n","\n","Module: src.embeddings.encoder_models\n","  Functions:\n","    - apply_dimensionality_reduction\n","    - apply_sift\n","    - init_weights\n","    - log_prob\n","    - process_feature_extraction\n","    - process_matrix_factorization\n","    - refine_embeddings_NF\n","    - train_nf_model\n","  Classes:\n","    - AdvancedAutoencoder\n","    - BasicAutoencoder\n","    - BasicVAE\n","    - DataLoader\n","    - DenoisingAutoencoder\n","    - EnhancedAutoencoder\n","    - FlexibleVAE\n","    - FlowLayer\n","    - ImprovedFlexibleVAE\n","    - ImprovedVAE\n","    - IntermediateAutoencoder\n","    - KernelPCA\n","    - MinMaxScaler\n","    - NMF\n","    - NormalizingFlowModel\n","    - PCA\n","    - ProjectionHead\n","    - SimCLR\n","    - StandardScaler\n","    - TensorDataset\n","    - TruncatedSVD\n","    - tqdm\n","\n","Module: src.embeddings.encoder_training\n","  Functions:\n","    - add_noise\n","    - ssim\n","    - train_autoencoder\n","    - train_autoencoder_v4\n","    - train_dae\n","    - train_simclr\n","    - train_vae\n","  Classes:\n","    - BYOLLoss\n","    - DataLoader\n","    - EarlyStopping\n","    - MinMaxScaler\n","    - Predictor\n","    - StandardScaler\n","    - TensorDataset\n","    - ToTensor\n","    - tqdm\n","\n"]}],"source":["import inspect\n","\n","# Import the entire modules\n","import src.data_utils as data_utils\n","import src.cl_loss_function as cl_loss\n","import src.losses as losses\n","import src.embeddings.encoder_models as encoder_models\n","import src.embeddings.encoder_training as encoder_training\n","\n","# Function to list functions and classes in a module\n","def list_functions_and_classes(module):\n","    members = inspect.getmembers(module)\n","    functions = [name for name, obj in members if inspect.isfunction(obj)]\n","    classes = [name for name, obj in members if inspect.isclass(obj)]\n","    return functions, classes\n","\n","# Function to print functions and classes in a readable format\n","def print_functions_and_classes(module_name, module):\n","    functions, classes = list_functions_and_classes(module)\n","    print(f\"Module: {module_name}\")\n","    print(\"  Functions:\")\n","    for func in functions:\n","        print(f\"    - {func}\")\n","    print(\"  Classes:\")\n","    for cls in classes:\n","        print(f\"    - {cls}\")\n","    print()  # Add a blank line for separation\n","\n","# Print functions and classes for each module\n","print_functions_and_classes(\"src.data_utils\", data_utils)\n","print_functions_and_classes(\"src.cl_loss_function\", cl_loss)\n","print_functions_and_classes(\"src.losses\", losses)\n","print_functions_and_classes(\"src.embeddings.encoder_models\", encoder_models)\n","print_functions_and_classes(\"src.embeddings.encoder_training\", encoder_training)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"elapsed":1378,"status":"ok","timestamp":1737828500800,"user":{"displayName":"Farshad H","userId":"17155898055621377416"},"user_tz":-210},"id":"9ByfVYCjeT7P","outputId":"1ccbf678-6173-440e-ad70-0595ee6e6e27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sampled Dataset: (700, 1, 28, 28) (700,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 2000x600 with 30 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Load and Preprocess MNIST Data\n","fraction = 0.01  # Fraction of the dataset to use\n","batch_size = 64\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=fraction, batch_size=batch_size, shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 30\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 6))\n","for i in range(n):\n","    ax = plt.subplot(3, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lC_8uAUF7t0r"},"outputs":[],"source":["# def generate_embeddings(model, data_loader, embedding_type, device=\"cpu\"):\n","#     model.eval()  # Set model to evaluation mode\n","#     embeddings = []\n","#     labels = []\n","\n","#     with torch.no_grad():\n","#         for images, label_batch in data_loader:\n","#             images = images.to(device)\n","#             if embedding_type == \"autoencoder\":\n","#                 encoded, _ = model(images)\n","#             elif embedding_type == \"vae\":\n","#                 mu, _, _ = model(images)\n","#                 encoded = mu  # Use the mean of the latent space\n","#             elif embedding_type == \"dae\":\n","#                 _, _, encoded = model(images)\n","#             else:\n","#                 raise ValueError(f\"Embedding type '{embedding_type}' is not recognized.\")\n","\n","#             embeddings.append(encoded.cpu())\n","#             labels.append(label_batch)\n","\n","#     embeddings = torch.cat(embeddings, dim=0)\n","#     labels = torch.cat(labels, dim=0)\n","\n","#     return embeddings, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8LPTX8iKf1j"},"outputs":[],"source":["# import torch.nn.functional as F\n","\n","# class NTXentLoss(nn.Module):\n","#     def __init__(self, temperature=0.5):\n","#         super(NTXentLoss, self).__init__()\n","#         self.temperature = temperature\n","\n","#     def forward(self, z_i, z_j):\n","#         batch_size = z_i.size(0)\n","\n","#         # Flatten the input tensors if they are not already 2D\n","#         z_i = z_i.view(z_i.size(0), -1)  # Shape: (batch_size, embedding_dim)\n","#         z_j = z_j.view(z_j.size(0), -1)  # Shape: (batch_size, embedding_dim)\n","\n","#         # Normalize the embeddings\n","#         z_i = F.normalize(z_i, dim=1)\n","#         z_j = F.normalize(z_j, dim=1)\n","\n","#         # Concatenate the embeddings\n","#         z = torch.cat([z_i, z_j], dim=0)  # Shape: (2 * batch_size, embedding_dim)\n","\n","#         # Compute the similarity matrix\n","#         similarity_matrix = torch.matmul(z, z.T) / self.temperature  # Shape: (2 * batch_size, 2 * batch_size)\n","\n","#         # Mask for positives and negatives\n","#         mask = ~torch.eye(2 * batch_size, device=z.device).bool()\n","#         positives = torch.cat([\n","#             torch.diag(similarity_matrix, batch_size),  # Positive pairs (z_i, z_j)\n","#             torch.diag(similarity_matrix, -batch_size)  # Positive pairs (z_j, z_i)\n","#         ])\n","#         negatives = similarity_matrix.masked_select(mask).view(2 * batch_size, -1)\n","\n","#         # Compute the NT-Xent loss\n","#         numerator = torch.exp(positives)\n","#         denominator = torch.sum(torch.exp(negatives), dim=-1)\n","#         loss = -torch.mean(torch.log(numerator / denominator))\n","\n","#         return loss\n","\n","# class VicRegLoss(nn.Module):\n","#     def __init__(self, lambda_var=25, mu_mean=25, nu_cov=1):\n","#         super(VicRegLoss, self).__init__()\n","#         self.lambda_var = lambda_var\n","#         self.mu_mean = mu_mean\n","#         self.nu_cov = nu_cov\n","\n","#     def forward(self, z1, z2):\n","#         # Flatten z1 and z2 if they are 4D\n","#         if z1.dim() == 4:\n","#             z1 = z1.view(z1.size(0), -1)  # Shape: (batch_size, 1 * 28 * 28)\n","#         if z2.dim() == 4:\n","#             z2 = z2.view(z2.size(0), -1)  # Shape: (batch_size, 1 * 28 * 28)\n","\n","#         # Variance loss\n","#         variance_loss = torch.mean(torch.relu(1 - torch.std(z1, dim=0))) + \\\n","#                         torch.mean(torch.relu(1 - torch.std(z2, dim=0)))\n","\n","#         # Mean loss\n","#         mean_loss = torch.mean((torch.mean(z1, dim=0) - torch.mean(z2, dim=0))**2)\n","\n","#         # Covariance loss\n","#         z1_centered = z1 - z1.mean(dim=0)\n","#         z2_centered = z2 - z2.mean(dim=0)\n","\n","#         covariance_matrix_z1 = torch.mm(z1_centered.T, z1_centered) / (z1.size(0) - 1)\n","#         covariance_matrix_z2 = torch.mm(z2_centered.T, z2_centered) / (z2.size(0) - 1)\n","\n","#         covariance_loss = torch.sum(covariance_matrix_z1 ** 2) - torch.sum(torch.diag(covariance_matrix_z1) ** 2) + \\\n","#                           torch.sum(covariance_matrix_z2 ** 2) - torch.sum(torch.diag(covariance_matrix_z2) ** 2)\n","\n","#         # Total loss\n","#         total_loss = self.lambda_var * variance_loss + \\\n","#                      self.mu_mean * mean_loss + \\\n","#                      self.nu_cov * covariance_loss\n","#         return total_loss\n","\n","# class TripletLoss(nn.Module):\n","#     def __init__(self, margin=1.0):\n","#         super(TripletLoss, self).__init__()\n","#         self.margin = margin\n","#         self.criterion = nn.TripletMarginWithDistanceLoss(\n","#             distance_function=lambda a, b: 1.0 - F.cosine_similarity(a, b),\n","#             margin=self.margin\n","#         )\n","\n","#     def forward(self, anchor, positive, negative):\n","#         return self.criterion(anchor, positive, negative)\n","\n","# class BarlowTwinsLoss(nn.Module):\n","#     def __init__(self, lambda_param=5e-3):\n","#         super(BarlowTwinsLoss, self).__init__()\n","#         self.lambda_param = lambda_param\n","\n","#     def forward(self, z_a, z_b):\n","#         \"\"\"\n","#         Compute the Barlow Twins loss between two sets of embeddings.\n","\n","#         Args:\n","#             z_a (torch.Tensor): First set of embeddings.\n","#             z_b (torch.Tensor): Second set of embeddings.\n","\n","#         Returns:\n","#             torch.Tensor: Computed Barlow Twins loss.\n","#         \"\"\"\n","#         batch_size = z_a.size(0)\n","#         feature_dim = z_a.size(1)\n","\n","#         # Normalize embeddings\n","#         z_a = (z_a - z_a.mean(dim=0)) / z_a.std(dim=0)\n","#         z_b = (z_b - z_b.mean(dim=0)) / z_b.std(dim=0)\n","\n","#         # Compute cross-correlation matrix\n","#         cross_corr = torch.matmul(z_a.T, z_b) / batch_size\n","\n","#         # Loss terms\n","#         invariance_loss = torch.sum((1 - torch.diag(cross_corr)) ** 2)\n","#         redundancy_loss = torch.sum(torch.triu(cross_corr, diagonal=1) ** 2) + torch.sum(torch.tril(cross_corr, diagonal=-1) ** 2)\n","\n","#         # Total loss\n","#         loss = invariance_loss + self.lambda_param * redundancy_loss\n","#         return loss\n","\n","class BYOLLoss(nn.Module):\n","    def __init__(self):\n","        super(BYOLLoss, self).__init__()\n","\n","    def forward(self, z_a, z_b, predictor):\n","        \"\"\"\n","        Compute the BYOL loss between two sets of embeddings.\n","\n","        Args:\n","            z_a (torch.Tensor): First set of embeddings.\n","            z_b (torch.Tensor): Second set of embeddings.\n","            predictor (nn.Module): Predictor network.\n","\n","        Returns:\n","            torch.Tensor: Computed BYOL loss.\n","        \"\"\"\n","        # Normalize embeddings\n","        z_a = F.normalize(z_a, dim=1)\n","        z_b = F.normalize(z_b, dim=1)\n","\n","        # Predict z_b from z_a\n","        p_a = predictor(z_a)\n","        p_a = F.normalize(p_a, dim=1)\n","\n","        # Compute MSE loss between predicted and target embeddings\n","        loss = 2 - 2 * (p_a * z_b).sum(dim=1).mean()\n","        return loss\n","\n","# class Predictor(nn.Module):\n","#     def __init__(self, input_dim, hidden_dim=512, output_dim=50):\n","#         super(Predictor, self).__init__()\n","#         self.net = nn.Sequential(\n","#             nn.Linear(input_dim, hidden_dim),\n","#             nn.BatchNorm1d(hidden_dim),\n","#             nn.ReLU(),\n","#             nn.Linear(hidden_dim, output_dim),\n","#         )\n","\n","#     def forward(self, x):\n","#         return self.net(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2i3xXINoYQ0g"},"outputs":[],"source":["import inspect\n","\n","def train_autoencoder_v4(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    predictor: Optional[nn.Module] = None,  # Add predictor for BYOL\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, VicReg, Triplet, Contrastive, InfoNCE, Barlow Twins, BYOL)\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","\n","                    # Flatten embeddings\n","                    encoded = encoded.view(encoded.size(0), -1)\n","                    positive_encoded = positive_encoded.view(positive_encoded.size(0), -1)\n","                    negative_encoded = negative_encoded.view(negative_encoded.size(0), -1)\n","\n","                    # Compute triplet loss\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, Contrastive, InfoNCE, Barlow Twins, BYOL, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Flatten embeddings\n","                    z1 = z1.view(z1.size(0), -1)\n","                    z2 = z2.view(z2.size(0), -1)\n","\n","                    # Handle all contrastive losses uniformly\n","                    if isinstance(contrastive_loss_fn, BYOLLoss):\n","                        # BYOL requires a predictor\n","                        if predictor is None:\n","                            raise ValueError(\"Predictor network must be provided for BYOL loss.\")\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2, predictor)\n","                    else:\n","                        # # Check if the loss function accepts a `temperature` parameter\n","                        # if \"temperature\" in inspect.signature(contrastive_loss_fn.forward).parameters:\n","                        #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                        # else:\n","                        #     contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                        # Check if the loss function accepts a `temperature` parameter\n","                        if \"temperature\" in inspect.signature(contrastive_loss_fn).parameters:\n","                            contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                        else:\n","                            contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"X4tX6ui8MaS5"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABiEAAAE/CAYAAAAg+mBzAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQORJREFUeJzt3XncVWW5N/AFiCM444A4ZTnnEQMzRzBLTTTNUkPs4HHK45w5p0xKUoBDaTlrghMlzmKKgKKpx9JTaqhojjiAoAJqKDzvH+973tNa161787DX3s/w/f53/T73Xvsqb9fez77d++rQ1NTUlAEAAAAAANRYx0Y3AAAAAAAAtE0OIQAAAAAAgFI4hAAAAAAAAErhEAIAAAAAACiFQwgAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABK4RACAAAAAAAoxVLVLFq0aFE2Y8aMrGvXrlmHDh3K7okWrKmpKZs7d27WvXv3rGPHcs+w7Dv+R732nT3Hv7LvqDevsTSCex315l5HI7jX0Qj2HfXmNZZGqHbfVXUIMWPGjGzdddetWXO0fq+//nrWo0ePUp/DvqOo7H1nz5Fi31FvXmNpBPc66s29jkZwr6MR7DvqzWssjVBp31V1LNa1a9eaNUTbUI89Yd9RVPaesOdIse+oN6+xNIJ7HfXmXkcjuNfRCPYd9eY1lkaotCeqOoTwtRqK6rEn7DuKyt4T9hwp9h315jWWRnCvo97c62gE9zoawb6j3rzG0giV9oTB1AAAAAAAQCkcQgAAAAAAAKVwCAEAAAAAAJTCIQQAAAAAAFAKhxAAAAAAAEAplmp0AwAAAABA+7POOuuE7PTTTw/Zsccem6v79+8f1tx44421awyoKd+EAAAAAAAASuEQAgAAAAAAKIVDCAAAAAAAoBQOIQAAAAAAgFIYTA0AAAAA1N1BBx0UsmOOOSZkM2fOzNX33XdfaT0BteebEAAAAAAAQCkcQgAAAAAAAKVwCAEAAAAAAJTCIQQAAAAAAFAKg6lpkzp16hSytdZaK2Rvv/12rl64cGFpPUEtLbVUvH03NTWFrHfv3iE7//zzK15/mWWWCdl2222Xq++6666wZtCgQSH7y1/+UvH5ABqlS5cuITvkkENy9WmnnRbWrL/++iH75JNPKq579913F7dFAGgTevXqlasfffTRsKZz584he/HFF0PWr1+/XP3CCy8sYXfUw9Zbbx2y4cOHh2zatGkhO+KII3L17Nmza9YXVKtPnz5VZanPRor69u0bssmTJzejq9bBNyEAAAAAAIBSOIQAAAAAAABK4RACAAAAAAAohUMIAAAAAACgFAZT0yaNGTMmZAcddFDInnnmmVz92WefhTWpYUePPPJIrp4yZUpYM3HixIp9QrWWXnrpXH3BBReENe+8807IBg4cGLINNtig4vN16NAhZMXB13vttVdYkxrUmhqO/c9//rNiD5BlWfbNb34zV992221hzT/+8Y+QbbXVVmW1RBuTGjp91llnVXzcvHnzQrbccsuFbNttt83Vd91112J0B9A6bLrpprn6ueeeC2vOOOOMkF1xxRW52qDZtu3kk0/O1Z06dQprFi1aFLKNNtooZGPHjs3V++67b1jz5ptvLmaHlK1Lly4hSw0j/9vf/hay4ucw0AjNHUKdMmnSpJClPotpK3wTAgAAAAAAKIVDCAAAAAAAoBQOIQAAAAAAgFKYCUGb9OGHH4ZsxIgRISv+dnPqt5x32mmnkJ155pm5OvXb0bNmzQrZjBkzQnbttdfm6l//+tdhzcKFC0NG+1L8TfGjjz66QZ18sS233DJkI0eODNlxxx1Xj3ZoAwYPHpyrV1hhhbBmww03rFM3tHbDhg0L2Y9+9KOKj3vttddClvrt6dT8KTMggHpbffXVQ1ac7ZVlWfbee+9VvNY222wTsn79+oXssMMOq/h8w4cPD1nx9+HPPvvsij3ROuy///4hS712Nldxb6Zeb3v27Fmz56M2fvrTn1a1btSoUSV3Ao03ZMiQRrdQV74JAQAAAAAAlMIhBAAAAAAAUAqHEAAAAAAAQCkcQgAAAAAAAKVot4Opd99995BdccUVuXrXXXcNa6ZPn96s50sNax06dGjIrrrqqlx99913N+v52rujjjqq1Ot36tQpV3/rW98Ka/r06ROyAw44IGQXXnhhrj7nnHPCmvHjx4fs5z//ea5+6aWXUq3Szs2ePTtkxQGrjzzySFjz0EMPhaw4EPiUU04JazbbbLOQbb/99iErDiGcN29eWANZFu9tO+ywQ1hz77331qsdWrCuXbuGbODAgbn6jDPOCGs6dqz83+Sst956IbvkkktCVnxtpv3p1q1brt5zzz3DmgsuuCBkq666aq6eM2dOWHPEEUeE7OGHHw7Zu+++W7FPWq+11lorZMW/fU477bSqrvXb3/42Vy9atKjitbMsy5ZffvmK1/7oo49C1rlz55Cdfvrpufrmm28Oa5555pmKz0djpf7ZFl+DsyzLll566dJ6KP6tQstQ/Cxsr732CmtS/47/+c9/Lq0naCl22WWXRrdQV74JAQAAAAAAlMIhBAAAAAAAUAqHEAAAAAAAQCkcQgAAAAAAAKVoF4Opi0OEsyw9TLA4wKvaoW5rrLFGrh4yZEhYU+2g5K233jpXG0zdMi1cuDBXT5gwIaxJZWeddVbIevfunasvvvjisOawww4L2Xe/+91cfeaZZ4Y1xUHnWZYeOEfLd+CBBzbrcal73aBBg5a0nSzLsmzcuHEhSw0I3nHHHUNWvNdNnTq1Jj3R9vTo0aPimlmzZtWhE1qS5ZZbLmQ33XRTyFJDgYs+/PDDkM2fPz9XL7vssmHNN77xjZDddtttIbvyyitz9dlnnx3WzJw5s1Kb1FFxuHSWxcGaWZb+53b//ffn6tQA39QQ9aamply98sorhzWp192nnnoqZN/5zndy9TvvvBPW0Dqk7mGp9/zbb799s65/wgknNOtxKcW9ePjhh4c1hxxySMhOPPHEXF38GyfLDKZuiVZbbbVcffnll4c1xXtR2VJDr9dee+2QvfXWW/Voh/+neH9KfT732GOPhaz4mQs0Sp8+fXJ1rT5PSV07y+J7wixLf85cNHjw4Bp0VC7fhAAAAAAAAErhEAIAAAAAACiFQwgAAAAAAKAU7WImxC9/+cuQpX4vcPLkybl65513DmuOP/74kBXXvf/++2HNiBEjKnT5fzX3d99pHVK/a1j8/cMddtghrNltt91CVtxTqd/h3HfffUM2cODAkPkt6rbhP/7jP0J28803l/Z8xd9Mz7Ise/vtt0t7Ptq+Xr16hWzXXXet+Lgy9zmNl5r/MHz48JBVM//hjTfeCFlqj02fPj1XF+d/ZVmW/fSnP60qO/LII3P1l7/85bAm9TpP45xzzjkhO+CAA0JWnCeXZVm25pprltLT5+nZs2fIbrzxxlxdzX2U+ttoo41y9c9+9rOwZsCAASHr2DH+d4QPPvhgrr700kvDmvPPPz9kxftR6nfZU78xPWfOnJC9+uqruTr198Xrr78esuJMiNTMi/POOy9k1E9qjs3VV1+dq/v161evdj7XuuuuG7KTTjopZKeeemo92uH/Kc6E+Oyzz8Kaiy66qF7twGKbNGlSsx5X/Iw5JTUTIqWaORSpNcVZEo2eG+GbEAAAAAAAQCkcQgAAAAAAAKVwCAEAAAAAAJTCIQQAAAAAAFCKNjeY+oILLghZapj0sGHDQnbLLbfk6tSA4L///e8hGzVqVK5ODdV59913QzZ69OiQwaeffhqye++9N2TFvXjxxReHNXvvvXfInnjiiZAVB4k9++yzFfukvs4444xcfdVVV4U1zz//fMg+/vjj0nqCWvv+979fcc3ChQtDlhqSTutVHIB50003hTXVDKHOsjj88Ec/+lFYUxxCnZJ6H3f66aeHrPheMsuybMKECbk6NYAu9b707LPPrtgXtVH8/z/1/qlbt24hu+KKKypeOzVkNzXAfNVVV614rWrtsssuuXq77bYLa1IDiCnPQQcdFLJrrrkmVy+99NJhTWqAa2qo7pVXXpmr586dG9Z89NFHIdtmm21y9eWXXx7WvPfeeyFrrk8++aTimmWXXbZmz8fiSw2h3njjjUNWq0HUd999d8hS+2T//fdv1vVTw91vuOGGXP30008369pEPXr0CFnxn13qb9Zq3otBPTR3CHVK3759K65JDYquZgh1tYrXSl071Wc1Q7WbwzchAAAAAACAUjiEAAAAAAAASuEQAgAAAAAAKIVDCAAAAAAAoBStfjB1cWjfcccdF9Z06NAhZCeffHLIXn755Vx92mmnhTUXXnhhyFKDhIs6d+4csv322y9kTU1NFa8FWZZlr7zySq7eZ599wppDDz00ZKnB6cXhhL179w5rpk2btpgdUkvz5s3L1S1hgNqKK64Ysg033LABndBW9OrVq+Ka1NDMJ598sox2aJAf/vCHubraIdQpp5xySq6u5ZC1RYsWhSy1F4vDO++///6wJjXk+sYbb8zVzz333OK2SEJqaOZRRx2Vq1dfffWqrtWpU6eQPfDAA7n68MMPD2tqOYQ6JfW3D/Wz1lprhWzo0KEhSw2iLvrxj38csuJA62rdd999VWW0byeccELIhgwZUtrz/eQnPwlZcdD6klhzzTVD1qVLl5pdn7zUUPGPPvooV8+ePTus+ec//1laT0uie/fuIZsxY0YDOqEMqaHQffr0ada1mnufTPWQyopSfVbT+y677FLV4wymBgAAAAAAWhWHEAAAAAAAQCkcQgAAAAAAAKVwCAEAAAAAAJSiVQ2mXm+99UJWHJyUGhD31ltvheziiy8O2ahRo3J1NQOnq7XUUvH/6vXXXz9kjz/+eM2eE1KD64oDjrMsy6699tpcPXHixLAm9e/fwoULm98crd5ee+0Vsq997Wshe/PNN0NmoBerrLJKyDbZZJOKj3vjjTfKaIcGSb22fP/732/WtZ5++umQ3Xrrrc26Vi099thjufqZZ54Ja77+9a+HrGfPnrnaYOraSO25agdRV2O33Xar2bWaq3ifnDZtWoM6aZ9Gjx4dso022qji4+65556Q3XLLLTXpCRohNdj0/PPPz9Vf+cpXwpqddtqpZj38/ve/D9mzzz5bs+uTN2vWrJC98847Dejki+29994hO/fcc0OWes/w6quv5upf/vKXYc3YsWOXoDvqJTWkubkGDRpUVVbUt2/fkFUzFDq1pqxh0rXkmxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUolXNhOjYMZ6ZFGctPPHEE2HNwQcfHLLp06fXrrEqbLvttlWt87ufrVPqt80POOCAkHXp0iVk8+fPz9WTJk0Ka1588cWQLVq0aHFa/P/GjRsXso033jhXp34P8ZhjjglZarYKbddaa62Vq6+77rqqHvePf/wjZC+//HJNeqL1St0P11lnnYqPu/3228tohwbZeeedQ1bNb+rPmTMnZKnfdZ07d27zGitR6nU+NROCcqRef4q/D77FFlvUq51SFH+v+v33329MI+3EDTfckKtTfwOkvP3227m6f//+YU3x74TWbtiwYRXXNPdvHBZf6nfxt9xyy2ZdKzUrcPz48SG7//77c/Xuu+/erOdLSc0+vOOOO0KWeg9B21acW3jllVeGNd26davqWltttVWuTs3hTM1EbA2/19+W9enTp6qs3lJ/F3To0KEBndSHb0IAAAAAAAClcAgBAAAAAACUwiEEAAAAAABQCocQAAAAAABAKVrVYOpXXnklZCuvvHLd+6ikc+fOIRszZkzIZs2aFbILLriglJ6oreKA3gcffDCs2WyzzUL27rvvhqw4NPM3v/lNWDNlypSQjRgxIlffe++96WarcN555+XqIUOGhDWp4aEGU7ddqWFI3/72t3N16l6X8umnn9akJ9qW4n76PE899VSuNtS8bUm9VlbjoosuCllLHEJdrc8++yxk99xzTwM6afuKw4CzLMuOP/74XH3JJZeENRtssEHIPv7445ClhrMWFd/DZVkcxjtq1KiK18myLHv44YdDtv/++1f1WBbf8ssvH7LiIPPUe6g///nPITvyyCNzdWu+h6WsuOKKIatmb15++eVltEPC6NGjQ/alL32pWdcaPnx4yH79619XfNzJJ5/crOdLeeedd0I2duzYml2f1mGbbbYJWTWflfTu3TtkL730UshuueWWXL3bbruFNan7WM+ePXP1/PnzK/ZE7bSEIdTVSvXaVgab+yYEAAAAAABQCocQAAAAAABAKRxCAAAAAAAApXAIAQAAAAAAlKJVDaZuLY499tiQrbPOOiG7+uqr69EOJSgO3lp33XXDmh133DFkqaF0xQGGBx98cFgzcODAkN199925OjVsqThoMcvSw5Wq0dwhZbRO++67b8iuvfbaXN3U1BTWPP/88yH7j//4j1q1RRuy9dZbhyw1zPOuu+7K1Z988klZLdEA2267bcU1c+bMCdlll11WRjt1seuuu4Zs4sSJIUv976YckyZNytWpIZNrrLFGyFLvqZo7XPgPf/hDsx43b968kM2aNatZ16KyffbZJ2RbbrllxcdNmDAhZE8//XQtWmoxlltuuVx9zjnnhDU9evSoeJ1bb721Zj2Rd/755+fqDTfcsNnXKr4ODx06NKxZe+21Q3bdddfl6m9+85vN7qHoqaeeqtm1aB26du0asptvvjlkq666aq7+wQ9+ENakPqtJKX7GMmXKlLDmy1/+csiK/z5Mnz69quej5UkNiU7tg0GDBjXr+qnHGUwNAAAAAADwBRxCAAAAAAAApXAIAQAAAAAAlMJMiBKkfoc/9RvWhx9+eD3aYQktv/zyIevTp0+uHjVqVFjzyCOPNOv5ir+7n2VZNmbMmJAdffTRuXrw4MFhzaOPPhqyk08+uarr034ccsghITvllFMqPu7dd98N2Z577hmyV199tXmN0aZ9+9vfDllqzsjLL79cj3Zowd5+++2QvfPOOw3opLKOHeN/33Puuefm6l69eoU1xdd0GmvGjBlVZc21wQYbhKxfv34VH7do0aKQXXrppbVoiSp997vfrbjmhRdeCNkVV1xRRjstyh577JGrTzrppKoeN3LkyFz94IMP1qwn8pZaKv/xT2oWV8r7778fshtuuOELr51l6b9razkD4o477sjVXktbh7XWWitkyy67bMiqmQN36KGHhmyjjTYK2UUXXZSrx48fX/Han2fatGm5OjUTsVu3bs2+PuVIfV5Wj8f+q2pnRBQ/b2xLfBMCAAAAAAAohUMIAAAAAACgFA4hAAAAAACAUjiEAAAAAAAASmEwdQ0Uh3Ctu+66Yc3YsWPr1Q41tttuu4Ws+M/46quvLrWHzz77LGS/+tWvcvX9998f1kyaNClkV111VchWXXXVXF3tkDJap+IAr8svvzysSQ2X+/TTT3P16NGjw5pXXnllyZqjzdpyyy1zdY8ePcKa1L3unnvuKa0nGi/1z7zotttuK7+RGunSpUvITj/99Fw9a9assGbixIml9UTLk3ov1rlz54qPu+WWW0J2991316QnqnPggQeGrKmpKVen3le9/vrrpfXUCKnX8KFDh1Z83MKFC0N255135uri/580XvFvgCyLQ4NTg35Tf0c31/z580NWHEw9e/bsmj0ftTN9+vRcve+++4Y13//+90M2ZsyYmvXw7rvv1uxaRTNmzCjt2pSrVgOnP0+1g6iL+vbtW+NOWg7fhAAAAAAAAErhEAIAAAAAACiFQwgAAAAAAKAUDiEAAAAAAIBSGExdA8WBgx07xrOdY489tl7tUGPbbbddyIpD1V577bV6tfO5pk2bFrIvf/nLIXv44YdDdtFFF1W8flsbqNcWdevWLWSpAYojR47M1Z06darq+pdcckmu/sUvfrEY3dHe9evXL1cvt9xyYc15550XspkzZ5bWE403duzYkO2+++65OjUAtSVIDVEsvidM2WeffUL28ssv16QnWp4NNtggZNtss02zrvXXv/51CbuBxfeDH/wgZEOGDAnZJptskquLg4uzLMsOPfTQkE2dOnUJuuPzpO49O+ywQ7Oulfob4/HHH2/WtZrrrLPOCtk111xT1x5onuLfjN/5znfCmrPPPjtkqfdGjz76aO0aa6allsp/jJr6zCU1CHvOnDml9UTj9enTp2bXmjx5cs2u1dL4JgQAAAAAAFAKhxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUwmDqxbTXXnuFbKeddsrVEyZMCGvmz59fWk/U39JLL52re/XqFdY8+eST9Wrnc6X2XXG/ZlmWvfTSS7l6zTXXDGsMzWz5rrrqqpAVhwFX6/bbbw/ZL3/5y2ZdC7Isy0499dSKax588ME6dEJrs9tuuzW6heRg1htvvLGqxxb39d/+9rea9ETrcMYZZ4RspZVWqvi4O++8M2QjR46sSU+U65VXXml0C1Xr2rVrrr7gggvCmkMOOSRkxcGsWZZlH374Ya7+1re+Fda0hL+P2ov11lsvZNtuu20DOvliH330UcgGDx4cst/+9rd16IYyPPbYY7n6xz/+cVhz2WWXheyee+4JWXFAefFzmc+zyiqrVFyz6qqrhmzzzTcP2Yknnpirt9lmm7DmsMMOC9l7771XsQei4sDnQYMGhTVDhgwJWZnDnSdNmhSy5g6m7tu37xJ207r4JgQAAAAAAFAKhxAAAAAAAEApHEIAAAAAAAClMBPiC3TsGM9oUr/F2qFDh1x98MEHhzWLFi2qXWPUVeq3m4v/zL/yla+ENS3hN09Tv5H485//PGSrr756xWsNGDAgZMXf3nv//ferb47F0q1bt1ydmv/wzW9+s2bPl/o94x133LHi4/bbb7+Q/fd//3fIpk6d+oU1bc8yyyzT6BZogaZPnx6yer9n6tSpU8h69uyZqy+99NKwpvheIMuy7Oabbw5Z//79l6A7WpuNN944V6d+T78aqdfOzz77rFnXonZS/943NTXl6vvuu69e7Xyuzp07h+wb3/hGyIr3rDXWWKOq6//1r38N2f7775+rzZOjGqecckrIzH9o26699tqQpd77/eQnPwnZr371q2Y95wknnJCrU59tpP5WqWaWROrv8jFjxixGd3yR1PyF5qh2RkRqJk1qDkVzpOY/lDm7oiXyTQgAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABK4RACAAAAAAAoRYem4iSthA8//DBbaaWV6tFPizJs2LCQnXXWWSEbN25crk4Nufn0009r11gL8MEHH2Qrrrhiqc/RUvZdagDdjBkzcnWXLl3Cmp122ilkqSFutRrA+aUvfSlkF110Ucj69esXsuIwnBEjRoQ1d955Z8iuueaaXH3kkUdWanOJlL3vWsqeSykOhX7ooYdKfb5qBi8uiXvvvTdX77XXXjW7dq21531XS/Pnz8/Vyy23XFiTGq5eq2FkrUl7eo1NeeWVV3J1t27dwppRo0aFrJr74q677hqyfffdN2SbbrppxWtdd911ITv00EMrPq6lcq9bfF27dg3Zc889l6vXWWedqq715z//OVcXX/ezLMv++c9/LkZ3LV9rvNe9/vrrIevevXuuLg5ozrIsu+2222rWQ2pQ6sCBA3N16n1VaiBm0TvvvBOyP/3pTyE75phjQvb2229XvH5L0F7udakeigOfDzjggJo9X+rvhDvuuCNko0ePztWPPvpoWFOrv49bkvay72pp6aWXDtnBBx+cq1OfbWy88cYh22KLLXL1zJkzw5qpU6eG7Pbbbw/ZI488kquL71uzLMsWLlwYsnprja+xKcW/Bfv06VPq89VS8XW3PQyhrrTvfBMCAAAAAAAohUMIAAAAAACgFA4hAAAAAACAUjiEAAAAAAAASrFUoxtoSTbYYINcfcIJJ4Q1qWFdRx11VK5ua0Oo27vUkK1zzz03Vx922GFhzdVXXx2yq666KmTF4TTPPvtsVX3tvvvuufrEE08Ma9Zcc82QDR8+PGRDhw7N1anBh4cffnjI/v3f/71Sm5C9+eabIXvrrbca0AktyRtvvBGysgeu0zr84Q9/yNUnnXRSWPOzn/2s1B6KAwtPPfXUsGbMmDGl9kDLt8cee4Ss2kHURXfddVeubmtDqNuKH/7whyErDs0sDonOsizbaKONatZDahDrzjvvXPFxn3zySciKg4qvv/76sObpp5+uvjlajA8++CBkqffkzfXcc8/l6tRQ36OPPrpmz0f7s2DBgpBdc801X1jT9hSHOw8ePDisGTRoUJ26+b9SA6aLfZLmmxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUokNT6gfvCz788MNspZVWqkc/DXXJJZfk6tRvGKZ++789/g7dBx98kK244oqlPkd72XdUr+x915L3XKdOnXL1FltsEdYceOCBIdtqq61CVpwVcv/991fVwworrJCrjz/++LBm/PjxIZswYULIrrvuulyd+s3PlqI977tamj9/fq5O/TPv2bNnyF555ZWyWmqx2vtrbPF/+y9+8Yuw5sgjj2zWtR944IGQvf766yH7zW9+k6uffPLJZj1fa+Je98U233zzkD3++OMhK75Wptx0000hO+6443L1e++9txjdtU5t5V5XnCP405/+NKzp3r17qT0U5za89tprYU1qvlt72GdF7fleN3LkyFydmrl0yy23hOzGG28MWfH92V//+tcla66Na8/7jsZoK6+xzdWnT59cnZobUVyTZeY9LKlK+843IQAAAAAAgFI4hAAAAAAAAErhEAIAAAAAACiFQwgAAAAAAKAU7XYw9XLLLReyadOm5eriEM0sy7KddtopZAZ6laMt7juWjIFeNIJ9VxvFoeXf/e53w5pvfvObIZs0aVJpPbVUXmNpBPe6L9arV6+QPfHEE8261jbbbBOy4mDh9qCt3utSQ6gPPfTQqtZV44EHHgjZvffem6s/+eSTZl27PXCvoxHsO+qtrb7G0rIZTA0AAAAAADSEQwgAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABKsVSjG2iUwYMHh2zdddfN1QcddFBY0x6HUAPAktpvv/0a3QJA3Y0ZMyZkzz33XAM6oV5mzJgRsvPOO68BnQAAtBy+CQEAAAAAAJTCIQQAAAAAAFAKhxAAAAAAAEApHEIAAAAAAAClaBeDqTt16hSy/v37h2z27Nm5euLEiaX1BAAAtF4vvvhiyL7yla/k6qFDh4Y1CxYsKK0nAABoiXwTAgAAAAAAKIVDCAAAAAAAoBQOIQAAAAAAgFK0i5kQCxcuDNm6667bgE4AAIDW5sknnwzZJpts0oBOAACg9fFNCAAAAAAAoBQOIQAAAAAAgFI4hAAAAAAAAEpR1SFEU1NT2X3QytRjT9h3FJW9J+w5Uuw76s1rLI3gXke9udfRCO51NIJ9R715jaURKu2Jqg4h5s6dW5NmaDvqsSfsO4rK3hP2HCn2HfXmNZZGcK+j3tzraAT3OhrBvqPevMbSCJX2RIemKo6uFi1alM2YMSPr2rVr1qFDh5o1R+vT1NSUzZ07N+vevXvWsWO5v+Zl3/E/6rXv7Dn+lX1HvXmNpRHc66g39zoawb2ORrDvqDevsTRCtfuuqkMIAAAAAACAxWUwNQAAAAAAUAqHEAAAAAAAQCkcQgAAAAAAAKVwCAEAAAAAAJTCIQQAAAAAAFAKhxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUwiEEAAAAAABQCocQAAAAAABAKRxCAAAAAAAApXAIAQAAAAAAlMIhBAAAAAAAUAqHEAAAAAAAQCkcQgAAAAAAAKVwCAEAAAAAAJTCIQQAAAAAAFAKhxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUwiEEAAAAAABQCocQAAAAAABAKRxCAAAAAAAApXAIAQAAAAAAlMIhBAAAAAAAUAqHEAAAAAAAQCkcQgAAAAAAAKVwCAEAAAAAAJTCIQQAAAAAAFAKhxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUwiEEAAAAAABQiqWqWbRo0aJsxowZWdeuXbMOHTqU3RMtWFNTUzZ37tyse/fuWceO5Z5h2Xf8j3rtO3uOf2XfUW9eY2kE9zrqzb2ORnCvoxHsO+rNayyNUO2+q+oQYsaMGdm6665bs+Zo/V5//fWsR48epT6HfUdR2fvOniPFvqPevMbSCO511Jt7HY3gXkcj2HfUm9dYGqHSvqvqWKxr1641a4i2oR57wr6jqOw9Yc+RYt9Rb15jaQT3OurNvY5GcK+jEew76s1rLI1QaU9UdQjhazUU1WNP2HcUlb0n7DlS7DvqzWssjeBeR72519EI7nU0gn1HvXmNpREq7QmDqQEAAAAAgFI4hAAAAAAAAErhEAIAAAAAACiFQwgAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABK4RACAAAAAAAohUMIAAAAAACgFA4hAAAAAACAUjiEAAAAAAAASuEQAgAAAAAAKIVDCAAAAAAAoBQOIQAAAAAAgFI4hAAAAAAAAErhEAIAAAAAACjFUo1uAABof44++uiQXXrppSHbbbfdcvXEiRNL6wmgtXn88cdDttZaa+Xqb33rW2HNCy+8UFpPAJ+nT58+uXrSpEk1u/bkyZNDNmTIkKrWAVA+34QAAAAAAABK4RACAAAAAAAohUMIAAAAAACgFA4hAAAAAACAUhhMDSU54ogjQnbGGWeEbP311694rY4d43nhU089lav32muvsOatt96qeG2ARvj6178eskWLFoXsuOOOy9UGUwPt1bBhw0K29dZbh6xTp065erPNNgtrDKYGaqk4cDrLajt0urk9TJkyJWQGU5MycuTIkM2ZMydk5513Xj3aoQ360Y9+FLLUfau55s+fH7Li39KN5psQAAAAAABAKRxCAAAAAAAApXAIAQAAAAAAlMJMCKhg+eWXD1lx/sKoUaPCmjXXXDNkxd/ozbIsa2pqqthD6nfSt9pqq1x9+eWXhzV77713xWtDtfbbb79cfeaZZ4Y1vXv3rlc7tDKdO3fO1auttlqDOqGtSs1Y2nnnnb+wzrIs23zzzUO2/fbbV3y+N954I2TDhw8PWXGOid/ip7m+973vhSz13pLWYcUVV8zVf/vb38Kajz76KGTnn39+yK677rraNQZVKP6Oeb3nP8CSWGWVVUI2YMCAkN1yyy31aIc2qjiPYcSIEWHNMsssU7Pnmz17dsUeGs03IQAAAAAAgFI4hAAAAAAAAErhEAIAAAAAACiFQwgAAAAAAKAUBlP/izXWWCNXX3XVVWFNv379QlbNYOHJkyeHbNy4cSErDhdeuHBhxWtTO1tuuWXITjzxxJANHDgwV3fo0CGsSe2LZ555JmSXXnpprv7v//7vsCZ1/fHjx+fq999/P6yBaqSGuY4ePTpkxcHUqT1eXJNl6aGvzz33XK4u7mfanuIg6u985zsN6oTWpmPH+N/MpO41F198ccjWXnvtXJ26b6UGv9577725+t/+7d/CmpVXXjlkF154YcimTZuWq4866qiw5rHHHgsZ7du+++4bsg033LCqxxYHHD/44IO1aIkamzdvXq7+8MMPw5otttgiZFdffXXIfv3rX+fq1N+ZN998c8iKf5u8+eab6WahYNCgQaVde8iQISHbZZddKj6ub9++ZbRDG7TrrruGrFu3biFL/R0LW2+9dchSg82PP/74XN2pU6eyWsqyLMuWX375kB144IG5OvVeoJ58EwIAAAAAACiFQwgAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABK0S4GUxeHEmZZlg0ePDhkxUEiyy23XFhTzRDqlD59+lSVbb/99rn6sMMOC2sWLFjQrB6Itttuu1x9xx13hDWrrrpqxevMnTs3ZCeffHLIbrvttpC99957Fa+fUhzAWRyiCZ9n0003zdVTpkwJa4pDhLMs3v9S98O///3vIfvd734XsuKgVoOpgf+x5ZZb5uqzzjorrCkOWcuyLHvppZdCdvnll+fq1OvwhAkTFrPDz1fsPcuybMSIEbn6+uuvD2u+8pWv1KwHWqd11103V59zzjlhzdJLLx2y2bNnh+zss8/O1an3qTTeokWLcvVPfvKTsCY1oLf490uWZdkKK6yQqwcOHBjWpLL58+fn6kcffTSsOeaYY0I2ffr0kNF2TZo0KWSpzzKqMXny5FxtmDSf59/+7d9CVvy87De/+U2zrl3t/p04cWKzrk/rlfoc5LLLLsvVO+ywQ1izxhprNOv5Pvroo5ANGzYsZFOnTs3V48aNC2vWWmutkB1wwAG5OvW54Ycfflixz1rxTQgAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABK0eZmQnTu3DlkN9xwQ8h22WWXiteaN29eyEaNGhWyd999N1enfmMr1UPq9zwPPvjgXJ2aK1B8Ppqv+Bun1cx/yLIsu/3223N1cT5DlqV/Z7+Wfv7zn5d6fdqGPfbYI2TXXXddru7WrVtYM3PmzJAV9/l5550X1jz33HMhW3755Sv2CbRPe+65Z8huueWWXJ2a0TVmzJiQpd4zpe5lZXrmmWdCVvwt1tQMipVWWilkxd//f//998OaTz/9dDE7pKXaZ599cvVWW21V1eOeeuqpkN1111016Yn6uv/++0P24IMPhmzHHXcM2U9/+tNcvddee1X1nMVZEt/61rfCmvvuuy9kqXv3Cy+8UNVz0nKk5mQOGjSoZtdPzTRJPSdsu+22IUvNInnooYdydXNnQtD+pF47U7NBevfuHbJ+/frVpId77rknZHfffXfIfvvb31a81ujRo0P2i1/8ImT77rtvri5+FpRl6dm4ZfFNCAAAAAAAoBQOIQAAAAAAgFI4hAAAAAAAAErhEAIAAAAAAChFmxtMPWDAgJBVM4Q6y+IgxNNOOy2sefXVV5vVV2qwSGowddEWW2wRMoOpa6e4Nzp06FDV44rDXVZbbbWwpji8Osuy7K233grZTTfdVNVzQiVnnXVWyIYOHRqypqamL6yzLMsOOeSQkP3xj3+s2MMmm2xS8fmA9ik1KDX1GlgclJoaYpm6t7VUXbt2zdUvvfRSWDN9+vSQFd9bpN43PvHEE0vYHY2w+uqrhyz1uluNsWPHLmk7tGALFy4M2ZQpU0L28MMP5+oNN9wwrDn55JNDduCBB+bqVVZZJaxJXeuwww4LWepvZ1qW4utpLYdQQ7XWW2+9kP3+978P2bLLLhuyCy64oJSeaN1WWmmlkG222Wa5+sYbbwxrunfvXtX133vvvVz9ySefVPW4Aw44IFen/gaYOXNmVdcqSr3/69+/f8i23nrrZl2/LL4JAQAAAAAAlMIhBAAAAAAAUAqHEAAAAAAAQCkcQgAAAAAAAKVoc4Op11xzzarWPfDAAyH74Q9/mKtrOUw1Nay1GqlBxtTOkUcemauvu+66sCY1dLpop512CtmOO+4YsgULFoRsxIgRFa//0EMPheyOO+6o+LiVV145ZD/72c9CdtVVV+Xq1jTws70aNmxYyM4888yQpYatz5o1K1dPmzYtrNlvv/1C9tprr+Xq0aNHV/V8KVdccUVV64DWa88998zV48aNC2tSQ1cPPfTQXD1mzJjaNlaiPn36hOyiiy7K1V/96lerulbx3vz00083ty1amAkTJoSsmsGBkyZNCtk999xTi5Zo5RYtWpSrU8Mv//M//zNk5513Xq4eOXJkWFMcXp1lWXbccceFrPjebvr06elmaZjJkyfn6loOph4yZEjF56N96ty5c65ODdRdZ511QjZlypSQPf744zXpaYUVVqjJdai/1DDp1Od4u+66a8VrzZ8/v6prXXLJJbk69flJvb399tshmzdvXsXH7bHHHiGr5rPFWvFNCAAAAAAAoBQOIQAAAAAAgFI4hAAAAAAAAErhEAIAAAAAAChFmxtMnRqmmjJnzpyQ1WoQda9evUJWHID8eW666aZc/fLLL9ekJ9KKgwFTw2tSQ9y22mqrZj3flltuGbLUEKai/v37h6w4SH1JrLjiijW7FuU466yzcnVqCHXqHlYcQp1lcVjs5ptvHtY899xzISsOYLrtttvCmt13372qvlLXh5SuXbvm6mWWWSas+ec//1mvdvgcq622Wsh++9vf5upll102rBk2bFjIUgPhWqIf/OAHIRs+fHjIiv+7n3/++bBmk002CdkLL7yQqxcsWLC4LdICpPZ9z549Q1bN3yHHHntsyFKv81CtN998M1fPnj27qsel9nUqo2Wp5aDo4iDqwYMH1+zatC3f+973cvX2228f1qQ+n0t9hvbBBx/UpKd99tmnqnWTJk2qyfPRfEsvvXSuHjNmTFizyy67VLzOp59+GrITTjghZNdcc81idNf6HHXUUSFLfeZZFt+EAAAAAAAASuEQAgAAAAAAKIVDCAAAAAAAoBRtbiZEtXr06BGyjh3zZzKLFi2q6lprrLFGri7OGciyLFt11VWrutZhhx2Wq/3+b309++yzITvmmGNqdv2+ffuGrPg72nvvvXdYM2DAgJr1kFL8zfVOnTqFNQsXLiy1B/7XSSedFLKhQ4fm6g4dOoQ1qd+FXnPNNSs+31/+8pfF6O5/HXHEESGrtq+pU6c26zlpf/r06ZOrN9xww7CmOK+E+kvNdlh33XVz9ciRI8Oa4m9KtxTdu3fP1UcffXRYc9ppp4XsnnvuCVlxTsQf//jHqnr493//96rW0bKdffbZzXpc6rXZ/AfK9uUvf7mqdam5hf/4xz9q3Q41VnxPtSTMgCClW7duIbvooosqPm7gwIEhmz59ei1ayrIsy772ta/l6i5dulT1uJkzZ9asB5qnOGOumvkPWZZld955Z64eO3ZsWDNu3LjmN0az+CYEAAAAAABQCocQAAAAAABAKRxCAAAAAAAApXAIAQAAAAAAlKLNDab+05/+FLLevXuH7Bvf+EbIisO0Jk+eHNY8/fTTIdtyyy1zdWoIdWrIdXEIdZZl2SeffBIy2o5JkyaFbOWVV87V2223XZ26+V+HH354rk7t89/85jd16qZ92W+//UJ2+umnh6ypqSlXpwbx7rnnnrVrLGHTTTf9wjrLYp9ZFoeyVis12Kz4/1dqEPYf/vCHkBnmCeVaeumlK6556qmnQpZ6f1Sm1VZbLWSnnnpqyIoDElP3ozfffDNkZ555Zsg23njjXL3iiiuGNamBrh9//HHIaPn23nvvXJ16Te/YMf53YMV/F1Lvu957770l7A7y1ltvvVy9/fbbV/W4e+65J2Tz58+vSU+Up7mDqYcMGVLbRpoh1XsxS31+k8ooz4ABA0JWfA81Y8aMsGbq1Kk166FHjx4h+973vperO3fuXNW1dtxxx5AV39e99dZbYU3q8xQq69WrV8h23nnnio+7/vrrQ3bsscfm6nnz5jW/MWrGNyEAAAAAAIBSOIQAAAAAAABK4RACAAAAAAAohUMIAAAAAACgFG1uMPXgwYNDlhpMs8UWW4Rsk002ydWHHHJIWJPKqvH444+H7LrrrmvWtWi9unfvHrK77747V2+11VZhTTUDDHfYYYewJjXY56KLLqp4/V//+tdhTWqg6GOPPRYyvthJJ52Uq1MDK1MDUGfOnJmr999//7DmtddeW8LuvlhxPy2//PJhTWpQ9JFHHhmyzTbb7AvrLEsPoSru+9S/G5deemnIOnXqFDKgdlJD6Yv22GOPkD3//PM16+HrX/96yL761a/m6tSAwdR9a9CgQbn697//fVgzZ86ckG2wwQYhu+CCC3L1ggULwpoDDzwwZKl1tCxdunQJ2U9+8pNcnfp3IzWQ/bLLLsvV/k6gHq6++upcvcIKK1T1uNQ9kbYr9RlLrR5XfL1dEqlr9e3bN2SGVZfnoIMOClnxfdY666wT1syePbtmPaTe11XzPjXlmmuuqbjmiSeeCNl2223XrOdr7x599NGQFf+OT73/vv3220PW1gdRp/7mWGWVVerfyGLyTQgAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABK0eZmQrz//vsh+/73vx+y1O9dnnvuubm6X79+Yc1GG21UsYf58+eH7Kijjqr4ONq+K6+8MmTF36uu9reD77zzzlz9l7/8Jaz5r//6r5CNHz++4rVScymKv2mdZVn2gx/8IFe/8cYbYQ15I0eOzNWpf96p7NZbb83VqRkK06ZNC1lqHkPREUccUXFNlmXZNttsk6ur/W3N4rydLMuyTTfdtOK1Uvu+uC61pvj/FVC+YcOGhWz11VfP1QMGDAhrmjtrq1p///vfc/Uf/vCHsOb8888P2UcffdSs50v971l//fVz9V133RXWPPnkk816PupnpZVWCtnAgQNDttNOOzXr+sW/Q1Kvb7Akjj/++JD16dOn4uNuu+22kD300EM16Ii2ZNKkSSGrZn+VLdWDmRDlSc3lGDduXK5OzRWs1sKFC3P1xIkTq3pccSZsai5Faq5galbmq6+++oU90XxLLRU/oi7+/X/ssceGNanPuNqa4tzQ66+/PqxJzT5uaXwTAgAAAAAAKIVDCAAAAAAAoBQOIQAAAAAAgFI4hAAAAAAAAErR5gZTVys1PPqkk07K1ffee29YM2HChJB99tlnufqcc84Ja5555pnFbZE2KDXUsBozZswIWXGA4YIFC6q61ptvvhmyX/ziF7n66quvDmt69+4dsrFjx+bqXXbZpaoe2rMOHTo0a01xwHRq2H1quHPqWsV11az5vHVFqWGuqYHZV1xxRcVrpYYepq5F+7LzzjuHzL5ovNdeey1k++23X65O/bMrDqnPsjjA+oYbbghrqh0cXXzf9u6771b1uGrstttuITv55JNDNnv27Fw9dOjQmvVA/aT+eY8aNapZ1yr+zZFlWfb2228361qQsvbaa4fshBNOCFnHjpX/m8Tm7nPajsGDB4csNYAYUp+X9ejRI1en7jvf/va3Q9alS5eQ3Xrrrbl6zpw5VfV11VVX5eqBAweGNS+//HLInn/++aquT21U87nE9OnT69VOXaywwgoh22yzzUJWHJz+ta99rVnP9+KLLzbrcbXimxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUwiEEAAAAAABQinY7mLoa+++/f1XrigNsLrjggjLaoR1LDfF98skna3b9m266KVePGDEirFlnnXVCtt5669Wsh/Zizz33zNXXXXddWNOtW7eQpQZFV7Nm1qxZISsO9KpmSHSWZdmZZ56Zq/fdd9+wJjUgODXUHJpru+22C9nll1/egE5YXKlh86msJf7z7Nq1a8hSw1pTw+XuueeeXF3L12/KsdJKK4UsNdS3Gi+99FLILr744mZdC6p10UUXhWzDDTes+LhTTjklZH/6059q0hOtV72HUE+ePDlkffr0qdm1qK8PPvig4pqbb765Dp3Q0o0ZMyZk/fv3z9Xjxo2r6nFFU6ZMCdkDDzxQVV+dO3fO1eecc05Vj6tG9+7dQ5YanN5cf/7zn3P1gAEDanbt5vBNCAAAAAAAoBQOIQAAAAAAgFI4hAAAAAAAAErhEAIAAAAAACiFwdT/ojh4tzgAJcuybM6cOSFr9GAP2r6hQ4c2ugVq5L777svVa621VlWP23TTTSuuSQ2Fbq6dd945ZN/73vdydWoQ9sMPP1yzHiBl1VVXDVlxWFiWZdmnn35aj3ZoJ1IDE7/61a+G7JlnngnZiSeeWEZLlGjEiBEh23777at67AsvvJCr99xzz5r0BF+k+H6yZ8+eYU2HDh1CNnXq1Fx99dVXhzWLFi1awu5or4YMGRKywYMH5+pJkyaFNc0dQt23b9+QGUwNrcfvfve7kO299965er311gtrzjzzzIrXPuKII0I2c+bMxejuf22++ebNetySKP5t+9prr4U1c+fODdl+++2Xq998883aNraYfBMCAAAAAAAohUMIAAAAAACgFA4hAAAAAACAUpgJ8S9+/OMf5+oVVlghrHnooYdC9uSTT5bWE21L6rdYU1mjVdtnx47OMeullvMeqpGaQVGcAZGaCTF8+PDSeqJ1W7BgQa5+++23w5pqZqQUfxc0y9JzIt55553F6A7yir8327t376oed84554TsrbfeqklPlGe33XbL1d/97nebfa1f/epXufrVV19t9rWgWqeeemqu3mijjcKa1Pu20aNH5+rU/EOoRrWzF4ozIJo7/yH1nOY/8Hmqmc80b968OnTCF7n//vtDdtRRR+Xq1Hu0Aw88sOK1u3XrVlXWEhTnNWVZlt177725+vzzz69XOzXlE0QAAAAAAKAUDiEAAAAAAIBSOIQAAAAAAABK4RACAAAAAAAoRbsdTN2rV6+QFQd6pfz+978vox3aidRAuFRWdP3114fsyCOPzNUff/xxs/vaeOONc/Wyyy4b1qT6XLRoUbOfk5atmkHkqX/+s2bNKq0nWrfZs2fn6tTgsUMOOaRe7cD/V7y3ZVmWDRs2LFevttpqYc348eNDdt9999WuMUrxta99LWRjx47N1al/3p999lnIXnzxxZA9+OCDS9AdVPbtb387ZIcffnjFx/3lL38J2V133VWTnmgdioObBw0aVLNrpwZML8nQ6aIhQ4aEbPDgwTW7Pm3HcsstF7KVV1654uPuvvvuErphSd188825esKECWHNpZdeGrL1118/V1944YU17asaTz31VK4eOnRoVY979dVXQ/b666/XpKdG800IAAAAAACgFA4hAAAAAACAUjiEAAAAAAAASuEQAgAAAAAAKEW7GExdzcDBLMuyzp075+p77703rPnd735Xu8Zod4YPHx6y4kCwbbbZJqzp379/yDbddNNcvWDBgmb3tfbaa+fqVVddNayZO3duyFIDwmgbqhlEfuutt9arHYDSrLLKKiH70Y9+lKs/+eSTsOass84K2ccff1y7xijFeuutF7LUIOqiZ599NmSpIddQS8XBmlmWHsDZpUuXXD1//vywJjXQ+tNPP12C7mhtioOpi3WW1XaYdHP17ds3ZKleIaVfv34hW2aZZXL1K6+8Etak7pu0PB988EHIpk6dWjEbO3ZsaT1RPd+EAAAAAAAASuEQAgAAAAAAKIVDCAAAAAAAoBTtYiZE7969Q7b77ruHbN68ebk69fv9CxcurF1jtDt33313yJ566qlcnfrN4RVXXDFkPXv2rFlfHTp0yNVvvvlmWHPOOeeE7Nprr61ZD7QsM2fODNkf//jHXH300UfXqx3aoNQ9Zfvttw9ZcT7J0KFDw5rUfoWU1MyjO++8M2TFfZeagTNt2rTaNUaLctVVV4Vs1KhRDeiE9m7cuHEh+9KXvhSy4j3rmGOOCWtmz55du8ZoE1KzF1IzISZNmlSz5yzOdkjNGDT/gSWx3377VVwzcuTIkKVmDQC15ZsQAAAAAABAKRxCAAAAAAAApXAIAQAAAAAAlMIhBAAAAAAAUIo2N5i6V69eIbv44oureuzUqVNz9SOPPFKTnuCLzJgxI1fvu+++YU01Q6iPO+64kK200kohO/fccyte68orrwxZcXA7bdv48eOryqC5XnvttZBtvPHGDeiE9mSbbbYJ2XbbbRey+fPn5+pBgwaV1hP1lXotW2qpNvcnEe3MpZdemqt/97vfNagTWrvUUOgOHTrUvxGooeJnLhMnTmxQJ9C++SYEAAAAAABQCocQAAAAAABAKRxCAAAAAAAApXAIAQAAAAAAlKLNTWE7+OCDQ9a7d++qHnvZZZfVuh1YbFOmTKkqK7rwwgtL6AYA2o7UAOKmpqaQDRgwIFdPnz69tJ4AFsezzz4bsmHDhjWgE4CWp3///o1uAfgcvgkBAAAAAACUwiEEAAAAAABQCocQAAAAAABAKRxCAAAAAAAApWhzg6kfeuihkJ1wwgkhGzNmTMjuvPPOUnoCAKDxJkyYELJOnTo1oBOAyrbddttGtwAAUBO+CQEAAAAAAJTCIQQAAAAAAFAKhxAAAAAAAEAp2txMiPHjx4esY0dnLQAAAAAAUG8+nQcAAAAAAErhEAIAAAAAACiFQwgAAAAAAKAUVR1CNDU1ld0HrUw99oR9R1HZe8KeI8W+o968xtII7nXUm3sdjeBeRyPYd9Sb11gaodKeqOoQYu7cuTVphrajHnvCvqOo7D1hz5Fi31FvXmNpBPc66s29jkZwr6MR7DvqzWssjVBpT3RoquLoatGiRdmMGTOyrl27Zh06dKhZc7Q+TU1N2dy5c7Pu3btnHTuW+2te9h3/o177zp7jX9l31JvXWBrBvY56c6+jEdzraAT7jnrzGksjVLvvqjqEAAAAAAAAWFwGUwMAAAAAAKVwCAEAAAAAAJTCIQQAAAAAAFAKhxAAAAAAAEApHEIAAAAAAAClcAgBAAAAAACUwiEEAAAAAABQiv8DOcBQDQmK28AAAAAASUVORK5CYII=\n","text/plain":["\u003cFigure size 2000x400 with 20 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training IntermediateAutoencoder with info_nce loss...\n","Epoch [1/50], Train Loss: 4.3815\n","Epoch [2/50], Train Loss: 4.2643\n","Epoch [3/50], Train Loss: 4.2422\n","Epoch [4/50], Train Loss: 4.2292\n","Epoch [5/50], Train Loss: 4.2260\n","Epoch [6/50], Train Loss: 4.2212\n","Epoch [7/50], Train Loss: 4.2175\n","Epoch [8/50], Train Loss: 4.2179\n","Epoch [9/50], Train Loss: 4.2154\n","Epoch [10/50], Train Loss: 4.2144\n","Epoch [11/50], Train Loss: 4.2109\n","Epoch [12/50], Train Loss: 4.2117\n","Epoch [13/50], Train Loss: 4.2114\n","Epoch [14/50], Train Loss: 4.2093\n","Epoch [15/50], Train Loss: 4.2084\n","Epoch [16/50], Train Loss: 4.2094\n","Epoch [17/50], Train Loss: 4.2074\n","Epoch [18/50], Train Loss: 4.2061\n","Epoch [19/50], Train Loss: 4.2061\n","Epoch [20/50], Train Loss: 4.2021\n","Epoch [21/50], Train Loss: 4.2060\n","Epoch [22/50], Train Loss: 4.1961\n","Epoch [23/50], Train Loss: 4.2039\n","Epoch [24/50], Train Loss: 4.1944\n","Epoch [25/50], Train Loss: 4.1993\n","Epoch [26/50], Train Loss: 4.2042\n","Epoch [27/50], Train Loss: 4.2010\n","Epoch [28/50], Train Loss: 4.2028\n","Epoch [29/50], Train Loss: 4.2018\n","Epoch [30/50], Train Loss: 4.1990\n","Epoch [31/50], Train Loss: 4.2029\n","Epoch [32/50], Train Loss: 4.2044\n","Early stopping triggered at epoch 32.\n","Embeddings saved in PyTorch format: ./saved_embeddings/embeddings/autoencoder_IntermediateAutoencoder_info_nce/IntermediateAutoencoder_info_nce_embeddings.pt\n","Model saved: ./saved_embeddings/embeddings/autoencoder_IntermediateAutoencoder_info_nce/IntermediateAutoencoder_info_nce.pth\n"]}],"source":["# ------------------------------\n","# Step 1: Define Configuration\n","# ------------------------------\n","\n","# Configuration\n","config = {\n","    \"model_type\": \"autoencoder\",  # Options: \"autoencoder\", \"vae\", \"dae\"\n","    \"model_name\": \"IntermediateAutoencoder\",  # Options: \"BasicAutoencoder\", \"IntermediateAutoencoder\", \"AdvancedAutoencoder\", \"EnhancedAutoencoder\", \"BasicVAE\", \"ImprovedVAE\", \"FlexibleVAE\", \"ImprovedFlexibleVAE\", \"DenoisingAutoencoder\"\n","    \"code_dim\": 50,  # Dimensionality of the embedding\n","    \"loss_type\": \"info_nce\",  # Options: \"mse\", \"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"\n","    \"noise_factor\": 0.1,  # Noise factor for denoising autoencoders\n","    \"temperature\": 0.5,  # Temperature parameter for NT-Xent loss\n","    \"margin\": 1.0,  # Margin for Triplet Loss\n","    \"epochs\": 50,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-3,\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"save_best\": True,  # Whether to save the best model\n","    \"save_path\": \"best_model.pth\",  # Path to save the best model\n","    \"beta\": 1.0,  # Weight for KL divergence (VAE only)\n","    \"alpha\": 0.5,  # Weight for contrastive or triplet loss\n","    \"fraction\": 1.0,  # Fraction of the dataset to use\n","    \"projection_dim\": None,  # Optional projection head dimension for VAEs\n","    \"strong_architecture\": False,  # Whether to use a deeper architecture for DenoisingAutoencoder\n","    \"input_shape\": (1, 28, 28),  # Input shape for FlexibleVAE and ImprovedFlexibleVAE\n","    \"patience\": 8,\n","    \"min_delta\": 0.001,\n","    \"triplet_data\": False,\n","}\n","\n","# ------------------------------\n","# Step 2: Load and Preprocess Data\n","# ------------------------------\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","# mnist_loader = data_utils.load_mnist_data(fraction=config[\"fraction\"], batch_size=config[\"batch_size\"], shuffle=True)\n","\n","# # Inspect Combined Dataset\n","# for batch in mnist_loader:\n","#     images, labels = batch\n","#     print(\"Batch Shape:\", images.shape, labels.shape)\n","#     break\n","\n","# Visualize Original Images\n","n = 20\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n","\n","# ------------------------------\n","# Step 3: Initialize Model, Loss, and Optimizer\n","# ------------------------------\n","\n","# Initialize the model\n","# Initialize the model\n","model_classes = {\n","    \"BasicAutoencoder\": encoder_models.BasicAutoencoder,\n","    \"IntermediateAutoencoder\": encoder_models.IntermediateAutoencoder,\n","    \"AdvancedAutoencoder\": encoder_models.AdvancedAutoencoder,\n","    \"EnhancedAutoencoder\": encoder_models.EnhancedAutoencoder,\n","    \"BasicVAE\": encoder_models.BasicVAE,\n","    \"ImprovedVAE\": encoder_models.ImprovedVAE,\n","    \"FlexibleVAE\": encoder_models.FlexibleVAE,\n","    \"ImprovedFlexibleVAE\": encoder_models.ImprovedFlexibleVAE,\n","    \"DenoisingAutoencoder\": encoder_models.DenoisingAutoencoder,\n","}\n","\n","# Initialize model with appropriate arguments\n","if config[\"model_name\"] in [\"FlexibleVAE\", \"ImprovedFlexibleVAE\"]:\n","    model = model_classes[config[\"model_name\"]](\n","        input_shape=config[\"input_shape\"],\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"]\n","    ).to(config[\"device\"])\n","elif config[\"model_name\"] == \"DenoisingAutoencoder\":\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"],\n","        strong_architecture=config[\"strong_architecture\"]\n","    ).to(config[\"device\"])\n","else:\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"]\n","    ).to(config[\"device\"])\n","\n","# Define the loss function\n","if config[\"model_type\"] == \"vae\":\n","    criterion = losses.vae_loss  # Use VAE loss for VAEs\n","else:\n","    loss_functions = {\n","        \"mse\": nn.MSELoss(),  # Reconstruction loss\n","        \"vicreg\": cl_loss.VicRegLoss(lambda_var=25, mu_mean=25, nu_cov=1),  # VicReg loss\n","        \"ntxent\": cl_loss.NTXentLoss(temperature=config[\"temperature\"]),  # NT-Xent loss\n","        \"triplet\": cl_loss.TripletLoss(margin=config[\"margin\"]),  # Triplet loss\n","        \"contrastive\": cl_loss.contrastive_loss,  # Basic contrastive loss\n","        \"info_nce\": cl_loss.info_nce_loss,  # InfoNCE loss\n","        \"barlow_twins\": cl_loss.BarlowTwinsLoss(lambda_param=5e-3),  # Barlow Twins loss\n","        \"byol\": cl_loss.BYOLLoss(),  # BYOL loss\n","    }\n","    criterion = loss_functions[config[\"loss_type\"]]\n","\n","predictor = cl_loss.Predictor(input_dim=config[\"code_dim\"]).to(config[\"device\"])\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Define scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","\n","# ------------------------------\n","# Step 4: Train the Model\n","# ------------------------------\n","\n","if config[\"model_type\"] == \"autoencoder\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_autoencoder_v4(\n","        model=model,\n","        data_loader=mnist_loader,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        optimizer=optimizer,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        scheduler=scheduler,\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        temperature=config[\"temperature\"],  # Pass temperature for NT-Xent, contrastive, and InfoNCE\n","        triplet_data=(config[\"loss_type\"] == \"triplet\"),  # Enable triplet data only for triplet loss\n","        augment_fn=cl_loss.augment if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        predictor=predictor if config[\"loss_type\"] == \"byol\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"vae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_vae(\n","        vae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,  # VAE loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        beta=config[\"beta\"],  # Weight for KL divergence\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"dae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_dae(\n","        dae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        noise_factor=config[\"noise_factor\"],  # Noise factor for denoising\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        triplet_loss_fn=criterion if config[\"loss_type\"] == \"triplet\" else None,\n","        ssim_func=losses.ssim if config[\"loss_type\"] == \"ssim\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","# ------------------------------\n","# Step 5: Save Embeddings and Model\n","# ------------------------------\n","\n","# Generate embeddings\n","embeddings, labels = data_utils.generate_embeddings(\n","    model=model,\n","    embedding_type=config[\"model_type\"],\n","    data_loader=mnist_loader,\n","    device=config[\"device\"],\n",")\n","\n","# Define the base storage directory for embeddings\n","base_dir = \"./saved_embeddings\"\n","os.makedirs(base_dir, exist_ok=True)\n","\n","# Ensure a dedicated directory for embeddings\n","embeddings_dir = os.path.join(base_dir, \"embeddings\")\n","os.makedirs(embeddings_dir, exist_ok=True)\n","\n","# Create a unique subdirectory for this embedding type, model, and loss type\n","embedding_subdir = f\"{config['model_type']}_{config['model_name']}_{config['loss_type']}\"\n","embedding_dir = os.path.join(embeddings_dir, embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","# Choose saving format: default is .pt, but .npy can be chosen\n","save_format = \"pt\"  # Change to \"npy\" for NumPy format\n","\n","# Save embeddings with differentiated names based on the model, loss type, and embedding type\n","if save_format == \"pt\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.pt\")\n","    torch.save({\"embeddings\": embeddings, \"labels\": labels}, embedding_file)\n","    print(f\"Embeddings saved in PyTorch format: {embedding_file}\")\n","elif save_format == \"npy\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.npy\")\n","    np.save(embedding_file, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    print(f\"Embeddings saved in NumPy format: {embedding_file}\")\n","else:\n","    raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# Save the model\n","model_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}.pth\")\n","torch.save(model.state_dict(), model_file)\n","print(f\"Model saved: {model_file}\")\n","\n","# ------------------------------\n","# Step 6: Visualize Embeddings\n","# ------------------------------\n","\n","# Visualize embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCTixDfTWufj"},"outputs":[],"source":["# ------------------------------\n","# Step 1: Define Configuration\n","# ------------------------------\n","\n","# Configuration\n","config = {\n","    \"model_type\": \"autoencoder\",  # Options: \"autoencoder\", \"vae\", \"dae\"\n","    \"model_name\": \"IntermediateAutoencoder\",  # Options: \"BasicAutoencoder\", \"IntermediateAutoencoder\", \"AdvancedAutoencoder\", \"EnhancedAutoencoder\", \"BasicVAE\", \"ImprovedVAE\", \"FlexibleVAE\", \"ImprovedFlexibleVAE\", \"DenoisingAutoencoder\"\n","    \"code_dim\": 50,  # Dimensionality of the embedding\n","    \"loss_type\": \"barlow_twins\",  # Options: \"mse\", \"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"\n","    \"noise_factor\": 0.1,  # Noise factor for denoising autoencoders\n","    \"temperature\": 0.5,  # Temperature parameter for NT-Xent loss\n","    \"margin\": 1.0,  # Margin for Triplet Loss\n","    \"epochs\": 50,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-3,\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"save_best\": True,  # Whether to save the best model\n","    \"save_path\": \"best_model.pth\",  # Path to save the best model\n","    \"beta\": 1.0,  # Weight for KL divergence (VAE only)\n","    \"alpha\": 0.5,  # Weight for contrastive or triplet loss\n","    \"fraction\": 1.0,  # Fraction of the dataset to use\n","    \"projection_dim\": None,  # Optional projection head dimension for VAEs\n","    \"strong_architecture\": False,  # Whether to use a deeper architecture for DenoisingAutoencoder\n","    \"input_shape\": (1, 28, 28),  # Input shape for FlexibleVAE and ImprovedFlexibleVAE\n","    \"patience\": 8,\n","    \"min_delta\": 0.001,\n","    \"triplet_data\": False,\n","}\n","\n","# ------------------------------\n","# Step 2: Load and Preprocess Data\n","# ------------------------------\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","# mnist_loader = data_utils.load_mnist_data(fraction=config[\"fraction\"], batch_size=config[\"batch_size\"], shuffle=True)\n","\n","# # Inspect Combined Dataset\n","# for batch in mnist_loader:\n","#     images, labels = batch\n","#     print(\"Batch Shape:\", images.shape, labels.shape)\n","#     break\n","\n","# Visualize Original Images\n","n = 20\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n","\n","# ------------------------------\n","# Step 3: Initialize Model, Loss, and Optimizer\n","# ------------------------------\n","\n","# Initialize the model\n","# Initialize the model\n","model_classes = {\n","    \"BasicAutoencoder\": encoder_models.BasicAutoencoder,\n","    \"IntermediateAutoencoder\": encoder_models.IntermediateAutoencoder,\n","    \"AdvancedAutoencoder\": encoder_models.AdvancedAutoencoder,\n","    \"EnhancedAutoencoder\": encoder_models.EnhancedAutoencoder,\n","    \"BasicVAE\": encoder_models.BasicVAE,\n","    \"ImprovedVAE\": encoder_models.ImprovedVAE,\n","    \"FlexibleVAE\": encoder_models.FlexibleVAE,\n","    \"ImprovedFlexibleVAE\": encoder_models.ImprovedFlexibleVAE,\n","    \"DenoisingAutoencoder\": encoder_models.DenoisingAutoencoder,\n","}\n","\n","# Initialize model with appropriate arguments\n","if config[\"model_name\"] in [\"FlexibleVAE\", \"ImprovedFlexibleVAE\"]:\n","    model = model_classes[config[\"model_name\"]](\n","        input_shape=config[\"input_shape\"],\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"]\n","    ).to(config[\"device\"])\n","elif config[\"model_name\"] == \"DenoisingAutoencoder\":\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"],\n","        strong_architecture=config[\"strong_architecture\"]\n","    ).to(config[\"device\"])\n","else:\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"]\n","    ).to(config[\"device\"])\n","\n","# Define the loss function\n","if config[\"model_type\"] == \"vae\":\n","    criterion = losses.vae_loss  # Use VAE loss for VAEs\n","else:\n","    loss_functions = {\n","        \"mse\": nn.MSELoss(),  # Reconstruction loss\n","        \"vicreg\": cl_loss.VicRegLoss(lambda_var=25, mu_mean=25, nu_cov=1),  # VicReg loss\n","        \"ntxent\": cl_loss.NTXentLoss(temperature=config[\"temperature\"]),  # NT-Xent loss\n","        \"triplet\": cl_loss.TripletLoss(margin=config[\"margin\"]),  # Triplet loss\n","        \"contrastive\": cl_loss.contrastive_loss,  # Basic contrastive loss\n","        \"info_nce\": cl_loss.info_nce_loss,  # InfoNCE loss\n","        \"barlow_twins\": cl_loss.BarlowTwinsLoss(lambda_param=5e-3),  # Barlow Twins loss\n","        \"byol\": cl_loss.BYOLLoss(),  # BYOL loss\n","    }\n","    criterion = loss_functions[config[\"loss_type\"]]\n","\n","predictor = cl_loss.Predictor(input_dim=config[\"code_dim\"]).to(config[\"device\"])\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Define scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","\n","# ------------------------------\n","# Step 4: Train the Model\n","# ------------------------------\n","\n","if config[\"model_type\"] == \"autoencoder\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_autoencoder_v4(\n","        model=model,\n","        data_loader=mnist_loader,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        optimizer=optimizer,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        scheduler=scheduler,\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        temperature=config[\"temperature\"],  # Pass temperature for NT-Xent, contrastive, and InfoNCE\n","        triplet_data=(config[\"loss_type\"] == \"triplet\"),  # Enable triplet data only for triplet loss\n","        augment_fn=cl_loss.augment if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        predictor=predictor if config[\"loss_type\"] == \"byol\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"vae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_vae(\n","        vae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,  # VAE loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        beta=config[\"beta\"],  # Weight for KL divergence\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"dae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_dae(\n","        dae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        noise_factor=config[\"noise_factor\"],  # Noise factor for denoising\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        triplet_loss_fn=criterion if config[\"loss_type\"] == \"triplet\" else None,\n","        ssim_func=losses.ssim if config[\"loss_type\"] == \"ssim\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","# ------------------------------\n","# Step 5: Save Embeddings and Model\n","# ------------------------------\n","\n","# Generate embeddings\n","embeddings, labels = data_utils.generate_embeddings(\n","    model=model,\n","    embedding_type=config[\"model_type\"],\n","    data_loader=mnist_loader,\n","    device=config[\"device\"],\n",")\n","\n","# Define the base storage directory for embeddings\n","base_dir = \"./saved_embeddings\"\n","os.makedirs(base_dir, exist_ok=True)\n","\n","# Ensure a dedicated directory for embeddings\n","embeddings_dir = os.path.join(base_dir, \"embeddings\")\n","os.makedirs(embeddings_dir, exist_ok=True)\n","\n","# Create a unique subdirectory for this embedding type, model, and loss type\n","embedding_subdir = f\"{config['model_type']}_{config['model_name']}_{config['loss_type']}\"\n","embedding_dir = os.path.join(embeddings_dir, embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","# Choose saving format: default is .pt, but .npy can be chosen\n","save_format = \"pt\"  # Change to \"npy\" for NumPy format\n","\n","# Save embeddings with differentiated names based on the model, loss type, and embedding type\n","if save_format == \"pt\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.pt\")\n","    torch.save({\"embeddings\": embeddings, \"labels\": labels}, embedding_file)\n","    print(f\"Embeddings saved in PyTorch format: {embedding_file}\")\n","elif save_format == \"npy\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.npy\")\n","    np.save(embedding_file, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    print(f\"Embeddings saved in NumPy format: {embedding_file}\")\n","else:\n","    raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# Save the model\n","model_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}.pth\")\n","torch.save(model.state_dict(), model_file)\n","print(f\"Model saved: {model_file}\")\n","\n","# ------------------------------\n","# Step 6: Visualize Embeddings\n","# ------------------------------\n","\n","# Visualize embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":998},"id":"ar0AchmQdst3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sampled Dataset: (70000, 1, 28, 28) (70000,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 2000x400 with 20 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training IntermediateAutoencoder with contrastive loss...\n","Epoch [1/50], Train Loss: 2.6596\n","Epoch [2/50], Train Loss: 2.5498\n","Epoch [3/50], Train Loss: 2.5281\n","Epoch [4/50], Train Loss: 2.5176\n","Epoch [5/50], Train Loss: 2.5109\n","Epoch [6/50], Train Loss: 2.5068\n","Epoch [7/50], Train Loss: 2.5040\n","Epoch [8/50], Train Loss: 2.5018\n","Epoch [9/50], Train Loss: 2.4592\n","Epoch [10/50], Train Loss: 2.3229\n","Epoch [11/50], Train Loss: 2.3217\n","Epoch [12/50], Train Loss: 2.3204\n","Epoch [13/50], Train Loss: 2.3185\n","Epoch [14/50], Train Loss: 2.3169\n","Epoch [15/50], Train Loss: 2.3160\n","Epoch [16/50], Train Loss: 2.3150\n","Epoch [17/50], Train Loss: 2.3139\n","Epoch [18/50], Train Loss: 2.3134\n","Epoch [19/50], Train Loss: 2.3125\n","Epoch [20/50], Train Loss: 2.3116\n","Epoch [21/50], Train Loss: 2.3063\n","Epoch [22/50], Train Loss: 2.3059\n","Epoch [23/50], Train Loss: 2.3053\n","Epoch [24/50], Train Loss: 2.3051\n","Epoch [25/50], Train Loss: 2.3050\n","Epoch [26/50], Train Loss: 2.3051\n","Epoch [27/50], Train Loss: 2.3047\n","Epoch [28/50], Train Loss: 2.3046\n","Epoch [29/50], Train Loss: 2.3046\n","Epoch [30/50], Train Loss: 2.3046\n","Epoch [31/50], Train Loss: 2.3042\n","Epoch [32/50], Train Loss: 2.3043\n","Epoch [33/50], Train Loss: 2.3043\n","Epoch [34/50], Train Loss: 2.3040\n","Epoch [35/50], Train Loss: 2.3041\n","Epoch [36/50], Train Loss: 2.3041\n","Epoch [37/50], Train Loss: 2.3040\n","Epoch [38/50], Train Loss: 2.3038\n","Epoch [39/50], Train Loss: 2.3036\n","Early stopping triggered at epoch 39.\n","Embeddings saved in PyTorch format: ./saved_embeddings/embeddings/autoencoder_IntermediateAutoencoder_contrastive/IntermediateAutoencoder_contrastive_embeddings.pt\n","Model saved: ./saved_embeddings/embeddings/autoencoder_IntermediateAutoencoder_contrastive/IntermediateAutoencoder_contrastive.pth\n"]}],"source":["# ------------------------------\n","# Step 1: Define Configuration\n","# ------------------------------\n","\n","# Configuration\n","config = {\n","    \"model_type\": \"autoencoder\",  # Options: \"autoencoder\", \"vae\", \"dae\"\n","    \"model_name\": \"IntermediateAutoencoder\",  # Options: \"BasicAutoencoder\", \"IntermediateAutoencoder\", \"AdvancedAutoencoder\", \"EnhancedAutoencoder\", \"BasicVAE\", \"ImprovedVAE\", \"FlexibleVAE\", \"ImprovedFlexibleVAE\", \"DenoisingAutoencoder\"\n","    \"code_dim\": 50,  # Dimensionality of the embedding\n","    \"loss_type\": \"contrastive\",  # Options: \"mse\", \"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"\n","    \"noise_factor\": 0.1,  # Noise factor for denoising autoencoders\n","    \"temperature\": 0.5,  # Temperature parameter for NT-Xent loss\n","    \"margin\": 1.0,  # Margin for Triplet Loss\n","    \"epochs\": 50,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-3,\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"save_best\": True,  # Whether to save the best model\n","    \"save_path\": \"best_model.pth\",  # Path to save the best model\n","    \"beta\": 1.0,  # Weight for KL divergence (VAE only)\n","    \"alpha\": 0.5,  # Weight for contrastive or triplet loss\n","    \"fraction\": 1.0,  # Fraction of the dataset to use\n","    \"projection_dim\": None,  # Optional projection head dimension for VAEs\n","    \"strong_architecture\": False,  # Whether to use a deeper architecture for DenoisingAutoencoder\n","    \"input_shape\": (1, 28, 28),  # Input shape for FlexibleVAE and ImprovedFlexibleVAE\n","    \"patience\": 8,\n","    \"min_delta\": 0.001,\n","    \"triplet_data\": False,\n","}\n","\n","# ------------------------------\n","# Step 2: Load and Preprocess Data\n","# ------------------------------\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=config[\"fraction\"], batch_size=config[\"batch_size\"], shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 20\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n","\n","# ------------------------------\n","# Step 3: Initialize Model, Loss, and Optimizer\n","# ------------------------------\n","\n","# Initialize the model\n","# Initialize the model\n","model_classes = {\n","    \"BasicAutoencoder\": encoder_models.BasicAutoencoder,\n","    \"IntermediateAutoencoder\": encoder_models.IntermediateAutoencoder,\n","    \"AdvancedAutoencoder\": encoder_models.AdvancedAutoencoder,\n","    \"EnhancedAutoencoder\": encoder_models.EnhancedAutoencoder,\n","    \"BasicVAE\": encoder_models.BasicVAE,\n","    \"ImprovedVAE\": encoder_models.ImprovedVAE,\n","    \"FlexibleVAE\": encoder_models.FlexibleVAE,\n","    \"ImprovedFlexibleVAE\": encoder_models.ImprovedFlexibleVAE,\n","    \"DenoisingAutoencoder\": encoder_models.DenoisingAutoencoder,\n","}\n","\n","# Initialize model with appropriate arguments\n","if config[\"model_name\"] in [\"FlexibleVAE\", \"ImprovedFlexibleVAE\"]:\n","    model = model_classes[config[\"model_name\"]](\n","        input_shape=config[\"input_shape\"],\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"]\n","    ).to(config[\"device\"])\n","elif config[\"model_name\"] == \"DenoisingAutoencoder\":\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"],\n","        strong_architecture=config[\"strong_architecture\"]\n","    ).to(config[\"device\"])\n","else:\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"]\n","    ).to(config[\"device\"])\n","\n","# Define the loss function\n","if config[\"model_type\"] == \"vae\":\n","    criterion = losses.vae_loss  # Use VAE loss for VAEs\n","else:\n","    loss_functions = {\n","        \"mse\": nn.MSELoss(),  # Reconstruction loss\n","        \"vicreg\": cl_loss.VicRegLoss(lambda_var=25, mu_mean=25, nu_cov=1),  # VicReg loss\n","        \"ntxent\": cl_loss.NTXentLoss(temperature=config[\"temperature\"]),  # NT-Xent loss\n","        \"triplet\": cl_loss.TripletLoss(margin=config[\"margin\"]),  # Triplet loss\n","        \"contrastive\": cl_loss.contrastive_loss,  # Basic contrastive loss\n","        \"info_nce\": cl_loss.info_nce_loss,  # InfoNCE loss\n","        \"barlow_twins\": cl_loss.BarlowTwinsLoss(lambda_param=5e-3),  # Barlow Twins loss\n","        \"byol\": cl_loss.BYOLLoss(),  # BYOL loss\n","    }\n","    criterion = loss_functions[config[\"loss_type\"]]\n","\n","predictor = cl_loss.Predictor(input_dim=config[\"code_dim\"]).to(config[\"device\"])\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Define scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","\n","# ------------------------------\n","# Step 4: Train the Model\n","# ------------------------------\n","\n","if config[\"model_type\"] == \"autoencoder\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_autoencoder_v4(\n","        model=model,\n","        data_loader=mnist_loader,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        optimizer=optimizer,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        scheduler=scheduler,\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        temperature=config[\"temperature\"],  # Pass temperature for NT-Xent, contrastive, and InfoNCE\n","        triplet_data=(config[\"loss_type\"] == \"triplet\"),  # Enable triplet data only for triplet loss\n","        augment_fn=cl_loss.augment if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        predictor=predictor if config[\"loss_type\"] == \"byol\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"vae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_vae(\n","        vae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,  # VAE loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        beta=config[\"beta\"],  # Weight for KL divergence\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"dae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_dae(\n","        dae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        noise_factor=config[\"noise_factor\"],  # Noise factor for denoising\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        triplet_loss_fn=criterion if config[\"loss_type\"] == \"triplet\" else None,\n","        ssim_func=losses.ssim if config[\"loss_type\"] == \"ssim\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","# ------------------------------\n","# Step 5: Save Embeddings and Model\n","# ------------------------------\n","\n","# Generate embeddings\n","embeddings, labels = data_utils.generate_embeddings(\n","    model=model,\n","    embedding_type=config[\"model_type\"],\n","    data_loader=mnist_loader,\n","    device=config[\"device\"],\n",")\n","\n","# Define the base storage directory for embeddings\n","base_dir = \"./saved_embeddings\"\n","os.makedirs(base_dir, exist_ok=True)\n","\n","# Ensure a dedicated directory for embeddings\n","embeddings_dir = os.path.join(base_dir, \"embeddings\")\n","os.makedirs(embeddings_dir, exist_ok=True)\n","\n","# Create a unique subdirectory for this embedding type, model, and loss type\n","embedding_subdir = f\"{config['model_type']}_{config['model_name']}_{config['loss_type']}\"\n","embedding_dir = os.path.join(embeddings_dir, embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","# Choose saving format: default is .pt, but .npy can be chosen\n","save_format = \"pt\"  # Change to \"npy\" for NumPy format\n","\n","# Save embeddings with differentiated names based on the model, loss type, and embedding type\n","if save_format == \"pt\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.pt\")\n","    torch.save({\"embeddings\": embeddings, \"labels\": labels}, embedding_file)\n","    print(f\"Embeddings saved in PyTorch format: {embedding_file}\")\n","elif save_format == \"npy\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.npy\")\n","    np.save(embedding_file, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    print(f\"Embeddings saved in NumPy format: {embedding_file}\")\n","else:\n","    raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# Save the model\n","model_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}.pth\")\n","torch.save(model.state_dict(), model_file)\n","print(f\"Model saved: {model_file}\")\n","\n","# ------------------------------\n","# Step 6: Visualize Embeddings\n","# ------------------------------\n","\n","# Visualize embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39624,"status":"ok","timestamp":1737827138070,"user":{"displayName":"Farshad H","userId":"17155898055621377416"},"user_tz":-210},"id":"vvEe15hwu6wG","outputId":"538764f7-bb0f-483b-df1a-e6ec6f976c8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing matrix factorization models (PCA, SVD, NMF)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1742: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["PCA embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_PCA/matrix_factorization_default_loss_PCA_embeddings.pt\n","SVD embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_SVD/matrix_factorization_default_loss_SVD_embeddings.pt\n","NMF embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_NMF/matrix_factorization_default_loss_NMF_embeddings.pt\n","Processing SIFT features...\n","SIFT embeddings saved in PyTorch format: ./saved_embeddings/embeddings/sift_features/matrix_factorization_default_loss_sift_embeddings.pt\n","Processing Kernel PCA...\n","SIFT Kernel PCA embeddings saved in PyTorch format: ./saved_embeddings/embeddings/kernel_pca_SIFT/matrix_factorization_default_loss_kernel_pca_SIFT_embeddings.pt\n","Kernel PCA Kernel PCA embeddings saved in PyTorch format: ./saved_embeddings/embeddings/kernel_pca_Kernel PCA/matrix_factorization_default_loss_kernel_pca_Kernel PCA_embeddings.pt\n","Processing Normalizing Flow...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/100: 100%|██████████| 6/6 [00:00\u003c00:00, 36.57it/s, loss=2.07e+6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100, Loss: 3358708.4375\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/100: 100%|██████████| 6/6 [00:00\u003c00:00, 107.73it/s, loss=7.67e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/100, Loss: 2421180.1562\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/100: 100%|██████████| 6/6 [00:00\u003c00:00, 81.05it/s, loss=1.28e+6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/100, Loss: 1847919.9583\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.78it/s, loss=6.37e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/100, Loss: 1471227.9167\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/100: 100%|██████████| 6/6 [00:00\u003c00:00, 84.62it/s, loss=4.63e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/100, Loss: 1251132.6458\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/100: 100%|██████████| 6/6 [00:00\u003c00:00, 85.21it/s, loss=4.12e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/100, Loss: 1145675.3698\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/100: 100%|██████████| 6/6 [00:00\u003c00:00, 81.63it/s, loss=3.62e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/100, Loss: 964567.2292\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.97it/s, loss=3.18e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/100, Loss: 852232.8125\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/100: 100%|██████████| 6/6 [00:00\u003c00:00, 107.51it/s, loss=5.24e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/100, Loss: 773914.8542\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/100: 100%|██████████| 6/6 [00:00\u003c00:00, 106.12it/s, loss=3.87e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/100, Loss: 681183.7708\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/100: 100%|██████████| 6/6 [00:00\u003c00:00, 108.85it/s, loss=2.09e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/100, Loss: 597496.1615\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/100: 100%|██████████| 6/6 [00:00\u003c00:00, 97.27it/s, loss=4.3e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/100, Loss: 529674.9219\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/100: 100%|██████████| 6/6 [00:00\u003c00:00, 90.65it/s, loss=1.75e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/100, Loss: 479913.4297\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/100: 100%|██████████| 6/6 [00:00\u003c00:00, 101.71it/s, loss=3.19e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/100, Loss: 429102.1875\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/100: 100%|██████████| 6/6 [00:00\u003c00:00, 98.08it/s, loss=1.53e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/100, Loss: 394330.2578\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 16/100: 100%|██████████| 6/6 [00:00\u003c00:00, 86.20it/s, loss=1.97e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/100, Loss: 362477.1484\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 17/100: 100%|██████████| 6/6 [00:00\u003c00:00, 86.77it/s, loss=1.46e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/100, Loss: 340135.8021\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 18/100: 100%|██████████| 6/6 [00:00\u003c00:00, 70.91it/s, loss=1.18e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/100, Loss: 314237.1810\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 19/100: 100%|██████████| 6/6 [00:00\u003c00:00, 81.17it/s, loss=1.55e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/100, Loss: 291413.4427\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 20/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.56it/s, loss=1.56e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/100, Loss: 290707.3542\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 21/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.78it/s, loss=1.09e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21/100, Loss: 278803.9284\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 22/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.38it/s, loss=1.77e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22/100, Loss: 238892.1484\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 23/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.61it/s, loss=1.1e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23/100, Loss: 222431.6576\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 24/100: 100%|██████████| 6/6 [00:00\u003c00:00, 88.80it/s, loss=6.85e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24/100, Loss: 207214.7018\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 25/100: 100%|██████████| 6/6 [00:00\u003c00:00, 82.08it/s, loss=1.12e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25/100, Loss: 199458.5755\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 26/100: 100%|██████████| 6/6 [00:00\u003c00:00, 76.88it/s, loss=8.64e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 26/100, Loss: 186315.3945\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 27/100: 100%|██████████| 6/6 [00:00\u003c00:00, 87.14it/s, loss=8.48e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 27/100, Loss: 178262.0560\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 28/100: 100%|██████████| 6/6 [00:00\u003c00:00, 95.33it/s, loss=84156.0]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 28/100, Loss: 167682.5859\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 29/100: 100%|██████████| 6/6 [00:00\u003c00:00, 88.11it/s, loss=6.83e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 29/100, Loss: 160388.3893\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 30/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.89it/s, loss=6.82e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 30/100, Loss: 152936.5846\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 31/100: 100%|██████████| 6/6 [00:00\u003c00:00, 72.68it/s, loss=6.38e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 31/100, Loss: 145889.3184\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 32/100: 100%|██████████| 6/6 [00:00\u003c00:00, 82.38it/s, loss=7.9e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 32/100, Loss: 139763.9167\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 33/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.67it/s, loss=5.41e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 33/100, Loss: 133955.5905\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 34/100: 100%|██████████| 6/6 [00:00\u003c00:00, 78.86it/s, loss=8.38e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 34/100, Loss: 128101.5221\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 35/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.97it/s, loss=4.97e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 35/100, Loss: 122939.9733\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 36/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.57it/s, loss=6.21e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36/100, Loss: 118031.4922\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 37/100: 100%|██████████| 6/6 [00:00\u003c00:00, 86.68it/s, loss=5.16e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 37/100, Loss: 113217.8691\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 38/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.16it/s, loss=5.4e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 38/100, Loss: 108768.2956\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 39/100: 100%|██████████| 6/6 [00:00\u003c00:00, 102.11it/s, loss=4.5e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 39/100, Loss: 104747.7949\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 40/100: 100%|██████████| 6/6 [00:00\u003c00:00, 88.08it/s, loss=6.76e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 40/100, Loss: 100538.6341\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 41/100: 100%|██████████| 6/6 [00:00\u003c00:00, 78.83it/s, loss=4.37e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 41/100, Loss: 96904.3444\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 42/100: 100%|██████████| 6/6 [00:00\u003c00:00, 96.72it/s, loss=4.14e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 42/100, Loss: 93436.9753\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 43/100: 100%|██████████| 6/6 [00:00\u003c00:00, 86.00it/s, loss=5.47e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43/100, Loss: 89912.4876\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 44/100: 100%|██████████| 6/6 [00:00\u003c00:00, 98.62it/s, loss=5.63e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 44/100, Loss: 86996.9225\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 45/100: 100%|██████████| 6/6 [00:00\u003c00:00, 98.84it/s, loss=4.22e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 45/100, Loss: 84351.9759\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 46/100: 100%|██████████| 6/6 [00:00\u003c00:00, 101.57it/s, loss=4.32e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 46/100, Loss: 81205.8405\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 47/100: 100%|██████████| 6/6 [00:00\u003c00:00, 100.49it/s, loss=3.48e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 47/100, Loss: 78411.0033\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 48/100: 100%|██████████| 6/6 [00:00\u003c00:00, 98.18it/s, loss=3.65e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 48/100, Loss: 75849.1829\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 49/100: 100%|██████████| 6/6 [00:00\u003c00:00, 106.14it/s, loss=5.49e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 49/100, Loss: 73511.2305\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 50/100: 100%|██████████| 6/6 [00:00\u003c00:00, 100.09it/s, loss=3.21e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 50/100, Loss: 71467.8600\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 51/100: 100%|██████████| 6/6 [00:00\u003c00:00, 101.90it/s, loss=3.37e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 51/100, Loss: 69202.5221\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 52/100: 100%|██████████| 6/6 [00:00\u003c00:00, 100.43it/s, loss=4.22e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 52/100, Loss: 67169.2773\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 53/100: 100%|██████████| 6/6 [00:00\u003c00:00, 97.12it/s, loss=3.95e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 53/100, Loss: 65240.4076\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 54/100: 100%|██████████| 6/6 [00:00\u003c00:00, 81.58it/s, loss=2.94e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 54/100, Loss: 63348.4551\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 55/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.09it/s, loss=2.58e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 55/100, Loss: 61536.6569\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 56/100: 100%|██████████| 6/6 [00:00\u003c00:00, 88.40it/s, loss=2.49e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 56/100, Loss: 59762.9795\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 57/100: 100%|██████████| 6/6 [00:00\u003c00:00, 85.10it/s, loss=3.22e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 57/100, Loss: 58057.9798\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 58/100: 100%|██████████| 6/6 [00:00\u003c00:00, 64.33it/s, loss=2.43e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 58/100, Loss: 56409.8597\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 59/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.43it/s, loss=3.08e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 59/100, Loss: 54758.1706\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 60/100: 100%|██████████| 6/6 [00:00\u003c00:00, 85.89it/s, loss=3.06e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 60/100, Loss: 53477.2435\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 61/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.39it/s, loss=2.8e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 61/100, Loss: 51979.7142\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 62/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.17it/s, loss=2.42e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 62/100, Loss: 50955.9232\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 63/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.03it/s, loss=2.02e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 63/100, Loss: 50059.9313\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 64/100: 100%|██████████| 6/6 [00:00\u003c00:00, 76.10it/s, loss=2.37e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 64/100, Loss: 48892.0033\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 65/100: 100%|██████████| 6/6 [00:00\u003c00:00, 91.37it/s, loss=1.91e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 65/100, Loss: 47641.3688\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 66/100: 100%|██████████| 6/6 [00:00\u003c00:00, 75.20it/s, loss=2.54e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 66/100, Loss: 46573.9515\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 67/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.14it/s, loss=2.66e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 67/100, Loss: 45430.9251\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 68/100: 100%|██████████| 6/6 [00:00\u003c00:00, 37.63it/s, loss=2.1e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 68/100, Loss: 44408.0306\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 69/100: 100%|██████████| 6/6 [00:00\u003c00:00, 39.11it/s, loss=2.15e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 69/100, Loss: 43342.6315\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 70/100: 100%|██████████| 6/6 [00:00\u003c00:00, 33.69it/s, loss=2.1e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 70/100, Loss: 42381.0215\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 71/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.35it/s, loss=2.09e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 71/100, Loss: 41489.6631\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 72/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.82it/s, loss=2.54e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 72/100, Loss: 40590.6426\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 73/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.55it/s, loss=2e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 73/100, Loss: 39775.6618\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 74/100: 100%|██████████| 6/6 [00:00\u003c00:00, 42.54it/s, loss=1.95e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 74/100, Loss: 38931.5667\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 75/100: 100%|██████████| 6/6 [00:00\u003c00:00, 62.28it/s, loss=2.07e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 75/100, Loss: 38064.4867\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 76/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.66it/s, loss=1.72e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 76/100, Loss: 37216.5501\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 77/100: 100%|██████████| 6/6 [00:00\u003c00:00, 67.33it/s, loss=1.55e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 77/100, Loss: 36429.3504\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 78/100: 100%|██████████| 6/6 [00:00\u003c00:00, 65.46it/s, loss=1.9e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 78/100, Loss: 35686.0915\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 79/100: 100%|██████████| 6/6 [00:00\u003c00:00, 66.23it/s, loss=1.75e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 79/100, Loss: 34992.1217\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 80/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.96it/s, loss=1.41e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 80/100, Loss: 34316.6235\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 81/100: 100%|██████████| 6/6 [00:00\u003c00:00, 86.02it/s, loss=2.1e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 81/100, Loss: 33686.7214\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 82/100: 100%|██████████| 6/6 [00:00\u003c00:00, 61.38it/s, loss=1.78e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 82/100, Loss: 33068.7715\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 83/100: 100%|██████████| 6/6 [00:00\u003c00:00, 20.25it/s, loss=1.6e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 83/100, Loss: 32472.2646\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 84/100: 100%|██████████| 6/6 [00:00\u003c00:00, 26.08it/s, loss=1.47e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 84/100, Loss: 31874.8514\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 85/100: 100%|██████████| 6/6 [00:00\u003c00:00, 44.20it/s, loss=1.74e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 85/100, Loss: 31250.9049\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 86/100: 100%|██████████| 6/6 [00:00\u003c00:00, 56.69it/s, loss=1.4e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 86/100, Loss: 30678.5666\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 87/100: 100%|██████████| 6/6 [00:00\u003c00:00, 49.20it/s, loss=1.55e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 87/100, Loss: 30157.6507\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 88/100: 100%|██████████| 6/6 [00:00\u003c00:00, 62.85it/s, loss=1.66e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 88/100, Loss: 29618.8926\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 89/100: 100%|██████████| 6/6 [00:00\u003c00:00, 48.00it/s, loss=1.54e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 89/100, Loss: 29256.7609\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 90/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.49it/s, loss=1.47e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 90/100, Loss: 28672.9494\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 91/100: 100%|██████████| 6/6 [00:00\u003c00:00, 52.99it/s, loss=1.65e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 91/100, Loss: 28188.0859\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 92/100: 100%|██████████| 6/6 [00:00\u003c00:00, 63.30it/s, loss=1.39e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 92/100, Loss: 27735.6774\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 93/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.98it/s, loss=1.47e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 93/100, Loss: 27292.6880\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 94/100: 100%|██████████| 6/6 [00:00\u003c00:00, 53.58it/s, loss=1.34e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 94/100, Loss: 26823.1232\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 95/100: 100%|██████████| 6/6 [00:00\u003c00:00, 52.85it/s, loss=1.24e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 95/100, Loss: 26418.6688\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 96/100: 100%|██████████| 6/6 [00:00\u003c00:00, 78.69it/s, loss=1.34e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 96/100, Loss: 26004.0822\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 97/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.10it/s, loss=1.19e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 97/100, Loss: 25667.7428\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 98/100: 100%|██████████| 6/6 [00:00\u003c00:00, 93.44it/s, loss=1e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 98/100, Loss: 25269.3530\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 99/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.91it/s, loss=1.22e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 99/100, Loss: 24884.7345\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 100/100: 100%|██████████| 6/6 [00:00\u003c00:00, 93.22it/s, loss=1.12e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100/100, Loss: 24520.1574\n","PCA refined embeddings (Normalizing Flow) saved in PyTorch format: ./saved_embeddings/embeddings/normalizing_flow_PCA/matrix_factorization_default_loss_normalizing_flow_PCA_refined_embeddings.pt\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/100: 100%|██████████| 6/6 [00:00\u003c00:00, 62.82it/s, loss=2.08e+6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100, Loss: 3476399.4792\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.00it/s, loss=1.56e+6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/100, Loss: 2232664.2917\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.20it/s, loss=6.75e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/100, Loss: 1731757.9583\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.65it/s, loss=5.32e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/100, Loss: 1374345.9583\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.23it/s, loss=6.47e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/100, Loss: 1154157.3229\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/100: 100%|██████████| 6/6 [00:00\u003c00:00, 52.86it/s, loss=4.06e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/100, Loss: 1002222.1562\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/100: 100%|██████████| 6/6 [00:00\u003c00:00, 70.09it/s, loss=3.98e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/100, Loss: 871659.7708\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/100: 100%|██████████| 6/6 [00:00\u003c00:00, 96.65it/s, loss=7.52e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/100, Loss: 752746.9271\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/100: 100%|██████████| 6/6 [00:00\u003c00:00, 101.07it/s, loss=3.16e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/100, Loss: 660082.9740\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/100: 100%|██████████| 6/6 [00:00\u003c00:00, 93.56it/s, loss=4e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/100, Loss: 570510.6094\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/100: 100%|██████████| 6/6 [00:00\u003c00:00, 59.93it/s, loss=1.84e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/100, Loss: 513269.3698\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/100: 100%|██████████| 6/6 [00:00\u003c00:00, 60.39it/s, loss=1.77e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/100, Loss: 475452.8255\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/100: 100%|██████████| 6/6 [00:00\u003c00:00, 55.10it/s, loss=3.09e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/100, Loss: 447217.4948\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/100: 100%|██████████| 6/6 [00:00\u003c00:00, 67.40it/s, loss=2.05e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/100, Loss: 410697.2370\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/100: 100%|██████████| 6/6 [00:00\u003c00:00, 76.08it/s, loss=1.29e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/100, Loss: 380160.4831\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 16/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.95it/s, loss=1.76e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/100, Loss: 353773.5755\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 17/100: 100%|██████████| 6/6 [00:00\u003c00:00, 96.36it/s, loss=1.02e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/100, Loss: 326704.5495\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 18/100: 100%|██████████| 6/6 [00:00\u003c00:00, 67.90it/s, loss=1.3e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/100, Loss: 304544.5716\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 19/100: 100%|██████████| 6/6 [00:00\u003c00:00, 67.49it/s, loss=1.16e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/100, Loss: 284459.7096\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 20/100: 100%|██████████| 6/6 [00:00\u003c00:00, 66.10it/s, loss=2.43e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/100, Loss: 266055.6562\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 21/100: 100%|██████████| 6/6 [00:00\u003c00:00, 54.80it/s, loss=1.03e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21/100, Loss: 254308.7018\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 22/100: 100%|██████████| 6/6 [00:00\u003c00:00, 48.67it/s, loss=1.84e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22/100, Loss: 239262.2630\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 23/100: 100%|██████████| 6/6 [00:00\u003c00:00, 59.76it/s, loss=1.24e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23/100, Loss: 224476.8216\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 24/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.46it/s, loss=1.3e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24/100, Loss: 211794.5508\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 25/100: 100%|██████████| 6/6 [00:00\u003c00:00, 50.80it/s, loss=1.08e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25/100, Loss: 201029.0560\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 26/100: 100%|██████████| 6/6 [00:00\u003c00:00, 56.51it/s, loss=1.66e+5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 26/100, Loss: 190888.8880\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 27/100: 100%|██████████| 6/6 [00:00\u003c00:00, 61.48it/s, loss=8.63e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 27/100, Loss: 180271.5052\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 28/100: 100%|██████████| 6/6 [00:00\u003c00:00, 55.47it/s, loss=7.32e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 28/100, Loss: 169998.5768\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 29/100: 100%|██████████| 6/6 [00:00\u003c00:00, 63.53it/s, loss=7.59e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 29/100, Loss: 161238.2878\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 30/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.84it/s, loss=7.11e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 30/100, Loss: 152895.3880\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 31/100: 100%|██████████| 6/6 [00:00\u003c00:00, 66.66it/s, loss=6.26e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 31/100, Loss: 146677.0345\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 32/100: 100%|██████████| 6/6 [00:00\u003c00:00, 72.11it/s, loss=5.86e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 32/100, Loss: 140104.4850\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 33/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.64it/s, loss=6.66e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 33/100, Loss: 133945.3633\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 34/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.95it/s, loss=8.75e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 34/100, Loss: 128261.6693\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 35/100: 100%|██████████| 6/6 [00:00\u003c00:00, 66.55it/s, loss=5.83e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 35/100, Loss: 123280.9766\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 36/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.08it/s, loss=5.8e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36/100, Loss: 118371.5436\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 37/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.43it/s, loss=5.43e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 37/100, Loss: 112770.4167\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 38/100: 100%|██████████| 6/6 [00:00\u003c00:00, 84.23it/s, loss=5.61e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 38/100, Loss: 107955.6016\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 39/100: 100%|██████████| 6/6 [00:00\u003c00:00, 72.73it/s, loss=6.32e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 39/100, Loss: 104104.2760\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 40/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.99it/s, loss=6e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 40/100, Loss: 100195.2259\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 41/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.22it/s, loss=3.73e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 41/100, Loss: 96786.6764\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 42/100: 100%|██████████| 6/6 [00:00\u003c00:00, 59.82it/s, loss=4.32e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 42/100, Loss: 93491.1556\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 43/100: 100%|██████████| 6/6 [00:00\u003c00:00, 52.13it/s, loss=4.7e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43/100, Loss: 90280.1823\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 44/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.61it/s, loss=3.57e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 44/100, Loss: 87283.3919\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 45/100: 100%|██████████| 6/6 [00:00\u003c00:00, 51.36it/s, loss=4.86e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 45/100, Loss: 84214.1432\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 46/100: 100%|██████████| 6/6 [00:00\u003c00:00, 45.16it/s, loss=4.24e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 46/100, Loss: 81449.0169\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 47/100: 100%|██████████| 6/6 [00:00\u003c00:00, 53.82it/s, loss=4.4e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 47/100, Loss: 78686.7493\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 48/100: 100%|██████████| 6/6 [00:00\u003c00:00, 49.13it/s, loss=3.66e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 48/100, Loss: 76305.7148\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 49/100: 100%|██████████| 6/6 [00:00\u003c00:00, 45.37it/s, loss=4.12e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 49/100, Loss: 74161.8496\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 50/100: 100%|██████████| 6/6 [00:00\u003c00:00, 62.79it/s, loss=2.79e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 50/100, Loss: 71662.7679\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 51/100: 100%|██████████| 6/6 [00:00\u003c00:00, 61.12it/s, loss=3.88e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 51/100, Loss: 69514.7181\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 52/100: 100%|██████████| 6/6 [00:00\u003c00:00, 62.31it/s, loss=3.6e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 52/100, Loss: 67427.9486\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 53/100: 100%|██████████| 6/6 [00:00\u003c00:00, 56.26it/s, loss=3.16e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 53/100, Loss: 65497.0153\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 54/100: 100%|██████████| 6/6 [00:00\u003c00:00, 56.25it/s, loss=3.66e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 54/100, Loss: 63725.0111\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 55/100: 100%|██████████| 6/6 [00:00\u003c00:00, 55.93it/s, loss=2.57e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 55/100, Loss: 61889.7406\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 56/100: 100%|██████████| 6/6 [00:00\u003c00:00, 59.47it/s, loss=2.9e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 56/100, Loss: 59982.8893\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 57/100: 100%|██████████| 6/6 [00:00\u003c00:00, 75.87it/s, loss=2.84e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 57/100, Loss: 58352.9840\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 58/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.96it/s, loss=2.72e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 58/100, Loss: 56761.4736\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 59/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.44it/s, loss=2.9e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 59/100, Loss: 55969.0863\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 60/100: 100%|██████████| 6/6 [00:00\u003c00:00, 62.60it/s, loss=3.19e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 60/100, Loss: 53836.5290\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 61/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.14it/s, loss=2.57e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 61/100, Loss: 52827.3542\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 62/100: 100%|██████████| 6/6 [00:00\u003c00:00, 87.05it/s, loss=2.97e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 62/100, Loss: 51918.7848\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 63/100: 100%|██████████| 6/6 [00:00\u003c00:00, 95.57it/s, loss=2.6e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 63/100, Loss: 50376.6755\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 64/100: 100%|██████████| 6/6 [00:00\u003c00:00, 94.71it/s, loss=2.39e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 64/100, Loss: 49123.5387\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 65/100: 100%|██████████| 6/6 [00:00\u003c00:00, 88.39it/s, loss=2.58e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 65/100, Loss: 48050.8206\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 66/100: 100%|██████████| 6/6 [00:00\u003c00:00, 90.02it/s, loss=2.41e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 66/100, Loss: 47204.7093\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 67/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.96it/s, loss=2.05e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 67/100, Loss: 46150.4261\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 68/100: 100%|██████████| 6/6 [00:00\u003c00:00, 98.69it/s, loss=1.93e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 68/100, Loss: 44750.4255\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 69/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.57it/s, loss=2.01e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 69/100, Loss: 43776.3197\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 70/100: 100%|██████████| 6/6 [00:00\u003c00:00, 90.99it/s, loss=2.4e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 70/100, Loss: 42728.7539\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 71/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.06it/s, loss=2.15e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 71/100, Loss: 41675.0814\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 72/100: 100%|██████████| 6/6 [00:00\u003c00:00, 86.01it/s, loss=2.63e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 72/100, Loss: 40755.0560\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 73/100: 100%|██████████| 6/6 [00:00\u003c00:00, 84.84it/s, loss=2.17e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 73/100, Loss: 39786.0166\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 74/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.13it/s, loss=2.39e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 74/100, Loss: 38890.6956\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 75/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.25it/s, loss=2.21e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 75/100, Loss: 38174.7100\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 76/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.14it/s, loss=1.82e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 76/100, Loss: 37380.4066\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 77/100: 100%|██████████| 6/6 [00:00\u003c00:00, 76.36it/s, loss=1.71e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 77/100, Loss: 36571.8333\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 78/100: 100%|██████████| 6/6 [00:00\u003c00:00, 82.04it/s, loss=2.16e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 78/100, Loss: 35875.1862\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 79/100: 100%|██████████| 6/6 [00:00\u003c00:00, 84.06it/s, loss=1.8e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 79/100, Loss: 35155.3327\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 80/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.75it/s, loss=1.57e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 80/100, Loss: 34465.4357\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 81/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.48it/s, loss=1.96e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 81/100, Loss: 33816.9616\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 82/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.71it/s, loss=1.55e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 82/100, Loss: 33184.0052\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 83/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.50it/s, loss=1.84e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 83/100, Loss: 32639.7604\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 84/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.26it/s, loss=1.56e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 84/100, Loss: 31944.7549\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 85/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.83it/s, loss=1.5e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 85/100, Loss: 31447.3758\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 86/100: 100%|██████████| 6/6 [00:00\u003c00:00, 66.06it/s, loss=1.2e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 86/100, Loss: 30878.4017\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 87/100: 100%|██████████| 6/6 [00:00\u003c00:00, 81.37it/s, loss=1.42e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 87/100, Loss: 30201.3438\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 88/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.89it/s, loss=1.68e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 88/100, Loss: 29612.4339\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 89/100: 100%|██████████| 6/6 [00:00\u003c00:00, 78.99it/s, loss=1.2e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 89/100, Loss: 29501.9725\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 90/100: 100%|██████████| 6/6 [00:00\u003c00:00, 84.50it/s, loss=1.59e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 90/100, Loss: 28635.2629\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 91/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.83it/s, loss=1.37e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 91/100, Loss: 28175.1416\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 92/100: 100%|██████████| 6/6 [00:00\u003c00:00, 90.08it/s, loss=1.4e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 92/100, Loss: 27737.5150\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 93/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.30it/s, loss=1.64e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 93/100, Loss: 27284.9798\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 94/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.94it/s, loss=1.7e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 94/100, Loss: 26764.5384\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 95/100: 100%|██████████| 6/6 [00:00\u003c00:00, 88.07it/s, loss=1.33e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 95/100, Loss: 26326.0921\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 96/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.48it/s, loss=1.38e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 96/100, Loss: 25885.9212\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 97/100: 100%|██████████| 6/6 [00:00\u003c00:00, 91.90it/s, loss=1.31e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 97/100, Loss: 25453.7109\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 98/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.13it/s, loss=1.25e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 98/100, Loss: 25096.5645\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 99/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.99it/s, loss=1.27e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 99/100, Loss: 24671.2078\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 100/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.35it/s, loss=1.07e+4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100/100, Loss: 24279.7354\n","SVD refined embeddings (Normalizing Flow) saved in PyTorch format: ./saved_embeddings/embeddings/normalizing_flow_SVD/matrix_factorization_default_loss_normalizing_flow_SVD_refined_embeddings.pt\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.14it/s, loss=2.79e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100, Loss: 5481.5284\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/100: 100%|██████████| 6/6 [00:00\u003c00:00, 64.04it/s, loss=2.77e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/100, Loss: 5404.8086\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/100: 100%|██████████| 6/6 [00:00\u003c00:00, 58.94it/s, loss=2.76e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/100, Loss: 5382.3698\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/100: 100%|██████████| 6/6 [00:00\u003c00:00, 63.56it/s, loss=2.76e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/100, Loss: 5372.2974\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.17it/s, loss=2.75e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/100, Loss: 5366.1206\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.75it/s, loss=2.75e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/100, Loss: 5361.5289\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.90it/s, loss=2.75e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/100, Loss: 5357.6661\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.13it/s, loss=2.74e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/100, Loss: 5353.7866\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.88it/s, loss=2.74e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/100, Loss: 5349.8460\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/100: 100%|██████████| 6/6 [00:00\u003c00:00, 87.67it/s, loss=2.74e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/100, Loss: 5346.0431\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/100: 100%|██████████| 6/6 [00:00\u003c00:00, 87.27it/s, loss=2.73e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/100, Loss: 5342.1610\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/100: 100%|██████████| 6/6 [00:00\u003c00:00, 95.36it/s, loss=2.73e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/100, Loss: 5338.1427\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/100: 100%|██████████| 6/6 [00:00\u003c00:00, 94.98it/s, loss=2.72e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/100, Loss: 5333.9820\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/100: 100%|██████████| 6/6 [00:00\u003c00:00, 87.08it/s, loss=2.72e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/100, Loss: 5329.7205\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.42it/s, loss=2.71e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/100, Loss: 5325.4141\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 16/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.59it/s, loss=2.71e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/100, Loss: 5320.9227\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 17/100: 100%|██████████| 6/6 [00:00\u003c00:00, 85.12it/s, loss=2.7e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/100, Loss: 5316.5645\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 18/100: 100%|██████████| 6/6 [00:00\u003c00:00, 101.20it/s, loss=2.7e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/100, Loss: 5312.2836\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 19/100: 100%|██████████| 6/6 [00:00\u003c00:00, 98.18it/s, loss=2.69e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/100, Loss: 5308.1126\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 20/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.22it/s, loss=2.69e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/100, Loss: 5304.1874\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 21/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.24it/s, loss=2.69e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21/100, Loss: 5300.5734\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 22/100: 100%|██████████| 6/6 [00:00\u003c00:00, 58.74it/s, loss=2.68e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22/100, Loss: 5297.0206\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 23/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.25it/s, loss=2.68e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23/100, Loss: 5293.8883\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 24/100: 100%|██████████| 6/6 [00:00\u003c00:00, 75.82it/s, loss=2.68e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24/100, Loss: 5291.0549\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 25/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.18it/s, loss=2.68e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25/100, Loss: 5288.3103\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 26/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.99it/s, loss=2.67e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 26/100, Loss: 5285.7412\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 27/100: 100%|██████████| 6/6 [00:00\u003c00:00, 63.96it/s, loss=2671.0]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 27/100, Loss: 5283.6004\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 28/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.36it/s, loss=2.67e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 28/100, Loss: 5281.5013\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 29/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.22it/s, loss=2.67e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 29/100, Loss: 5279.4812\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 30/100: 100%|██████████| 6/6 [00:00\u003c00:00, 72.18it/s, loss=2.66e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 30/100, Loss: 5277.4419\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 31/100: 100%|██████████| 6/6 [00:00\u003c00:00, 72.50it/s, loss=2.66e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 31/100, Loss: 5275.3955\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 32/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.08it/s, loss=2.66e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 32/100, Loss: 5274.0279\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 33/100: 100%|██████████| 6/6 [00:00\u003c00:00, 57.03it/s, loss=2.66e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 33/100, Loss: 5272.2230\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 34/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.10it/s, loss=2.66e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 34/100, Loss: 5270.9952\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 35/100: 100%|██████████| 6/6 [00:00\u003c00:00, 75.47it/s, loss=2.66e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 35/100, Loss: 5269.2483\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 36/100: 100%|██████████| 6/6 [00:00\u003c00:00, 78.36it/s, loss=2.66e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36/100, Loss: 5267.7466\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 37/100: 100%|██████████| 6/6 [00:00\u003c00:00, 63.77it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 37/100, Loss: 5266.2290\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 38/100: 100%|██████████| 6/6 [00:00\u003c00:00, 62.62it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 38/100, Loss: 5264.7682\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 39/100: 100%|██████████| 6/6 [00:00\u003c00:00, 60.70it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 39/100, Loss: 5263.9369\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 40/100: 100%|██████████| 6/6 [00:00\u003c00:00, 72.14it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 40/100, Loss: 5262.7376\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 41/100: 100%|██████████| 6/6 [00:00\u003c00:00, 85.72it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 41/100, Loss: 5261.9191\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 42/100: 100%|██████████| 6/6 [00:00\u003c00:00, 99.15it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 42/100, Loss: 5260.7370\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 43/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.84it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43/100, Loss: 5260.1261\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 44/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.98it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 44/100, Loss: 5259.3719\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 45/100: 100%|██████████| 6/6 [00:00\u003c00:00, 93.36it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 45/100, Loss: 5258.0825\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 46/100: 100%|██████████| 6/6 [00:00\u003c00:00, 82.31it/s, loss=2.65e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 46/100, Loss: 5256.9305\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 47/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.17it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 47/100, Loss: 5255.8656\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 48/100: 100%|██████████| 6/6 [00:00\u003c00:00, 93.50it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 48/100, Loss: 5254.9724\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 49/100: 100%|██████████| 6/6 [00:00\u003c00:00, 92.43it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 49/100, Loss: 5254.1268\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 50/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.89it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 50/100, Loss: 5253.2002\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 51/100: 100%|██████████| 6/6 [00:00\u003c00:00, 91.22it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 51/100, Loss: 5252.3311\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 52/100: 100%|██████████| 6/6 [00:00\u003c00:00, 94.59it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 52/100, Loss: 5251.4462\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 53/100: 100%|██████████| 6/6 [00:00\u003c00:00, 76.94it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 53/100, Loss: 5250.8895\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 54/100: 100%|██████████| 6/6 [00:00\u003c00:00, 78.04it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 54/100, Loss: 5249.9297\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 55/100: 100%|██████████| 6/6 [00:00\u003c00:00, 54.49it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 55/100, Loss: 5249.3018\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 56/100: 100%|██████████| 6/6 [00:00\u003c00:00, 60.37it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 56/100, Loss: 5248.7972\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 57/100: 100%|██████████| 6/6 [00:00\u003c00:00, 79.02it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 57/100, Loss: 5248.2872\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 58/100: 100%|██████████| 6/6 [00:00\u003c00:00, 77.09it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 58/100, Loss: 5247.6230\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 59/100: 100%|██████████| 6/6 [00:00\u003c00:00, 65.58it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 59/100, Loss: 5246.6736\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 60/100: 100%|██████████| 6/6 [00:00\u003c00:00, 78.44it/s, loss=2.64e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 60/100, Loss: 5245.9157\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 61/100: 100%|██████████| 6/6 [00:00\u003c00:00, 87.90it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 61/100, Loss: 5245.1157\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 62/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.40it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 62/100, Loss: 5244.4133\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 63/100: 100%|██████████| 6/6 [00:00\u003c00:00, 76.92it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 63/100, Loss: 5243.6681\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 64/100: 100%|██████████| 6/6 [00:00\u003c00:00, 82.00it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 64/100, Loss: 5243.2593\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 65/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.81it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 65/100, Loss: 5242.4785\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 66/100: 100%|██████████| 6/6 [00:00\u003c00:00, 80.08it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 66/100, Loss: 5242.2761\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 67/100: 100%|██████████| 6/6 [00:00\u003c00:00, 82.22it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 67/100, Loss: 5241.4966\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 68/100: 100%|██████████| 6/6 [00:00\u003c00:00, 81.40it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 68/100, Loss: 5241.1039\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 69/100: 100%|██████████| 6/6 [00:00\u003c00:00, 74.35it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 69/100, Loss: 5240.3432\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 70/100: 100%|██████████| 6/6 [00:00\u003c00:00, 52.05it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 70/100, Loss: 5239.9497\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 71/100: 100%|██████████| 6/6 [00:00\u003c00:00, 50.46it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 71/100, Loss: 5239.4091\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 72/100: 100%|██████████| 6/6 [00:00\u003c00:00, 83.70it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 72/100, Loss: 5238.9976\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 73/100: 100%|██████████| 6/6 [00:00\u003c00:00, 75.53it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 73/100, Loss: 5238.3294\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 74/100: 100%|██████████| 6/6 [00:00\u003c00:00, 71.03it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 74/100, Loss: 5237.7444\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 75/100: 100%|██████████| 6/6 [00:00\u003c00:00, 67.13it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 75/100, Loss: 5237.0498\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 76/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.47it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 76/100, Loss: 5236.5045\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 77/100: 100%|██████████| 6/6 [00:00\u003c00:00, 54.81it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 77/100, Loss: 5236.2478\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 78/100: 100%|██████████| 6/6 [00:00\u003c00:00, 51.66it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 78/100, Loss: 5235.8320\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 79/100: 100%|██████████| 6/6 [00:00\u003c00:00, 57.70it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 79/100, Loss: 5235.3754\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 80/100: 100%|██████████| 6/6 [00:00\u003c00:00, 73.04it/s, loss=2.63e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 80/100, Loss: 5235.5533\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 81/100: 100%|██████████| 6/6 [00:00\u003c00:00, 87.32it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 81/100, Loss: 5234.9341\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 82/100: 100%|██████████| 6/6 [00:00\u003c00:00, 67.83it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 82/100, Loss: 5234.5599\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 83/100: 100%|██████████| 6/6 [00:00\u003c00:00, 67.34it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 83/100, Loss: 5234.6737\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 84/100: 100%|██████████| 6/6 [00:00\u003c00:00, 68.45it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 84/100, Loss: 5234.3649\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 85/100: 100%|██████████| 6/6 [00:00\u003c00:00, 59.59it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 85/100, Loss: 5233.7415\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 86/100: 100%|██████████| 6/6 [00:00\u003c00:00, 58.64it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 86/100, Loss: 5233.3593\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 87/100: 100%|██████████| 6/6 [00:00\u003c00:00, 37.66it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 87/100, Loss: 5232.4336\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 88/100: 100%|██████████| 6/6 [00:00\u003c00:00, 82.76it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 88/100, Loss: 5231.7578\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 89/100: 100%|██████████| 6/6 [00:00\u003c00:00, 81.42it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 89/100, Loss: 5231.1811\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 90/100: 100%|██████████| 6/6 [00:00\u003c00:00, 88.24it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 90/100, Loss: 5230.7364\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 91/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.60it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 91/100, Loss: 5230.9087\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 92/100: 100%|██████████| 6/6 [00:00\u003c00:00, 86.77it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 92/100, Loss: 5229.3865\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 93/100: 100%|██████████| 6/6 [00:00\u003c00:00, 65.01it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 93/100, Loss: 5229.7407\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 94/100: 100%|██████████| 6/6 [00:00\u003c00:00, 90.52it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 94/100, Loss: 5229.2914\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 95/100: 100%|██████████| 6/6 [00:00\u003c00:00, 66.63it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 95/100, Loss: 5228.6436\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 96/100: 100%|██████████| 6/6 [00:00\u003c00:00, 46.13it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 96/100, Loss: 5227.9370\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 97/100: 100%|██████████| 6/6 [00:00\u003c00:00, 52.48it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 97/100, Loss: 5228.0457\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 98/100: 100%|██████████| 6/6 [00:00\u003c00:00, 47.49it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 98/100, Loss: 5227.9027\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 99/100: 100%|██████████| 6/6 [00:00\u003c00:00, 69.27it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 99/100, Loss: 5228.0733\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 100/100: 100%|██████████| 6/6 [00:00\u003c00:00, 90.54it/s, loss=2.62e+3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100/100, Loss: 5228.5775\n","NMF refined embeddings (Normalizing Flow) saved in PyTorch format: ./saved_embeddings/embeddings/normalizing_flow_NMF/matrix_factorization_default_loss_normalizing_flow_NMF_refined_embeddings.pt\n","Feature extraction and normalizing flow processing complete!\n"]}],"source":["from src.embeddings.encoder_models import (\n","    process_matrix_factorization,\n","    apply_sift,\n","    process_feature_extraction,\n","    NormalizingFlowModel,\n","    train_nf_model,\n",")\n","\n","# ------------------------------\n","# Configuration Dictionary\n","# ------------------------------\n","\n","config = {\n","    # Save format and paths\n","    \"save_format\": \"pt\",  # Options: \"pt\" (PyTorch) or \"npy\" (NumPy)\n","    \"base_dir\": \"./saved_embeddings\",\n","    \"embeddings_dir\": \"./saved_embeddings/embeddings\",\n","\n","    # Model and loss naming\n","    \"model_name\": \"matrix_factorization\",\n","    \"loss_type\": \"default_loss\",\n","\n","    # Data settings\n","    \"n_components\": 50,  # Number of components for dimensionality reduction\n","    \"n_features\": 50,  # Number of features for SIFT\n","    \"kernel\": \"rbf\",  # Kernel for Kernel PCA\n","\n","    # Normalizing Flow settings\n","    \"num_flows\": 4,\n","    \"num_epochs\": 100,\n","    \"learning_rate\": 1e-3,\n","    \"batch_size\": 128,\n","\n","    # Device (CPU/GPU)\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","}\n","\n","# Ensure valid save format\n","if config[\"save_format\"] not in [\"pt\", \"npy\"]:\n","    print(f\"Invalid save format: {config['save_format']}. Defaulting to 'pt'.\")\n","    config[\"save_format\"] = \"pt\"\n","\n","# Create directories if they don't exist\n","os.makedirs(config[\"base_dir\"], exist_ok=True)\n","os.makedirs(config[\"embeddings_dir\"], exist_ok=True)\n","\n","# ------------------------------\n","# Helper Function to Save Embeddings\n","# ------------------------------\n","\n","def save_embeddings(embeddings, labels, file_path, save_format):\n","    \"\"\"Save embeddings and labels in the specified format.\"\"\"\n","    if save_format == \"pt\":\n","        torch.save({\"embeddings\": embeddings, \"labels\": labels}, file_path)\n","    elif save_format == \"npy\":\n","        np.save(file_path, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    else:\n","        raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# ------------------------------\n","# Step 1: Load Data\n","# ------------------------------\n","\n","# Extract flattened images and labels\n","sampled_x, sampled_y = mnist_loader.dataset.tensors[0].numpy(), mnist_loader.dataset.tensors[1].numpy()\n","\n","# ------------------------------\n","# Step 2: Matrix Factorization\n","# ------------------------------\n","\n","print(\"Processing matrix factorization models (PCA, SVD, NMF)...\")\n","factorized_embeddings, factorized_labels = process_matrix_factorization(\n","    sampled_x, sampled_y, n_components=config[\"n_components\"]\n",")\n","\n","for method, embeddings in factorized_embeddings.items():\n","    embedding_subdir = f\"matrix_factorization_{method}\"\n","    embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","    os.makedirs(embedding_dir, exist_ok=True)\n","\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_{method}_embeddings.{config['save_format']}\")\n","    save_embeddings(embeddings, factorized_labels, embedding_file, config[\"save_format\"])\n","    print(f\"{method} embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 3: SIFT Features\n","# ------------------------------\n","\n","print(\"Processing SIFT features...\")\n","sift_features = apply_sift(sampled_x, n_features=config[\"n_features\"])\n","sift_labels = torch.tensor(sampled_y, dtype=torch.long)\n","\n","embedding_subdir = \"sift_features\"\n","embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_sift_embeddings.{config['save_format']}\")\n","save_embeddings(sift_features, sift_labels, embedding_file, config[\"save_format\"])\n","print(f\"SIFT embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 4: Kernel PCA\n","# ------------------------------\n","\n","print(\"Processing Kernel PCA...\")\n","kernel_pca_features, kernel_pca_labels = process_feature_extraction(\n","    sampled_x, sampled_y, n_features=config[\"n_features\"], kernel=config[\"kernel\"], n_components=config[\"n_components\"]\n",")\n","\n","for method, embeddings in kernel_pca_features.items():\n","    embedding_subdir = f\"kernel_pca_{method}\"\n","    embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","    os.makedirs(embedding_dir, exist_ok=True)\n","\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_kernel_pca_{method}_embeddings.{config['save_format']}\")\n","    save_embeddings(embeddings, kernel_pca_labels, embedding_file, config[\"save_format\"])\n","    print(f\"{method} Kernel PCA embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 5: Normalizing Flow\n","# ------------------------------\n","\n","print(\"Processing Normalizing Flow...\")\n","for method, embeddings in factorized_embeddings.items():\n","    # Initialize and train Normalizing Flow model\n","    input_dim = embeddings.size(1)\n","    nf_model = NormalizingFlowModel(input_dim=input_dim, num_flows=config[\"num_flows\"]).to(config[\"device\"])\n","    trained_nf_model = train_nf_model(\n","        nf_model, embeddings, num_epochs=config[\"num_epochs\"], lr=config[\"learning_rate\"], batch_size=config[\"batch_size\"]\n","    )\n","\n","    # Refine embeddings\n","    with torch.no_grad():\n","        refined_embeddings, _ = trained_nf_model(embeddings)\n","\n","        embedding_subdir = f\"normalizing_flow_{method}\"\n","        embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","        os.makedirs(embedding_dir, exist_ok=True)\n","\n","        embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_normalizing_flow_{method}_refined_embeddings.{config['save_format']}\")\n","        save_embeddings(refined_embeddings, factorized_labels, embedding_file, config[\"save_format\"])\n","        print(f\"{method} refined embeddings (Normalizing Flow) saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","print(\"Feature extraction and normalizing flow processing complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mf82IvkVxtrP"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}