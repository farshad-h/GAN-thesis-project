{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Embedding Generation Notebook\n","\n","## Objective\n","This notebook demonstrates how to use custom encoder models to generate embeddings from the MNIST dataset. These models are implemented in `encoder_models.py`, and the training processes are defined in `encoder_training.py`.\n","\n","## Workflow\n","1. **Load and Preprocess Data**:\n","   - Load the MNIST dataset for testing the embedding generation process.\n","   - Normalize and prepare the data.\n","2. **Model Selection and Training**:\n","   - Train selected encoder models from `encoder_models.py`.\n","   - Generate embeddings from the bottleneck layer.\n","3. **Feature Extraction**:\n","   - Generate embeddings using matrix factorization (PCA, SVD, NMF) and SIFT.\n","4. **Save Embeddings**:\n","   - Save all embeddings and trained models for reuse.\n","\n","## Models and Methods\n","### Supported Models\n","The following encoder models are available for training and embedding generation. Each model is implemented in `encoder_models.py`:\n","- **Encoder Models**:\n","  - BasicAutoencoder, IntermediateAutoencoder, AdvancedAutoencoder, EnhancedAutoencoder.\n","  - BasicVAE, VAEWithFCDecoder, ImprovedVAE, FlexibleVAE.\n","- **Feature Extraction**:\n","  - PCA, SVD, NMF.\n","  - SIFT, Kernel PCA.\n","\n","#### **Autoencoders**\n","1. **BasicAutoencoder**:\n","   - A simple autoencoder with:\n","     - **Encoder**: Two convolutional layers followed by max-pooling.\n","     - **Decoder**: Two transposed convolutional layers to reconstruct the input.\n","   - Designed for grayscale datasets like MNIST.\n","   - Suitable for basic dimensionality reduction and reconstruction tasks.\n","\n","2. **IntermediateAutoencoder**:\n","   - A deeper autoencoder with:\n","     - **Batch Normalization** for improved stability.\n","     - Additional feature maps for a more expressive latent space.\n","   - Designed for moderately complex embedding tasks requiring better feature extraction.\n","\n","3. **AdvancedAutoencoder**:\n","   - A sophisticated autoencoder with:\n","     - **Skip Connections** to improve gradient flow and reconstruction accuracy.\n","     - **LeakyReLU Activations** and Batch Normalization for robust performance.\n","   - Suitable for high-dimensional or structured data requiring detailed reconstruction.\n","\n","4. **EnhancedAutoencoder**:\n","   - A deeper autoencoder with:\n","     - Additional convolutional layers in the encoder.\n","     - Transposed convolutional layers in the decoder.\n","     - LeakyReLU activations and Batch Normalization for better embedding representation.\n","   - Designed for datasets requiring intricate reconstructions under noisy conditions.\n","\n","#### **Variational Autoencoders (VAEs)**\n","5. **BasicVAE**:\n","   - A simple VAE with:\n","     - **Encoder**: Two convolutional layers and a fully connected layer to parameterize the latent space.\n","     - **Decoder**: Fully connected and transposed convolution layers to reconstruct input images.\n","   - Suitable for generative tasks with simple latent spaces.\n","\n","6. **VAEWithFCDecoder**:\n","   - A VAE with a fully connected decoder for enhanced latent-to-feature mapping.\n","   - Features:\n","     - **Encoder**: Convolutional layers with Batch Normalization.\n","     - **Decoder**: A combination of fully connected and transposed convolutional layers.\n","\n","7. **ImprovedVAE**:\n","   - An advanced VAE with:\n","     - A bottleneck layer for enhanced feature extraction.\n","     - Transposed convolutions for smooth reconstructions.\n","     - KL divergence loss for latent space regularization.\n","   - Designed for datasets requiring expressive latent representations.\n","\n","8. **FlexibleVAE**:\n","   - A flexible VAE that supports dynamic input shapes and optional projection heads for contrastive learning.\n","   - Suitable for embedding tasks with varying input dimensions.\n","\n","9. **ImprovedFlexibleVAE**:\n","   - Combines convolutional and fully connected layers in the encoder.\n","   - Uses transposed convolutions in the decoder for better reconstruction.\n","   - Optional **Projection Head** for self-supervised contrastive learning tasks.\n","\n","#### **Denoising Autoencoders**\n","10. **DenoisingAutoencoder**:\n","    - A denoising autoencoder with:\n","      - **Encoder**: Convolutional layers for feature extraction.\n","      - **Decoder**: Transposed convolutional layers for reconstruction.\n","      - Optional **Projection Head** for contrastive learning.\n","    - Supports two architectures:\n","      - **Basic**: Simpler structure for standard denoising tasks.\n","      - **Strong**: Deeper architecture for challenging noisy datasets.\n","\n","#### **Feature Extraction and Normalizing Flow Models**\n","11. **Matrix Factorization**:\n","    - Embeddings generated using PCA, SVD, and NMF.\n","    - Useful for dimensionality reduction and compact representations.\n","\n","12. **SIFT (Scale-Invariant Feature Transform)**:\n","    - Extracts scale-invariant features from images.\n","    - Pads feature descriptors to ensure consistent dimensionality.\n","\n","13. **Kernel PCA**:\n","    - Nonlinear dimensionality reduction using Kernel PCA with adjustable kernels.\n","\n","14. **Normalizing Flow Models**:\n","    - Transforms embeddings into a latent space using invertible transformations.\n","    - Useful for embedding refinement and generative tasks.\n","\n","\n","**Training**:\n","   - Each model is trained using the corresponding training loop defined in `encoder_training.py`.\n","   - Training includes support for reconstruction loss, KL divergence (for VAE), and optional noise injection.\n","**Embedding Generation**:\n","   - Once the models are trained, embeddings are generated for the MNIST dataset.\n","   - Encodings from the bottleneck layer are extracted for downstream tasks.\n","**Results Storage**:\n","   - Save trained models to `.pth` files.\n","   - Save generated embeddings to `.pt` files for reuse in downstream applications.\n","\n","## Supported Features\n","- **Flexible Model Selection**:\n","  - Choose specific models to train and generate embeddings for, bypassing others if needed.\n","- **Custom Configuration**:\n","  - Easily modify parameters like the bottleneck size (`code_dim`), number of training epochs, and learning rates.\n","\n","## Outputs\n","- Trained models saved as `.pth` files.\n","- Generated embeddings saved as `.pt` files in a structured directory (`./embeddings`).\n","\n","## Notes\n","This notebook is designed for flexibility and reusability. You can:\n","- Add new encoder models in `encoder_models.py`.\n","- Customize training loops in `encoder_training.py`.\n","- Modify this notebook to train specific models or generate embeddings for specific datasets.\n"],"metadata":{"id":"VUQM0eOdRPMH"}},{"cell_type":"code","source":["import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# Mount Google Drive and set repository path\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Repository path (adjust if needed)\n","repo_path = \"/content/drive/MyDrive/GAN-thesis-project\"\n","\n","# Add repository path to sys.path for module imports\n","if repo_path not in sys.path:\n","    sys.path.append(repo_path)\n","\n","# Change working directory to the repository\n","os.chdir(repo_path)\n","\n","# Verify the working directory\n","print(f\"Current working directory: {os.getcwd()}\")\n","\n","# Configuration\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLvDZtTSZFUb","executionInfo":{"status":"ok","timestamp":1737827036201,"user_tz":-210,"elapsed":61058,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"fdd771f6-add4-4557-f80f-4674e43ed718"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Current working directory: /content/drive/MyDrive/GAN-thesis-project\n","Using device: cpu\n"]}]},{"cell_type":"code","source":["import inspect\n","\n","# Import the entire modules\n","import src.data_utils as data_utils\n","import src.cl_loss_function as cl_loss\n","import src.losses as losses\n","import src.embeddings.encoder_models as encoder_models\n","import src.embeddings.encoder_training as encoder_training\n","\n","# Function to list functions and classes in a module\n","def list_functions_and_classes(module):\n","    members = inspect.getmembers(module)\n","    functions = [name for name, obj in members if inspect.isfunction(obj)]\n","    classes = [name for name, obj in members if inspect.isclass(obj)]\n","    return functions, classes\n","\n","# Function to print functions and classes in a readable format\n","def print_functions_and_classes(module_name, module):\n","    functions, classes = list_functions_and_classes(module)\n","    print(f\"Module: {module_name}\")\n","    print(\"  Functions:\")\n","    for func in functions:\n","        print(f\"    - {func}\")\n","    print(\"  Classes:\")\n","    for cls in classes:\n","        print(f\"    - {cls}\")\n","    print()  # Add a blank line for separation\n","\n","# Print functions and classes for each module\n","print_functions_and_classes(\"src.data_utils\", data_utils)\n","print_functions_and_classes(\"src.cl_loss_function\", cl_loss)\n","print_functions_and_classes(\"src.losses\", losses)\n","print_functions_and_classes(\"src.embeddings.encoder_models\", encoder_models)\n","print_functions_and_classes(\"src.embeddings.encoder_training\", encoder_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jah7kWk-SpUb","executionInfo":{"status":"ok","timestamp":1737827043565,"user_tz":-210,"elapsed":7367,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"3d5ed25a-0218-434b-894d-33a8af45a328"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Module: src.data_utils\n","  Functions:\n","    - analyze_embeddings\n","    - analyze_embeddings_v2\n","    - create_dataloader\n","    - create_embedding_loaders\n","    - generate_embeddings\n","    - kurtosis\n","    - load_data\n","    - load_embeddings\n","    - load_mnist_data\n","    - pdist\n","    - preprocess_images\n","    - save_embeddings\n","    - skew\n","    - split_dataset\n","    - train_test_split\n","    - visualize_embeddings\n","  Classes:\n","    - DataLoader\n","    - LocalOutlierFactor\n","    - TensorDataset\n","\n","Module: src.cl_loss_function\n","  Functions:\n","    - augment\n","    - compute_nt_xent_loss_with_augmentation\n","    - compute_triplet_loss_with_augmentation\n","    - contrastive_loss\n","    - hflip\n","    - info_nce_loss\n","    - resize\n","  Classes:\n","    - BYOLLoss\n","    - ContrastiveHead\n","    - DataLoader\n","    - NTXentLoss\n","    - PCA\n","    - Predictor\n","    - TensorDataset\n","    - TripletLoss\n","    - VicRegLoss\n","\n","Module: src.losses\n","  Functions:\n","    - add_noise\n","    - cyclical_beta_schedule\n","    - linear_beta_schedule\n","    - loss_function_dae_ssim\n","    - vae_loss\n","    - vae_ssim_loss\n","  Classes:\n","\n","Module: src.embeddings.encoder_models\n","  Functions:\n","    - apply_dimensionality_reduction\n","    - apply_sift\n","    - init_weights\n","    - log_prob\n","    - process_feature_extraction\n","    - process_matrix_factorization\n","    - refine_embeddings_NF\n","    - train_nf_model\n","  Classes:\n","    - AdvancedAutoencoder\n","    - BasicAutoencoder\n","    - BasicVAE\n","    - DataLoader\n","    - DenoisingAutoencoder\n","    - EnhancedAutoencoder\n","    - FlexibleVAE\n","    - FlowLayer\n","    - ImprovedFlexibleVAE\n","    - ImprovedVAE\n","    - IntermediateAutoencoder\n","    - KernelPCA\n","    - MinMaxScaler\n","    - NMF\n","    - NormalizingFlowModel\n","    - PCA\n","    - ProjectionHead\n","    - SimCLR\n","    - StandardScaler\n","    - TensorDataset\n","    - TruncatedSVD\n","    - tqdm\n","\n","Module: src.embeddings.encoder_training\n","  Functions:\n","    - add_noise\n","    - ssim\n","    - train_autoencoder\n","    - train_autoencoder_v4\n","    - train_dae\n","    - train_simclr\n","    - train_vae\n","  Classes:\n","    - DataLoader\n","    - EarlyStopping\n","    - MinMaxScaler\n","    - StandardScaler\n","    - TensorDataset\n","    - ToTensor\n","    - tqdm\n","\n"]}]},{"cell_type":"code","source":["# Load and Preprocess MNIST Data\n","fraction = 0.01  # Fraction of the dataset to use\n","batch_size = 64\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=fraction, batch_size=batch_size, shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 30\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 6))\n","for i in range(n):\n","    ax = plt.subplot(3, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n"],"metadata":{"id":"9ByfVYCjeT7P","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"ok","timestamp":1737827049208,"user_tz":-210,"elapsed":4576,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"b8ce608b-de1d-4922-984e-aa7887e89a70"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampled Dataset: (700, 1, 28, 28) (700,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x600 with 30 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# def generate_embeddings(model, data_loader, embedding_type, device=\"cpu\"):\n","#     model.eval()  # Set model to evaluation mode\n","#     embeddings = []\n","#     labels = []\n","\n","#     with torch.no_grad():\n","#         for images, label_batch in data_loader:\n","#             images = images.to(device)\n","#             if embedding_type == \"autoencoder\":\n","#                 encoded, _ = model(images)\n","#             elif embedding_type == \"vae\":\n","#                 mu, _, _ = model(images)\n","#                 encoded = mu  # Use the mean of the latent space\n","#             elif embedding_type == \"dae\":\n","#                 _, _, encoded = model(images)\n","#             else:\n","#                 raise ValueError(f\"Embedding type '{embedding_type}' is not recognized.\")\n","\n","#             embeddings.append(encoded.cpu())\n","#             labels.append(label_batch)\n","\n","#     embeddings = torch.cat(embeddings, dim=0)\n","#     labels = torch.cat(labels, dim=0)\n","\n","#     return embeddings, labels"],"metadata":{"id":"lC_8uAUF7t0r","executionInfo":{"status":"ok","timestamp":1737815473322,"user_tz":-210,"elapsed":3,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# import torch.nn.functional as F\n","\n","# class NTXentLoss(nn.Module):\n","#     def __init__(self, temperature=0.5):\n","#         super(NTXentLoss, self).__init__()\n","#         self.temperature = temperature\n","\n","#     def forward(self, z_i, z_j):\n","#         batch_size = z_i.size(0)\n","\n","#         # Flatten the input tensors if they are not already 2D\n","#         z_i = z_i.view(z_i.size(0), -1)  # Shape: (batch_size, embedding_dim)\n","#         z_j = z_j.view(z_j.size(0), -1)  # Shape: (batch_size, embedding_dim)\n","\n","#         # Normalize the embeddings\n","#         z_i = F.normalize(z_i, dim=1)\n","#         z_j = F.normalize(z_j, dim=1)\n","\n","#         # Concatenate the embeddings\n","#         z = torch.cat([z_i, z_j], dim=0)  # Shape: (2 * batch_size, embedding_dim)\n","\n","#         # Compute the similarity matrix\n","#         similarity_matrix = torch.matmul(z, z.T) / self.temperature  # Shape: (2 * batch_size, 2 * batch_size)\n","\n","#         # Mask for positives and negatives\n","#         mask = ~torch.eye(2 * batch_size, device=z.device).bool()\n","#         positives = torch.cat([\n","#             torch.diag(similarity_matrix, batch_size),  # Positive pairs (z_i, z_j)\n","#             torch.diag(similarity_matrix, -batch_size)  # Positive pairs (z_j, z_i)\n","#         ])\n","#         negatives = similarity_matrix.masked_select(mask).view(2 * batch_size, -1)\n","\n","#         # Compute the NT-Xent loss\n","#         numerator = torch.exp(positives)\n","#         denominator = torch.sum(torch.exp(negatives), dim=-1)\n","#         loss = -torch.mean(torch.log(numerator / denominator))\n","\n","#         return loss\n","\n","# class VicRegLoss(nn.Module):\n","#     def __init__(self, lambda_var=25, mu_mean=25, nu_cov=1):\n","#         super(VicRegLoss, self).__init__()\n","#         self.lambda_var = lambda_var\n","#         self.mu_mean = mu_mean\n","#         self.nu_cov = nu_cov\n","\n","#     def forward(self, z1, z2):\n","#         # Flatten z1 and z2 if they are 4D\n","#         if z1.dim() == 4:\n","#             z1 = z1.view(z1.size(0), -1)  # Shape: (batch_size, 1 * 28 * 28)\n","#         if z2.dim() == 4:\n","#             z2 = z2.view(z2.size(0), -1)  # Shape: (batch_size, 1 * 28 * 28)\n","\n","#         # Variance loss\n","#         variance_loss = torch.mean(torch.relu(1 - torch.std(z1, dim=0))) + \\\n","#                         torch.mean(torch.relu(1 - torch.std(z2, dim=0)))\n","\n","#         # Mean loss\n","#         mean_loss = torch.mean((torch.mean(z1, dim=0) - torch.mean(z2, dim=0))**2)\n","\n","#         # Covariance loss\n","#         z1_centered = z1 - z1.mean(dim=0)\n","#         z2_centered = z2 - z2.mean(dim=0)\n","\n","#         covariance_matrix_z1 = torch.mm(z1_centered.T, z1_centered) / (z1.size(0) - 1)\n","#         covariance_matrix_z2 = torch.mm(z2_centered.T, z2_centered) / (z2.size(0) - 1)\n","\n","#         covariance_loss = torch.sum(covariance_matrix_z1 ** 2) - torch.sum(torch.diag(covariance_matrix_z1) ** 2) + \\\n","#                           torch.sum(covariance_matrix_z2 ** 2) - torch.sum(torch.diag(covariance_matrix_z2) ** 2)\n","\n","#         # Total loss\n","#         total_loss = self.lambda_var * variance_loss + \\\n","#                      self.mu_mean * mean_loss + \\\n","#                      self.nu_cov * covariance_loss\n","#         return total_loss\n","\n","# class TripletLoss(nn.Module):\n","#     def __init__(self, margin=1.0):\n","#         super(TripletLoss, self).__init__()\n","#         self.margin = margin\n","#         self.criterion = nn.TripletMarginWithDistanceLoss(\n","#             distance_function=lambda a, b: 1.0 - F.cosine_similarity(a, b),\n","#             margin=self.margin\n","#         )\n","\n","#     def forward(self, anchor, positive, negative):\n","#         return self.criterion(anchor, positive, negative)\n","\n","# class BarlowTwinsLoss(nn.Module):\n","#     def __init__(self, lambda_param=5e-3):\n","#         super(BarlowTwinsLoss, self).__init__()\n","#         self.lambda_param = lambda_param\n","\n","#     def forward(self, z_a, z_b):\n","#         \"\"\"\n","#         Compute the Barlow Twins loss between two sets of embeddings.\n","\n","#         Args:\n","#             z_a (torch.Tensor): First set of embeddings.\n","#             z_b (torch.Tensor): Second set of embeddings.\n","\n","#         Returns:\n","#             torch.Tensor: Computed Barlow Twins loss.\n","#         \"\"\"\n","#         batch_size = z_a.size(0)\n","#         feature_dim = z_a.size(1)\n","\n","#         # Normalize embeddings\n","#         z_a = (z_a - z_a.mean(dim=0)) / z_a.std(dim=0)\n","#         z_b = (z_b - z_b.mean(dim=0)) / z_b.std(dim=0)\n","\n","#         # Compute cross-correlation matrix\n","#         cross_corr = torch.matmul(z_a.T, z_b) / batch_size\n","\n","#         # Loss terms\n","#         invariance_loss = torch.sum((1 - torch.diag(cross_corr)) ** 2)\n","#         redundancy_loss = torch.sum(torch.triu(cross_corr, diagonal=1) ** 2) + torch.sum(torch.tril(cross_corr, diagonal=-1) ** 2)\n","\n","#         # Total loss\n","#         loss = invariance_loss + self.lambda_param * redundancy_loss\n","#         return loss\n","\n","# class BYOLLoss(nn.Module):\n","#     def __init__(self):\n","#         super(BYOLLoss, self).__init__()\n","\n","#     def forward(self, z_a, z_b, predictor):\n","#         \"\"\"\n","#         Compute the BYOL loss between two sets of embeddings.\n","\n","#         Args:\n","#             z_a (torch.Tensor): First set of embeddings.\n","#             z_b (torch.Tensor): Second set of embeddings.\n","#             predictor (nn.Module): Predictor network.\n","\n","#         Returns:\n","#             torch.Tensor: Computed BYOL loss.\n","#         \"\"\"\n","#         # Normalize embeddings\n","#         z_a = F.normalize(z_a, dim=1)\n","#         z_b = F.normalize(z_b, dim=1)\n","\n","#         # Predict z_b from z_a\n","#         p_a = predictor(z_a)\n","#         p_a = F.normalize(p_a, dim=1)\n","\n","#         # Compute MSE loss between predicted and target embeddings\n","#         loss = 2 - 2 * (p_a * z_b).sum(dim=1).mean()\n","#         return loss\n","\n","# class Predictor(nn.Module):\n","#     def __init__(self, input_dim, hidden_dim=512, output_dim=50):\n","#         super(Predictor, self).__init__()\n","#         self.net = nn.Sequential(\n","#             nn.Linear(input_dim, hidden_dim),\n","#             nn.BatchNorm1d(hidden_dim),\n","#             nn.ReLU(),\n","#             nn.Linear(hidden_dim, output_dim),\n","#         )\n","\n","#     def forward(self, x):\n","#         return self.net(x)"],"metadata":{"id":"Y8LPTX8iKf1j","executionInfo":{"status":"ok","timestamp":1737825225851,"user_tz":-210,"elapsed":580,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["from typing import Callable, Optional\n","\n","def train_autoencoder(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    noise_factor: float = 0.0,\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, InfoNCE)\n","    - Triplet loss\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","\n","    Args:\n","        model (nn.Module): The autoencoder model.\n","        data_loader (DataLoader): DataLoader for training data.\n","        loss_fn (Callable): Primary loss function (e.g., reconstruction loss).\n","        optimizer (optim.Optimizer): Optimizer for the model.\n","        epochs (int): Number of epochs to train.\n","        device (str): Device to train on ('cpu' or 'cuda').\n","        noise_factor (float): Factor for adding noise to input images (denoising autoencoder).\n","        scheduler (Optional[optim.lr_scheduler._LRScheduler]): Learning rate scheduler.\n","        contrastive_loss_fn (Optional[Callable]): Contrastive loss function (e.g., NT-Xent, triplet loss).\n","        temperature (float): Temperature parameter for NT-Xent loss.\n","        triplet_data (bool): Whether the data_loader provides triplets (anchor, positive, negative).\n","        augment_fn (Optional[Callable]): Augmentation function for contrastive learning.\n","        patience (int): Number of epochs with no significant improvement before triggering early stopping.\n","        min_delta (float): Minimum change in loss to qualify as an improvement.\n","\n","    Returns:\n","        None: Prints loss values for each epoch.\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            # Add noise if specified\n","            if noise_factor > 0:\n","                noisy_images = images + noise_factor * torch.randn_like(images)\n","                noisy_images = torch.clamp(noisy_images, 0.0, 1.0)\n","                encoded, decoded = model(noisy_images)\n","            else:\n","                encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Handle different contrastive loss functions\n","                    if isinstance(contrastive_loss_fn, NTXentLoss):\n","                        # NT-Xent loss requires temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)\n","                    elif isinstance(contrastive_loss_fn, VicRegLoss):\n","                        # VicReg loss does not require temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    else:\n","                        # Default behavior for other contrastive losses\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break\n","\n","class EarlyStopping:\n","    \"\"\"\n","    Early stopping to stop training when the loss does not improve after a specified number of epochs (patience).\n","    \"\"\"\n","    def __init__(self, patience=5, min_delta=0):\n","        \"\"\"\n","        Args:\n","            patience (int): Number of epochs to wait for improvement before stopping.\n","            min_delta (float): Minimum change in loss to qualify as an improvement.\n","        \"\"\"\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_loss = float('inf')\n","        self.early_stop = False\n","\n","    def __call__(self, current_loss):\n","        \"\"\"\n","        Check if training should stop.\n","\n","        Args:\n","            current_loss (float): Current epoch's loss.\n","        \"\"\"\n","        if current_loss < self.best_loss - self.min_delta:\n","            self.best_loss = current_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True"],"metadata":{"id":"haU_-HAd8kYw","executionInfo":{"status":"ok","timestamp":1737816788489,"user_tz":-210,"elapsed":315,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def train_autoencoder_v2(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    noise_factor: float = 0.0,\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, VicReg, Triplet)\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","\n","    Args:\n","        model (nn.Module): The autoencoder model.\n","        data_loader (DataLoader): DataLoader for training data.\n","        loss_fn (Callable): Primary loss function (e.g., reconstruction loss).\n","        optimizer (optim.Optimizer): Optimizer for the model.\n","        epochs (int): Number of epochs to train.\n","        device (str): Device to train on ('cpu' or 'cuda').\n","        noise_factor (float): Factor for adding noise to input images (denoising autoencoder).\n","        scheduler (Optional[optim.lr_scheduler._LRScheduler]): Learning rate scheduler.\n","        contrastive_loss_fn (Optional[Callable]): Contrastive loss function (e.g., NT-Xent, VicReg, Triplet).\n","        temperature (float): Temperature parameter for NT-Xent loss.\n","        triplet_data (bool): Whether the data_loader provides triplets (anchor, positive, negative).\n","        augment_fn (Optional[Callable]): Augmentation function for contrastive learning.\n","        patience (int): Number of epochs with no significant improvement before triggering early stopping.\n","        min_delta (float): Minimum change in loss to qualify as an improvement.\n","\n","    Returns:\n","        None: Prints loss values for each epoch.\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            # Add noise if specified\n","            if noise_factor > 0:\n","                noisy_images = images + noise_factor * torch.randn_like(images)\n","                noisy_images = torch.clamp(noisy_images, 0.0, 1.0)\n","                encoded, decoded = model(noisy_images)\n","            else:\n","                encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","\n","                    # Flatten embeddings\n","                    encoded = encoded.view(encoded.size(0), -1)\n","                    positive_encoded = positive_encoded.view(positive_encoded.size(0), -1)\n","                    negative_encoded = negative_encoded.view(negative_encoded.size(0), -1)\n","\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Flatten embeddings\n","                    z1 = z1.view(z1.size(0), -1)\n","                    z2 = z2.view(z2.size(0), -1)\n","\n","                    # Handle different contrastive loss functions\n","                    if isinstance(contrastive_loss_fn, NTXentLoss):\n","                        # NT-Xent loss does not require temperature in forward()\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    elif isinstance(contrastive_loss_fn, VicRegLoss):\n","                        # VicReg loss does not require temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    else:\n","                        # Default behavior for other contrastive losses\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break"],"metadata":{"id":"nLgJBbvQ-7Ox","executionInfo":{"status":"ok","timestamp":1737817328544,"user_tz":-210,"elapsed":308,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def train_autoencoder_v3(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    noise_factor: float = 0.0,\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, VicReg, Triplet)\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","\n","    Args:\n","        model (nn.Module): The autoencoder model.\n","        data_loader (DataLoader): DataLoader for training data.\n","        loss_fn (Callable): Primary loss function (e.g., reconstruction loss).\n","        optimizer (optim.Optimizer): Optimizer for the model.\n","        epochs (int): Number of epochs to train.\n","        device (str): Device to train on ('cpu' or 'cuda').\n","        noise_factor (float): Factor for adding noise to input images (denoising autoencoder).\n","        scheduler (Optional[optim.lr_scheduler._LRScheduler]): Learning rate scheduler.\n","        contrastive_loss_fn (Optional[Callable]): Contrastive loss function (e.g., NT-Xent, VicReg, Triplet).\n","        temperature (float): Temperature parameter for NT-Xent loss.\n","        triplet_data (bool): Whether the data_loader provides triplets (anchor, positive, negative).\n","        augment_fn (Optional[Callable]): Augmentation function for contrastive learning.\n","        patience (int): Number of epochs with no significant improvement before triggering early stopping.\n","        min_delta (float): Minimum change in loss to qualify as an improvement.\n","\n","    Returns:\n","        None: Prints loss values for each epoch.\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            # Add noise if specified\n","            if noise_factor > 0:\n","                noisy_images = images + noise_factor * torch.randn_like(images)\n","                noisy_images = torch.clamp(noisy_images, 0.0, 1.0)\n","                encoded, decoded = model(noisy_images)\n","            else:\n","                encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","\n","                    # Flatten embeddings\n","                    encoded = encoded.view(encoded.size(0), -1)\n","                    positive_encoded = positive_encoded.view(positive_encoded.size(0), -1)\n","                    negative_encoded = negative_encoded.view(negative_encoded.size(0), -1)\n","\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Flatten embeddings\n","                    z1 = z1.view(z1.size(0), -1)\n","                    z2 = z2.view(z2.size(0), -1)\n","\n","                    # # Handle different contrastive loss functions\n","                    # if contrastive_loss_fn.__name__ == \"contrastive_loss\":\n","                    #     # Basic contrastive loss\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)\n","                    # elif contrastive_loss_fn.__name__ == \"info_nce_loss\":\n","                    #     # InfoNCE loss\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)\n","                    if isinstance(contrastive_loss_fn, NTXentLoss):\n","                        # NT-Xent loss does not require temperature in forward()\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    elif isinstance(contrastive_loss_fn, VicRegLoss):\n","                        # VicReg loss does not require temperature\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                    else:\n","                        # Default behavior for other contrastive losses\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","                    # # Handle all contrastive losses uniformly\n","                    # if hasattr(contrastive_loss_fn, \"temperature\"):\n","                    #     # Pass temperature to loss functions that require it\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                    # else:\n","                    #     # For loss functions that don't use temperature\n","                    #     contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break"],"metadata":{"id":"F3V_6-o4COPK","executionInfo":{"status":"ok","timestamp":1737823800237,"user_tz":-210,"elapsed":320,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["import inspect\n","\n","def train_autoencoder_v4(\n","    model: nn.Module,\n","    data_loader: DataLoader,\n","    loss_fn: Callable,\n","    optimizer: optim.Optimizer,\n","    epochs: int = 10,\n","    device: str = \"cpu\",\n","    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n","    contrastive_loss_fn: Optional[Callable] = None,\n","    temperature: float = 0.5,\n","    triplet_data: bool = False,\n","    augment_fn: Optional[Callable] = None,\n","    predictor: Optional[nn.Module] = None,  # Add predictor for BYOL\n","    patience: int = 5,\n","    min_delta: float = 0.001,\n","):\n","    \"\"\"\n","    Unified training function for autoencoders with support for:\n","    - Reconstruction loss\n","    - Contrastive loss (e.g., NT-Xent, VicReg, Triplet, Contrastive, InfoNCE, Barlow Twins, BYOL)\n","    - Noise injection (for denoising autoencoders)\n","    - Data augmentation\n","    - Early stopping\n","    \"\"\"\n","    model.to(device).train()\n","\n","    # Initialize early stopping\n","    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in data_loader:\n","            # Prepare data based on whether it's triplet data or not\n","            if triplet_data:\n","                anchor, positive, negative = batch\n","                anchor, positive, negative = (\n","                    anchor.to(device).float(),\n","                    positive.to(device).float(),\n","                    negative.to(device).float(),\n","                )\n","                images = anchor  # Use anchor as the primary input for reconstruction\n","            else:\n","                images, _ = batch\n","                images = images.to(device).float()\n","\n","            encoded, decoded = model(images)\n","\n","            # Compute reconstruction loss\n","            reconstruction_loss = loss_fn(decoded, images)\n","\n","            # Compute contrastive loss if specified\n","            contrastive_loss_value = 0\n","            if contrastive_loss_fn is not None:\n","                if triplet_data:\n","                    # Triplet loss\n","                    positive_encoded, _ = model(positive)\n","                    negative_encoded, _ = model(negative)\n","\n","                    # Flatten embeddings\n","                    encoded = encoded.view(encoded.size(0), -1)\n","                    positive_encoded = positive_encoded.view(positive_encoded.size(0), -1)\n","                    negative_encoded = negative_encoded.view(negative_encoded.size(0), -1)\n","\n","                    # Compute triplet loss\n","                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)\n","                else:\n","                    # NT-Xent, VicReg, Contrastive, InfoNCE, Barlow Twins, BYOL, or other contrastive loss\n","                    if augment_fn:\n","                        augmented_1 = augment_fn(images)\n","                        augmented_2 = augment_fn(images)\n","                        z1, _ = model(augmented_1)\n","                        z2, _ = model(augmented_2)\n","                    else:\n","                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation\n","\n","                    # Flatten embeddings\n","                    z1 = z1.view(z1.size(0), -1)\n","                    z2 = z2.view(z2.size(0), -1)\n","\n","                    # Handle all contrastive losses uniformly\n","                    if isinstance(contrastive_loss_fn, BYOLLoss):\n","                        # BYOL requires a predictor\n","                        if predictor is None:\n","                            raise ValueError(\"Predictor network must be provided for BYOL loss.\")\n","                        contrastive_loss_value = contrastive_loss_fn(z1, z2, predictor)\n","                    else:\n","                        # # Check if the loss function accepts a `temperature` parameter\n","                        # if \"temperature\" in inspect.signature(contrastive_loss_fn.forward).parameters:\n","                        #     contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                        # else:\n","                        #     contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","                        # Check if the loss function accepts a `temperature` parameter\n","                        if \"temperature\" in inspect.signature(contrastive_loss_fn).parameters:\n","                            contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature=temperature)\n","                        else:\n","                            contrastive_loss_value = contrastive_loss_fn(z1, z2)\n","\n","            # Total loss\n","            total_loss_value = reconstruction_loss + contrastive_loss_value\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            total_loss_value.backward()\n","            optimizer.step()\n","\n","            total_loss += total_loss_value.item()\n","\n","        # Step the scheduler if provided\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Compute average epoch loss\n","        avg_loss = total_loss / len(data_loader)\n","        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}\")\n","\n","        # Check for early stopping\n","        early_stopping(avg_loss)\n","        if early_stopping.early_stop:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n","            break"],"metadata":{"id":"2i3xXINoYQ0g","executionInfo":{"status":"ok","timestamp":1737826310943,"user_tz":-210,"elapsed":348,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["# ------------------------------\n","# Step 1: Define Configuration\n","# ------------------------------\n","\n","# Configuration\n","config = {\n","    \"model_type\": \"autoencoder\",  # Options: \"autoencoder\", \"vae\", \"dae\"\n","    \"model_name\": \"EnhancedAutoencoder\",  # Options: \"BasicAutoencoder\", \"IntermediateAutoencoder\", \"AdvancedAutoencoder\", \"EnhancedAutoencoder\", \"BasicVAE\", \"ImprovedVAE\", \"FlexibleVAE\", \"ImprovedFlexibleVAE\", \"DenoisingAutoencoder\"\n","    \"code_dim\": 50,  # Dimensionality of the embedding\n","    \"loss_type\": \"ntxent\",  # Options: \"mse\", \"vicreg\", \"ntxent\", \"triplet\"\n","    \"noise_factor\": 0.1,  # Noise factor for denoising autoencoders\n","    \"temperature\": 0.5,  # Temperature parameter for NT-Xent loss\n","    \"margin\": 1.0,  # Margin for Triplet Loss\n","    \"epochs\": 100,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-3,\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"save_best\": True,  # Whether to save the best model\n","    \"save_path\": \"best_model.pth\",  # Path to save the best model\n","    \"beta\": 1.0,  # Weight for KL divergence (VAE only)\n","    \"alpha\": 0.5,  # Weight for contrastive or triplet loss\n","    \"fraction\": 0.01,  # Fraction of the dataset to use\n","    \"projection_dim\": None,  # Optional projection head dimension for VAEs\n","    \"strong_architecture\": False,  # Whether to use a deeper architecture for DenoisingAutoencoder\n","    \"input_shape\": (1, 28, 28),  # Input shape for FlexibleVAE and ImprovedFlexibleVAE\n","    \"patience\": 5,\n","    \"min_delta\": 0.001,\n","    \"triplet_data\": False,\n","}\n","\n","# ------------------------------\n","# Step 2: Load and Preprocess Data\n","# ------------------------------\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=config[\"fraction\"], batch_size=config[\"batch_size\"], shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 20\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n","\n","# ------------------------------\n","# Step 3: Initialize Model, Loss, and Optimizer\n","# ------------------------------\n","\n","# Initialize the model\n","model_classes = {\n","    \"BasicAutoencoder\": encoder_models.BasicAutoencoder,\n","    \"IntermediateAutoencoder\": encoder_models.IntermediateAutoencoder,\n","    \"AdvancedAutoencoder\": encoder_models.AdvancedAutoencoder,\n","    \"EnhancedAutoencoder\": encoder_models.EnhancedAutoencoder,\n","    \"BasicVAE\": encoder_models.BasicVAE,\n","    \"ImprovedVAE\": encoder_models.ImprovedVAE,\n","    \"FlexibleVAE\": encoder_models.FlexibleVAE,\n","    \"ImprovedFlexibleVAE\": encoder_models.ImprovedFlexibleVAE,\n","    \"DenoisingAutoencoder\": encoder_models.DenoisingAutoencoder,\n","}\n","\n","# Initialize model with appropriate arguments\n","if config[\"model_name\"] in [\"FlexibleVAE\", \"ImprovedFlexibleVAE\"]:\n","    model = model_classes[config[\"model_name\"]](\n","        input_shape=config[\"input_shape\"],\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"]\n","    ).to(config[\"device\"])\n","elif config[\"model_name\"] == \"DenoisingAutoencoder\":\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"],\n","        strong_architecture=config[\"strong_architecture\"]\n","    ).to(config[\"device\"])\n","else:\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"]\n","    ).to(config[\"device\"])\n","\n","# Define the loss function\n","if config[\"model_type\"] == \"vae\":\n","    criterion = losses.vae_loss  # Use VAE loss for VAEs\n","else:\n","    loss_functions = {\n","        \"mse\": nn.MSELoss(),  # Reconstruction loss\n","        \"vicreg\": VicRegLoss(lambda_var=25, mu_mean=25, nu_cov=1),  # VicReg loss\n","        \"ntxent\": NTXentLoss(temperature=config[\"temperature\"]),\n","        # cl_loss.NTXentLoss(temperature=config[\"temperature\"]),  # NT-Xent loss\n","        \"triplet\": TripletLoss(margin=config[\"margin\"]),  # Triplet loss\n","    }\n","    criterion = loss_functions[config[\"loss_type\"]]\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Define scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","\n","# ------------------------------\n","# Step 4: Train the Model\n","# ------------------------------\n","\n","if config[\"model_type\"] == \"autoencoder\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    train_autoencoder_v3(\n","        model=model,\n","        data_loader=mnist_loader,\n","        loss_fn=criterion,\n","        optimizer=optimizer,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        # noise_factor=config[\"noise_factor\"],\n","        scheduler=scheduler,\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"triplet\"] else None,\n","        # triplet_data=(config[\"loss_type\"] != \"triplet\"),\n","        augment_fn=cl_loss.augment if config[\"loss_type\"] in [\"vicreg\", \"ntxent\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"vae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_vae(\n","        vae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        beta=config[\"beta\"],\n","        alpha=config[\"alpha\"],\n","        temperature=config[\"temperature\"],\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"dae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_dae(\n","        dae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        noise_factor=config[\"noise_factor\"],\n","        alpha=config[\"alpha\"],\n","        temperature=config[\"temperature\"],\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\"] else None,\n","        triplet_loss_fn=criterion if config[\"loss_type\"] == \"triplet\" else None,\n","        ssim_func=losses.ssim if config[\"loss_type\"] == \"ssim\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","# ------------------------------\n","# Step 5: Save Embeddings and Model\n","# ------------------------------\n","\n","# Generate embeddings\n","embeddings, labels = data_utils.generate_embeddings(\n","    model=model,\n","    embedding_type=config[\"model_type\"],\n","    data_loader=mnist_loader,\n","    device=config[\"device\"],\n",")\n","\n","# Define the base storage directory for embeddings\n","base_dir = \"./saved_embeddings\"\n","os.makedirs(base_dir, exist_ok=True)\n","\n","# Ensure a dedicated directory for embeddings\n","embeddings_dir = os.path.join(base_dir, \"embeddings\")\n","os.makedirs(embeddings_dir, exist_ok=True)\n","\n","# Create a unique subdirectory for this embedding type, model, and loss type\n","embedding_subdir = f\"{config['model_type']}_{config['model_name']}_{config['loss_type']}\"\n","embedding_dir = os.path.join(embeddings_dir, embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","# Choose saving format: default is .pt, but .npy can be chosen\n","save_format = \"pt\"  # Change to \"npy\" for NumPy format\n","\n","# Save embeddings with differentiated names based on the model, loss type, and embedding type\n","if save_format == \"pt\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.pt\")\n","    torch.save({\"embeddings\": embeddings, \"labels\": labels}, embedding_file)\n","    print(f\"Embeddings saved in PyTorch format: {embedding_file}\")\n","elif save_format == \"npy\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.npy\")\n","    np.save(embedding_file, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    print(f\"Embeddings saved in NumPy format: {embedding_file}\")\n","else:\n","    raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# Save the model\n","model_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}.pth\")\n","torch.save(model.state_dict(), model_file)\n","print(f\"Model saved: {model_file}\")\n","\n","# ------------------------------\n","# Step 6: Visualize Embeddings\n","# ------------------------------\n","\n","# Visualize embeddings\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":667},"id":"zAKUO7472Gn7","executionInfo":{"status":"error","timestamp":1737824748106,"user_tz":-210,"elapsed":8913,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"4a7676f4-a6d8-4d6d-ed75-13acebe37876"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampled Dataset: (700, 1, 28, 28) (700,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x400 with 20 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training EnhancedAutoencoder with ntxent loss...\n","Epoch [1/100], Train Loss: 8.9189\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-100-56da34e65d77>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"autoencoder\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training {config['model_name']} with {config['loss_type']} loss...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     train_autoencoder_v3(\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-e2c0e6269fd5>\u001b[0m in \u001b[0;36mtrain_autoencoder_v3\u001b[0;34m(model, data_loader, loss_fn, optimizer, epochs, device, noise_factor, scheduler, contrastive_loss_fn, temperature, triplet_data, augment_fn, patience, min_delta)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtotal_loss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# ------------------------------\n","# Step 1: Define Configuration\n","# ------------------------------\n","\n","# Configuration\n","config = {\n","    \"model_type\": \"autoencoder\",  # Options: \"autoencoder\", \"vae\", \"dae\"\n","    \"model_name\": \"EnhancedAutoencoder\",  # Options: \"BasicAutoencoder\", \"IntermediateAutoencoder\", \"AdvancedAutoencoder\", \"EnhancedAutoencoder\", \"BasicVAE\", \"ImprovedVAE\", \"FlexibleVAE\", \"ImprovedFlexibleVAE\", \"DenoisingAutoencoder\"\n","    \"code_dim\": 50,  # Dimensionality of the embedding\n","    \"loss_type\": \"mse\",  # Options: \"mse\", \"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"\n","    \"noise_factor\": 0.1,  # Noise factor for denoising autoencoders\n","    \"temperature\": 0.5,  # Temperature parameter for NT-Xent loss\n","    \"margin\": 1.0,  # Margin for Triplet Loss\n","    \"epochs\": 100,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-3,\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","    \"save_best\": True,  # Whether to save the best model\n","    \"save_path\": \"best_model.pth\",  # Path to save the best model\n","    \"beta\": 1.0,  # Weight for KL divergence (VAE only)\n","    \"alpha\": 0.5,  # Weight for contrastive or triplet loss\n","    \"fraction\": 0.01,  # Fraction of the dataset to use\n","    \"projection_dim\": None,  # Optional projection head dimension for VAEs\n","    \"strong_architecture\": False,  # Whether to use a deeper architecture for DenoisingAutoencoder\n","    \"input_shape\": (1, 28, 28),  # Input shape for FlexibleVAE and ImprovedFlexibleVAE\n","    \"patience\": 5,\n","    \"min_delta\": 0.001,\n","    \"triplet_data\": False,\n","}\n","\n","# ------------------------------\n","# Step 2: Load and Preprocess Data\n","# ------------------------------\n","\n","# Load Combined MNIST Dataset (Train + Test)\n","mnist_loader = data_utils.load_mnist_data(fraction=config[\"fraction\"], batch_size=config[\"batch_size\"], shuffle=True)\n","\n","# Inspect Combined Dataset\n","for batch in mnist_loader:\n","    images, labels = batch\n","    print(\"Batch Shape:\", images.shape, labels.shape)\n","    break\n","\n","# Visualize Original Images\n","n = 20\n","sample_indices = np.random.choice(len(mnist_loader.dataset), n, replace=False)\n","sampled_images = mnist_loader.dataset.tensors[0][sample_indices].numpy()\n","sampled_images = (sampled_images * 127.5 + 127.5).astype(np.uint8).squeeze()  # Denormalize for display\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, 10, i + 1)\n","    plt.imshow(sampled_images[i], cmap=\"gray\")\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()\n","\n","# ------------------------------\n","# Step 3: Initialize Model, Loss, and Optimizer\n","# ------------------------------\n","\n","# Initialize the model\n","# Initialize the model\n","model_classes = {\n","    \"BasicAutoencoder\": encoder_models.BasicAutoencoder,\n","    \"IntermediateAutoencoder\": encoder_models.IntermediateAutoencoder,\n","    \"AdvancedAutoencoder\": encoder_models.AdvancedAutoencoder,\n","    \"EnhancedAutoencoder\": encoder_models.EnhancedAutoencoder,\n","    \"BasicVAE\": encoder_models.BasicVAE,\n","    \"ImprovedVAE\": encoder_models.ImprovedVAE,\n","    \"FlexibleVAE\": encoder_models.FlexibleVAE,\n","    \"ImprovedFlexibleVAE\": encoder_models.ImprovedFlexibleVAE,\n","    \"DenoisingAutoencoder\": encoder_models.DenoisingAutoencoder,\n","}\n","\n","# Initialize model with appropriate arguments\n","if config[\"model_name\"] in [\"FlexibleVAE\", \"ImprovedFlexibleVAE\"]:\n","    model = model_classes[config[\"model_name\"]](\n","        input_shape=config[\"input_shape\"],\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"]\n","    ).to(config[\"device\"])\n","elif config[\"model_name\"] == \"DenoisingAutoencoder\":\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"],\n","        projection_dim=config[\"projection_dim\"],\n","        strong_architecture=config[\"strong_architecture\"]\n","    ).to(config[\"device\"])\n","else:\n","    model = model_classes[config[\"model_name\"]](\n","        code_dim=config[\"code_dim\"]\n","    ).to(config[\"device\"])\n","\n","# Define the loss function\n","if config[\"model_type\"] == \"vae\":\n","    criterion = losses.vae_loss  # Use VAE loss for VAEs\n","else:\n","    loss_functions = {\n","        \"mse\": nn.MSELoss(),  # Reconstruction loss\n","        \"vicreg\": cl_loss.VicRegLoss(lambda_var=25, mu_mean=25, nu_cov=1),  # VicReg loss\n","        \"ntxent\": cl_loss.NTXentLoss(temperature=config[\"temperature\"]),  # NT-Xent loss\n","        \"triplet\": cl_loss.TripletLoss(margin=config[\"margin\"]),  # Triplet loss\n","        \"contrastive\": cl_loss.contrastive_loss,  # Basic contrastive loss\n","        \"info_nce\": cl_loss.info_nce_loss,  # InfoNCE loss\n","        \"barlow_twins\": cl_loss.BarlowTwinsLoss(lambda_param=5e-3),  # Barlow Twins loss\n","        \"byol\": cl_loss.BYOLLoss(),  # BYOL loss\n","    }\n","    criterion = loss_functions[config[\"loss_type\"]]\n","\n","predictor = cl_loss.Predictor(input_dim=config[\"code_dim\"]).to(config[\"device\"])\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Define scheduler\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","\n","# ------------------------------\n","# Step 4: Train the Model\n","# ------------------------------\n","\n","if config[\"model_type\"] == \"autoencoder\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_autoencoder_v4(\n","        model=model,\n","        data_loader=mnist_loader,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        optimizer=optimizer,\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        scheduler=scheduler,\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"triplet\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        temperature=config[\"temperature\"],  # Pass temperature for NT-Xent, contrastive, and InfoNCE\n","        triplet_data=(config[\"loss_type\"] == \"triplet\"),  # Enable triplet data only for triplet loss\n","        augment_fn=cl_loss.augment if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\", \"barlow_twins\", \"byol\"] else None,\n","        predictor=predictor if config[\"loss_type\"] == \"byol\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"vae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_vae(\n","        vae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion,  # VAE loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        beta=config[\"beta\"],  # Weight for KL divergence\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","elif config[\"model_type\"] == \"dae\":\n","    print(f\"Training {config['model_name']} with {config['loss_type']} loss...\")\n","    encoder_training.train_dae(\n","        dae=model,\n","        train_loader=mnist_loader,\n","        optimizer=optimizer,\n","        loss_fn=criterion if config[\"loss_type\"] == \"mse\" else nn.MSELoss(),  # Reconstruction loss\n","        epochs=config[\"epochs\"],\n","        device=config[\"device\"],\n","        val_loader=None,  # No validation loader for simplicity\n","        scheduler=scheduler,\n","        save_best=config[\"save_best\"],\n","        save_path=config[\"save_path\"],\n","        noise_factor=config[\"noise_factor\"],  # Noise factor for denoising\n","        alpha=config[\"alpha\"],  # Weight for contrastive loss\n","        temperature=config[\"temperature\"],  # Temperature for NT-Xent, contrastive, and InfoNCE\n","        contrastive_loss_fn=criterion if config[\"loss_type\"] in [\"vicreg\", \"ntxent\", \"contrastive\", \"info_nce\"] else None,\n","        triplet_loss_fn=criterion if config[\"loss_type\"] == \"triplet\" else None,\n","        ssim_func=losses.ssim if config[\"loss_type\"] == \"ssim\" else None,\n","        patience=config[\"patience\"],\n","        min_delta=config[\"min_delta\"],\n","    )\n","\n","# ------------------------------\n","# Step 5: Save Embeddings and Model\n","# ------------------------------\n","\n","# Generate embeddings\n","embeddings, labels = data_utils.generate_embeddings(\n","    model=model,\n","    embedding_type=config[\"model_type\"],\n","    data_loader=mnist_loader,\n","    device=config[\"device\"],\n",")\n","\n","# Define the base storage directory for embeddings\n","base_dir = \"./saved_embeddings\"\n","os.makedirs(base_dir, exist_ok=True)\n","\n","# Ensure a dedicated directory for embeddings\n","embeddings_dir = os.path.join(base_dir, \"embeddings\")\n","os.makedirs(embeddings_dir, exist_ok=True)\n","\n","# Create a unique subdirectory for this embedding type, model, and loss type\n","embedding_subdir = f\"{config['model_type']}_{config['model_name']}_{config['loss_type']}\"\n","embedding_dir = os.path.join(embeddings_dir, embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","# Choose saving format: default is .pt, but .npy can be chosen\n","save_format = \"pt\"  # Change to \"npy\" for NumPy format\n","\n","# Save embeddings with differentiated names based on the model, loss type, and embedding type\n","if save_format == \"pt\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.pt\")\n","    torch.save({\"embeddings\": embeddings, \"labels\": labels}, embedding_file)\n","    print(f\"Embeddings saved in PyTorch format: {embedding_file}\")\n","elif save_format == \"npy\":\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_embeddings.npy\")\n","    np.save(embedding_file, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    print(f\"Embeddings saved in NumPy format: {embedding_file}\")\n","else:\n","    raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# Save the model\n","model_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}.pth\")\n","torch.save(model.state_dict(), model_file)\n","print(f\"Model saved: {model_file}\")\n","\n","# ------------------------------\n","# Step 6: Visualize Embeddings\n","# ------------------------------\n","\n","# Visualize embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"X4tX6ui8MaS5","executionInfo":{"status":"error","timestamp":1737827149791,"user_tz":-210,"elapsed":2149,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"63bf3c7f-c775-4e67-f5bf-5aae51884abd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampled Dataset: (700, 1, 28, 28) (700,)\n","Batch Shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x400 with 20 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"module 'src.cl_loss_function' has no attribute 'BarlowTwinsLoss'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-9f8d131045ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;34m\"contrastive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcl_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrastive_loss\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Basic contrastive loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;34m\"info_nce\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcl_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_nce_loss\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# InfoNCE loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;34m\"barlow_twins\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcl_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBarlowTwinsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Barlow Twins loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;34m\"byol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcl_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYOLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# BYOL loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     }\n","\u001b[0;31mAttributeError\u001b[0m: module 'src.cl_loss_function' has no attribute 'BarlowTwinsLoss'"]}]},{"cell_type":"code","source":["from src.embeddings.encoder_models import (\n","    process_matrix_factorization,\n","    apply_sift,\n","    process_feature_extraction,\n","    NormalizingFlowModel,\n","    train_nf_model,\n",")\n","\n","# ------------------------------\n","# Configuration Dictionary\n","# ------------------------------\n","\n","config = {\n","    # Save format and paths\n","    \"save_format\": \"pt\",  # Options: \"pt\" (PyTorch) or \"npy\" (NumPy)\n","    \"base_dir\": \"./saved_embeddings\",\n","    \"embeddings_dir\": \"./saved_embeddings/embeddings\",\n","\n","    # Model and loss naming\n","    \"model_name\": \"matrix_factorization\",\n","    \"loss_type\": \"default_loss\",\n","\n","    # Data settings\n","    \"n_components\": 50,  # Number of components for dimensionality reduction\n","    \"n_features\": 50,  # Number of features for SIFT\n","    \"kernel\": \"rbf\",  # Kernel for Kernel PCA\n","\n","    # Normalizing Flow settings\n","    \"num_flows\": 4,\n","    \"num_epochs\": 100,\n","    \"learning_rate\": 1e-3,\n","    \"batch_size\": 128,\n","\n","    # Device (CPU/GPU)\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","}\n","\n","# Ensure valid save format\n","if config[\"save_format\"] not in [\"pt\", \"npy\"]:\n","    print(f\"Invalid save format: {config['save_format']}. Defaulting to 'pt'.\")\n","    config[\"save_format\"] = \"pt\"\n","\n","# Create directories if they don't exist\n","os.makedirs(config[\"base_dir\"], exist_ok=True)\n","os.makedirs(config[\"embeddings_dir\"], exist_ok=True)\n","\n","# ------------------------------\n","# Helper Function to Save Embeddings\n","# ------------------------------\n","\n","def save_embeddings(embeddings, labels, file_path, save_format):\n","    \"\"\"Save embeddings and labels in the specified format.\"\"\"\n","    if save_format == \"pt\":\n","        torch.save({\"embeddings\": embeddings, \"labels\": labels}, file_path)\n","    elif save_format == \"npy\":\n","        np.save(file_path, {\"embeddings\": embeddings.numpy(), \"labels\": labels.numpy()})\n","    else:\n","        raise ValueError(f\"Unsupported save format: {save_format}\")\n","\n","# ------------------------------\n","# Step 1: Load Data\n","# ------------------------------\n","\n","# Extract flattened images and labels\n","sampled_x, sampled_y = mnist_loader.dataset.tensors[0].numpy(), mnist_loader.dataset.tensors[1].numpy()\n","\n","# ------------------------------\n","# Step 2: Matrix Factorization\n","# ------------------------------\n","\n","print(\"Processing matrix factorization models (PCA, SVD, NMF)...\")\n","factorized_embeddings, factorized_labels = process_matrix_factorization(\n","    sampled_x, sampled_y, n_components=config[\"n_components\"]\n",")\n","\n","for method, embeddings in factorized_embeddings.items():\n","    embedding_subdir = f\"matrix_factorization_{method}\"\n","    embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","    os.makedirs(embedding_dir, exist_ok=True)\n","\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_{method}_embeddings.{config['save_format']}\")\n","    save_embeddings(embeddings, factorized_labels, embedding_file, config[\"save_format\"])\n","    print(f\"{method} embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 3: SIFT Features\n","# ------------------------------\n","\n","print(\"Processing SIFT features...\")\n","sift_features = apply_sift(sampled_x, n_features=config[\"n_features\"])\n","sift_labels = torch.tensor(sampled_y, dtype=torch.long)\n","\n","embedding_subdir = \"sift_features\"\n","embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","os.makedirs(embedding_dir, exist_ok=True)\n","\n","embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_sift_embeddings.{config['save_format']}\")\n","save_embeddings(sift_features, sift_labels, embedding_file, config[\"save_format\"])\n","print(f\"SIFT embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 4: Kernel PCA\n","# ------------------------------\n","\n","print(\"Processing Kernel PCA...\")\n","kernel_pca_features, kernel_pca_labels = process_feature_extraction(\n","    sampled_x, sampled_y, n_features=config[\"n_features\"], kernel=config[\"kernel\"], n_components=config[\"n_components\"]\n",")\n","\n","for method, embeddings in kernel_pca_features.items():\n","    embedding_subdir = f\"kernel_pca_{method}\"\n","    embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","    os.makedirs(embedding_dir, exist_ok=True)\n","\n","    embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_kernel_pca_{method}_embeddings.{config['save_format']}\")\n","    save_embeddings(embeddings, kernel_pca_labels, embedding_file, config[\"save_format\"])\n","    print(f\"{method} Kernel PCA embeddings saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","# ------------------------------\n","# Step 5: Normalizing Flow\n","# ------------------------------\n","\n","print(\"Processing Normalizing Flow...\")\n","for method, embeddings in factorized_embeddings.items():\n","    # Initialize and train Normalizing Flow model\n","    input_dim = embeddings.size(1)\n","    nf_model = NormalizingFlowModel(input_dim=input_dim, num_flows=config[\"num_flows\"]).to(config[\"device\"])\n","    trained_nf_model = train_nf_model(\n","        nf_model, embeddings, num_epochs=config[\"num_epochs\"], lr=config[\"learning_rate\"], batch_size=config[\"batch_size\"]\n","    )\n","\n","    # Refine embeddings\n","    with torch.no_grad():\n","        refined_embeddings, _ = trained_nf_model(embeddings)\n","\n","        embedding_subdir = f\"normalizing_flow_{method}\"\n","        embedding_dir = os.path.join(config[\"embeddings_dir\"], embedding_subdir)\n","        os.makedirs(embedding_dir, exist_ok=True)\n","\n","        embedding_file = os.path.join(embedding_dir, f\"{config['model_name']}_{config['loss_type']}_normalizing_flow_{method}_refined_embeddings.{config['save_format']}\")\n","        save_embeddings(refined_embeddings, factorized_labels, embedding_file, config[\"save_format\"])\n","        print(f\"{method} refined embeddings (Normalizing Flow) saved in {'PyTorch' if config['save_format'] == 'pt' else 'NumPy'} format: {embedding_file}\")\n","\n","print(\"Feature extraction and normalizing flow processing complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvEe15hwu6wG","executionInfo":{"status":"ok","timestamp":1737827138070,"user_tz":-210,"elapsed":39624,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"538764f7-bb0f-483b-df1a-e6ec6f976c8a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing matrix factorization models (PCA, SVD, NMF)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1742: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["PCA embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_PCA/matrix_factorization_default_loss_PCA_embeddings.pt\n","SVD embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_SVD/matrix_factorization_default_loss_SVD_embeddings.pt\n","NMF embeddings saved in PyTorch format: ./saved_embeddings/embeddings/matrix_factorization_NMF/matrix_factorization_default_loss_NMF_embeddings.pt\n","Processing SIFT features...\n","SIFT embeddings saved in PyTorch format: ./saved_embeddings/embeddings/sift_features/matrix_factorization_default_loss_sift_embeddings.pt\n","Processing Kernel PCA...\n","SIFT Kernel PCA embeddings saved in PyTorch format: ./saved_embeddings/embeddings/kernel_pca_SIFT/matrix_factorization_default_loss_kernel_pca_SIFT_embeddings.pt\n","Kernel PCA Kernel PCA embeddings saved in PyTorch format: ./saved_embeddings/embeddings/kernel_pca_Kernel PCA/matrix_factorization_default_loss_kernel_pca_Kernel PCA_embeddings.pt\n","Processing Normalizing Flow...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/100: 100%|██████████| 6/6 [00:00<00:00, 36.57it/s, loss=2.07e+6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 3358708.4375\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/100: 100%|██████████| 6/6 [00:00<00:00, 107.73it/s, loss=7.67e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100, Loss: 2421180.1562\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/100: 100%|██████████| 6/6 [00:00<00:00, 81.05it/s, loss=1.28e+6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/100, Loss: 1847919.9583\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/100: 100%|██████████| 6/6 [00:00<00:00, 69.78it/s, loss=6.37e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/100, Loss: 1471227.9167\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/100: 100%|██████████| 6/6 [00:00<00:00, 84.62it/s, loss=4.63e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/100, Loss: 1251132.6458\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/100: 100%|██████████| 6/6 [00:00<00:00, 85.21it/s, loss=4.12e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/100, Loss: 1145675.3698\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/100: 100%|██████████| 6/6 [00:00<00:00, 81.63it/s, loss=3.62e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/100, Loss: 964567.2292\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/100: 100%|██████████| 6/6 [00:00<00:00, 83.97it/s, loss=3.18e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/100, Loss: 852232.8125\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/100: 100%|██████████| 6/6 [00:00<00:00, 107.51it/s, loss=5.24e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/100, Loss: 773914.8542\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/100: 100%|██████████| 6/6 [00:00<00:00, 106.12it/s, loss=3.87e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/100, Loss: 681183.7708\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/100: 100%|██████████| 6/6 [00:00<00:00, 108.85it/s, loss=2.09e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/100, Loss: 597496.1615\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/100: 100%|██████████| 6/6 [00:00<00:00, 97.27it/s, loss=4.3e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/100, Loss: 529674.9219\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/100: 100%|██████████| 6/6 [00:00<00:00, 90.65it/s, loss=1.75e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/100, Loss: 479913.4297\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/100: 100%|██████████| 6/6 [00:00<00:00, 101.71it/s, loss=3.19e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/100, Loss: 429102.1875\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/100: 100%|██████████| 6/6 [00:00<00:00, 98.08it/s, loss=1.53e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/100, Loss: 394330.2578\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/100: 100%|██████████| 6/6 [00:00<00:00, 86.20it/s, loss=1.97e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/100, Loss: 362477.1484\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/100: 100%|██████████| 6/6 [00:00<00:00, 86.77it/s, loss=1.46e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/100, Loss: 340135.8021\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/100: 100%|██████████| 6/6 [00:00<00:00, 70.91it/s, loss=1.18e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/100, Loss: 314237.1810\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/100: 100%|██████████| 6/6 [00:00<00:00, 81.17it/s, loss=1.55e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/100, Loss: 291413.4427\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/100: 100%|██████████| 6/6 [00:00<00:00, 79.56it/s, loss=1.56e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/100, Loss: 290707.3542\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/100: 100%|██████████| 6/6 [00:00<00:00, 79.78it/s, loss=1.09e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/100, Loss: 278803.9284\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/100: 100%|██████████| 6/6 [00:00<00:00, 74.38it/s, loss=1.77e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/100, Loss: 238892.1484\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/100: 100%|██████████| 6/6 [00:00<00:00, 80.61it/s, loss=1.1e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/100, Loss: 222431.6576\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/100: 100%|██████████| 6/6 [00:00<00:00, 88.80it/s, loss=6.85e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/100, Loss: 207214.7018\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25/100: 100%|██████████| 6/6 [00:00<00:00, 82.08it/s, loss=1.12e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/100, Loss: 199458.5755\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 26/100: 100%|██████████| 6/6 [00:00<00:00, 76.88it/s, loss=8.64e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/100, Loss: 186315.3945\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 27/100: 100%|██████████| 6/6 [00:00<00:00, 87.14it/s, loss=8.48e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27/100, Loss: 178262.0560\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 28/100: 100%|██████████| 6/6 [00:00<00:00, 95.33it/s, loss=84156.0]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28/100, Loss: 167682.5859\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 29/100: 100%|██████████| 6/6 [00:00<00:00, 88.11it/s, loss=6.83e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29/100, Loss: 160388.3893\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 30/100: 100%|██████████| 6/6 [00:00<00:00, 79.89it/s, loss=6.82e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30/100, Loss: 152936.5846\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 31/100: 100%|██████████| 6/6 [00:00<00:00, 72.68it/s, loss=6.38e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/100, Loss: 145889.3184\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 32/100: 100%|██████████| 6/6 [00:00<00:00, 82.38it/s, loss=7.9e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/100, Loss: 139763.9167\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 33/100: 100%|██████████| 6/6 [00:00<00:00, 68.67it/s, loss=5.41e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33/100, Loss: 133955.5905\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 34/100: 100%|██████████| 6/6 [00:00<00:00, 78.86it/s, loss=8.38e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/100, Loss: 128101.5221\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 35/100: 100%|██████████| 6/6 [00:00<00:00, 71.97it/s, loss=4.97e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/100, Loss: 122939.9733\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 36/100: 100%|██████████| 6/6 [00:00<00:00, 83.57it/s, loss=6.21e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36/100, Loss: 118031.4922\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 37/100: 100%|██████████| 6/6 [00:00<00:00, 86.68it/s, loss=5.16e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37/100, Loss: 113217.8691\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 38/100: 100%|██████████| 6/6 [00:00<00:00, 77.16it/s, loss=5.4e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38/100, Loss: 108768.2956\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 39/100: 100%|██████████| 6/6 [00:00<00:00, 102.11it/s, loss=4.5e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/100, Loss: 104747.7949\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 40/100: 100%|██████████| 6/6 [00:00<00:00, 88.08it/s, loss=6.76e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/100, Loss: 100538.6341\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 41/100: 100%|██████████| 6/6 [00:00<00:00, 78.83it/s, loss=4.37e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41/100, Loss: 96904.3444\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 42/100: 100%|██████████| 6/6 [00:00<00:00, 96.72it/s, loss=4.14e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42/100, Loss: 93436.9753\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 43/100: 100%|██████████| 6/6 [00:00<00:00, 86.00it/s, loss=5.47e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43/100, Loss: 89912.4876\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 44/100: 100%|██████████| 6/6 [00:00<00:00, 98.62it/s, loss=5.63e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44/100, Loss: 86996.9225\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 45/100: 100%|██████████| 6/6 [00:00<00:00, 98.84it/s, loss=4.22e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45/100, Loss: 84351.9759\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 46/100: 100%|██████████| 6/6 [00:00<00:00, 101.57it/s, loss=4.32e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46/100, Loss: 81205.8405\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 47/100: 100%|██████████| 6/6 [00:00<00:00, 100.49it/s, loss=3.48e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47/100, Loss: 78411.0033\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 48/100: 100%|██████████| 6/6 [00:00<00:00, 98.18it/s, loss=3.65e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48/100, Loss: 75849.1829\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 49/100: 100%|██████████| 6/6 [00:00<00:00, 106.14it/s, loss=5.49e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49/100, Loss: 73511.2305\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 50/100: 100%|██████████| 6/6 [00:00<00:00, 100.09it/s, loss=3.21e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50/100, Loss: 71467.8600\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 51/100: 100%|██████████| 6/6 [00:00<00:00, 101.90it/s, loss=3.37e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51/100, Loss: 69202.5221\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 52/100: 100%|██████████| 6/6 [00:00<00:00, 100.43it/s, loss=4.22e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52/100, Loss: 67169.2773\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 53/100: 100%|██████████| 6/6 [00:00<00:00, 97.12it/s, loss=3.95e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53/100, Loss: 65240.4076\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 54/100: 100%|██████████| 6/6 [00:00<00:00, 81.58it/s, loss=2.94e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54/100, Loss: 63348.4551\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 55/100: 100%|██████████| 6/6 [00:00<00:00, 83.09it/s, loss=2.58e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55/100, Loss: 61536.6569\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 56/100: 100%|██████████| 6/6 [00:00<00:00, 88.40it/s, loss=2.49e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56/100, Loss: 59762.9795\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 57/100: 100%|██████████| 6/6 [00:00<00:00, 85.10it/s, loss=3.22e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57/100, Loss: 58057.9798\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 58/100: 100%|██████████| 6/6 [00:00<00:00, 64.33it/s, loss=2.43e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58/100, Loss: 56409.8597\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 59/100: 100%|██████████| 6/6 [00:00<00:00, 83.43it/s, loss=3.08e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59/100, Loss: 54758.1706\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 60/100: 100%|██████████| 6/6 [00:00<00:00, 85.89it/s, loss=3.06e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60/100, Loss: 53477.2435\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 61/100: 100%|██████████| 6/6 [00:00<00:00, 83.39it/s, loss=2.8e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61/100, Loss: 51979.7142\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 62/100: 100%|██████████| 6/6 [00:00<00:00, 68.17it/s, loss=2.42e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62/100, Loss: 50955.9232\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 63/100: 100%|██████████| 6/6 [00:00<00:00, 83.03it/s, loss=2.02e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63/100, Loss: 50059.9313\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 64/100: 100%|██████████| 6/6 [00:00<00:00, 76.10it/s, loss=2.37e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64/100, Loss: 48892.0033\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 65/100: 100%|██████████| 6/6 [00:00<00:00, 91.37it/s, loss=1.91e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65/100, Loss: 47641.3688\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 66/100: 100%|██████████| 6/6 [00:00<00:00, 75.20it/s, loss=2.54e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66/100, Loss: 46573.9515\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 67/100: 100%|██████████| 6/6 [00:00<00:00, 77.14it/s, loss=2.66e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67/100, Loss: 45430.9251\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 68/100: 100%|██████████| 6/6 [00:00<00:00, 37.63it/s, loss=2.1e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68/100, Loss: 44408.0306\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 69/100: 100%|██████████| 6/6 [00:00<00:00, 39.11it/s, loss=2.15e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69/100, Loss: 43342.6315\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 70/100: 100%|██████████| 6/6 [00:00<00:00, 33.69it/s, loss=2.1e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70/100, Loss: 42381.0215\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 71/100: 100%|██████████| 6/6 [00:00<00:00, 69.35it/s, loss=2.09e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71/100, Loss: 41489.6631\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 72/100: 100%|██████████| 6/6 [00:00<00:00, 74.82it/s, loss=2.54e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72/100, Loss: 40590.6426\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 73/100: 100%|██████████| 6/6 [00:00<00:00, 74.55it/s, loss=2e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73/100, Loss: 39775.6618\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 74/100: 100%|██████████| 6/6 [00:00<00:00, 42.54it/s, loss=1.95e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74/100, Loss: 38931.5667\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 75/100: 100%|██████████| 6/6 [00:00<00:00, 62.28it/s, loss=2.07e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75/100, Loss: 38064.4867\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 76/100: 100%|██████████| 6/6 [00:00<00:00, 80.66it/s, loss=1.72e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76/100, Loss: 37216.5501\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 77/100: 100%|██████████| 6/6 [00:00<00:00, 67.33it/s, loss=1.55e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77/100, Loss: 36429.3504\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 78/100: 100%|██████████| 6/6 [00:00<00:00, 65.46it/s, loss=1.9e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78/100, Loss: 35686.0915\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 79/100: 100%|██████████| 6/6 [00:00<00:00, 66.23it/s, loss=1.75e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79/100, Loss: 34992.1217\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 80/100: 100%|██████████| 6/6 [00:00<00:00, 74.96it/s, loss=1.41e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80/100, Loss: 34316.6235\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 81/100: 100%|██████████| 6/6 [00:00<00:00, 86.02it/s, loss=2.1e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81/100, Loss: 33686.7214\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 82/100: 100%|██████████| 6/6 [00:00<00:00, 61.38it/s, loss=1.78e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82/100, Loss: 33068.7715\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 83/100: 100%|██████████| 6/6 [00:00<00:00, 20.25it/s, loss=1.6e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83/100, Loss: 32472.2646\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 84/100: 100%|██████████| 6/6 [00:00<00:00, 26.08it/s, loss=1.47e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84/100, Loss: 31874.8514\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 85/100: 100%|██████████| 6/6 [00:00<00:00, 44.20it/s, loss=1.74e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85/100, Loss: 31250.9049\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 86/100: 100%|██████████| 6/6 [00:00<00:00, 56.69it/s, loss=1.4e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86/100, Loss: 30678.5666\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 87/100: 100%|██████████| 6/6 [00:00<00:00, 49.20it/s, loss=1.55e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87/100, Loss: 30157.6507\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 88/100: 100%|██████████| 6/6 [00:00<00:00, 62.85it/s, loss=1.66e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88/100, Loss: 29618.8926\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 89/100: 100%|██████████| 6/6 [00:00<00:00, 48.00it/s, loss=1.54e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89/100, Loss: 29256.7609\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 90/100: 100%|██████████| 6/6 [00:00<00:00, 74.49it/s, loss=1.47e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90/100, Loss: 28672.9494\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 91/100: 100%|██████████| 6/6 [00:00<00:00, 52.99it/s, loss=1.65e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91/100, Loss: 28188.0859\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 92/100: 100%|██████████| 6/6 [00:00<00:00, 63.30it/s, loss=1.39e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92/100, Loss: 27735.6774\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 93/100: 100%|██████████| 6/6 [00:00<00:00, 79.98it/s, loss=1.47e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93/100, Loss: 27292.6880\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 94/100: 100%|██████████| 6/6 [00:00<00:00, 53.58it/s, loss=1.34e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94/100, Loss: 26823.1232\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 95/100: 100%|██████████| 6/6 [00:00<00:00, 52.85it/s, loss=1.24e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95/100, Loss: 26418.6688\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 96/100: 100%|██████████| 6/6 [00:00<00:00, 78.69it/s, loss=1.34e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96/100, Loss: 26004.0822\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 97/100: 100%|██████████| 6/6 [00:00<00:00, 83.10it/s, loss=1.19e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97/100, Loss: 25667.7428\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 98/100: 100%|██████████| 6/6 [00:00<00:00, 93.44it/s, loss=1e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98/100, Loss: 25269.3530\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 99/100: 100%|██████████| 6/6 [00:00<00:00, 92.91it/s, loss=1.22e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99/100, Loss: 24884.7345\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 100/100: 100%|██████████| 6/6 [00:00<00:00, 93.22it/s, loss=1.12e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100/100, Loss: 24520.1574\n","PCA refined embeddings (Normalizing Flow) saved in PyTorch format: ./saved_embeddings/embeddings/normalizing_flow_PCA/matrix_factorization_default_loss_normalizing_flow_PCA_refined_embeddings.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/100: 100%|██████████| 6/6 [00:00<00:00, 62.82it/s, loss=2.08e+6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 3476399.4792\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/100: 100%|██████████| 6/6 [00:00<00:00, 73.00it/s, loss=1.56e+6]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100, Loss: 2232664.2917\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/100: 100%|██████████| 6/6 [00:00<00:00, 83.20it/s, loss=6.75e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/100, Loss: 1731757.9583\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/100: 100%|██████████| 6/6 [00:00<00:00, 77.65it/s, loss=5.32e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/100, Loss: 1374345.9583\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/100: 100%|██████████| 6/6 [00:00<00:00, 73.23it/s, loss=6.47e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/100, Loss: 1154157.3229\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/100: 100%|██████████| 6/6 [00:00<00:00, 52.86it/s, loss=4.06e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/100, Loss: 1002222.1562\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/100: 100%|██████████| 6/6 [00:00<00:00, 70.09it/s, loss=3.98e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/100, Loss: 871659.7708\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/100: 100%|██████████| 6/6 [00:00<00:00, 96.65it/s, loss=7.52e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/100, Loss: 752746.9271\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/100: 100%|██████████| 6/6 [00:00<00:00, 101.07it/s, loss=3.16e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/100, Loss: 660082.9740\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/100: 100%|██████████| 6/6 [00:00<00:00, 93.56it/s, loss=4e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/100, Loss: 570510.6094\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/100: 100%|██████████| 6/6 [00:00<00:00, 59.93it/s, loss=1.84e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/100, Loss: 513269.3698\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/100: 100%|██████████| 6/6 [00:00<00:00, 60.39it/s, loss=1.77e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/100, Loss: 475452.8255\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/100: 100%|██████████| 6/6 [00:00<00:00, 55.10it/s, loss=3.09e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/100, Loss: 447217.4948\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/100: 100%|██████████| 6/6 [00:00<00:00, 67.40it/s, loss=2.05e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/100, Loss: 410697.2370\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/100: 100%|██████████| 6/6 [00:00<00:00, 76.08it/s, loss=1.29e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/100, Loss: 380160.4831\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/100: 100%|██████████| 6/6 [00:00<00:00, 92.95it/s, loss=1.76e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/100, Loss: 353773.5755\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/100: 100%|██████████| 6/6 [00:00<00:00, 96.36it/s, loss=1.02e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/100, Loss: 326704.5495\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/100: 100%|██████████| 6/6 [00:00<00:00, 67.90it/s, loss=1.3e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/100, Loss: 304544.5716\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/100: 100%|██████████| 6/6 [00:00<00:00, 67.49it/s, loss=1.16e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/100, Loss: 284459.7096\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/100: 100%|██████████| 6/6 [00:00<00:00, 66.10it/s, loss=2.43e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/100, Loss: 266055.6562\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/100: 100%|██████████| 6/6 [00:00<00:00, 54.80it/s, loss=1.03e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/100, Loss: 254308.7018\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/100: 100%|██████████| 6/6 [00:00<00:00, 48.67it/s, loss=1.84e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/100, Loss: 239262.2630\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/100: 100%|██████████| 6/6 [00:00<00:00, 59.76it/s, loss=1.24e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/100, Loss: 224476.8216\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/100: 100%|██████████| 6/6 [00:00<00:00, 79.46it/s, loss=1.3e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/100, Loss: 211794.5508\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25/100: 100%|██████████| 6/6 [00:00<00:00, 50.80it/s, loss=1.08e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/100, Loss: 201029.0560\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 26/100: 100%|██████████| 6/6 [00:00<00:00, 56.51it/s, loss=1.66e+5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/100, Loss: 190888.8880\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 27/100: 100%|██████████| 6/6 [00:00<00:00, 61.48it/s, loss=8.63e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27/100, Loss: 180271.5052\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 28/100: 100%|██████████| 6/6 [00:00<00:00, 55.47it/s, loss=7.32e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28/100, Loss: 169998.5768\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 29/100: 100%|██████████| 6/6 [00:00<00:00, 63.53it/s, loss=7.59e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29/100, Loss: 161238.2878\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 30/100: 100%|██████████| 6/6 [00:00<00:00, 80.84it/s, loss=7.11e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30/100, Loss: 152895.3880\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 31/100: 100%|██████████| 6/6 [00:00<00:00, 66.66it/s, loss=6.26e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/100, Loss: 146677.0345\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 32/100: 100%|██████████| 6/6 [00:00<00:00, 72.11it/s, loss=5.86e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/100, Loss: 140104.4850\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 33/100: 100%|██████████| 6/6 [00:00<00:00, 68.64it/s, loss=6.66e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33/100, Loss: 133945.3633\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 34/100: 100%|██████████| 6/6 [00:00<00:00, 74.95it/s, loss=8.75e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/100, Loss: 128261.6693\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 35/100: 100%|██████████| 6/6 [00:00<00:00, 66.55it/s, loss=5.83e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/100, Loss: 123280.9766\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 36/100: 100%|██████████| 6/6 [00:00<00:00, 73.08it/s, loss=5.8e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36/100, Loss: 118371.5436\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 37/100: 100%|██████████| 6/6 [00:00<00:00, 68.43it/s, loss=5.43e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37/100, Loss: 112770.4167\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 38/100: 100%|██████████| 6/6 [00:00<00:00, 84.23it/s, loss=5.61e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38/100, Loss: 107955.6016\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 39/100: 100%|██████████| 6/6 [00:00<00:00, 72.73it/s, loss=6.32e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/100, Loss: 104104.2760\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 40/100: 100%|██████████| 6/6 [00:00<00:00, 80.99it/s, loss=6e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/100, Loss: 100195.2259\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 41/100: 100%|██████████| 6/6 [00:00<00:00, 69.22it/s, loss=3.73e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41/100, Loss: 96786.6764\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 42/100: 100%|██████████| 6/6 [00:00<00:00, 59.82it/s, loss=4.32e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42/100, Loss: 93491.1556\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 43/100: 100%|██████████| 6/6 [00:00<00:00, 52.13it/s, loss=4.7e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43/100, Loss: 90280.1823\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 44/100: 100%|██████████| 6/6 [00:00<00:00, 68.61it/s, loss=3.57e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44/100, Loss: 87283.3919\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 45/100: 100%|██████████| 6/6 [00:00<00:00, 51.36it/s, loss=4.86e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45/100, Loss: 84214.1432\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 46/100: 100%|██████████| 6/6 [00:00<00:00, 45.16it/s, loss=4.24e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46/100, Loss: 81449.0169\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 47/100: 100%|██████████| 6/6 [00:00<00:00, 53.82it/s, loss=4.4e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47/100, Loss: 78686.7493\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 48/100: 100%|██████████| 6/6 [00:00<00:00, 49.13it/s, loss=3.66e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48/100, Loss: 76305.7148\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 49/100: 100%|██████████| 6/6 [00:00<00:00, 45.37it/s, loss=4.12e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49/100, Loss: 74161.8496\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 50/100: 100%|██████████| 6/6 [00:00<00:00, 62.79it/s, loss=2.79e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50/100, Loss: 71662.7679\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 51/100: 100%|██████████| 6/6 [00:00<00:00, 61.12it/s, loss=3.88e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51/100, Loss: 69514.7181\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 52/100: 100%|██████████| 6/6 [00:00<00:00, 62.31it/s, loss=3.6e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52/100, Loss: 67427.9486\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 53/100: 100%|██████████| 6/6 [00:00<00:00, 56.26it/s, loss=3.16e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53/100, Loss: 65497.0153\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 54/100: 100%|██████████| 6/6 [00:00<00:00, 56.25it/s, loss=3.66e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54/100, Loss: 63725.0111\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 55/100: 100%|██████████| 6/6 [00:00<00:00, 55.93it/s, loss=2.57e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55/100, Loss: 61889.7406\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 56/100: 100%|██████████| 6/6 [00:00<00:00, 59.47it/s, loss=2.9e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56/100, Loss: 59982.8893\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 57/100: 100%|██████████| 6/6 [00:00<00:00, 75.87it/s, loss=2.84e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57/100, Loss: 58352.9840\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 58/100: 100%|██████████| 6/6 [00:00<00:00, 71.96it/s, loss=2.72e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58/100, Loss: 56761.4736\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 59/100: 100%|██████████| 6/6 [00:00<00:00, 69.44it/s, loss=2.9e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59/100, Loss: 55969.0863\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 60/100: 100%|██████████| 6/6 [00:00<00:00, 62.60it/s, loss=3.19e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60/100, Loss: 53836.5290\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 61/100: 100%|██████████| 6/6 [00:00<00:00, 68.14it/s, loss=2.57e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61/100, Loss: 52827.3542\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 62/100: 100%|██████████| 6/6 [00:00<00:00, 87.05it/s, loss=2.97e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62/100, Loss: 51918.7848\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 63/100: 100%|██████████| 6/6 [00:00<00:00, 95.57it/s, loss=2.6e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63/100, Loss: 50376.6755\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 64/100: 100%|██████████| 6/6 [00:00<00:00, 94.71it/s, loss=2.39e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64/100, Loss: 49123.5387\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 65/100: 100%|██████████| 6/6 [00:00<00:00, 88.39it/s, loss=2.58e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65/100, Loss: 48050.8206\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 66/100: 100%|██████████| 6/6 [00:00<00:00, 90.02it/s, loss=2.41e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66/100, Loss: 47204.7093\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 67/100: 100%|██████████| 6/6 [00:00<00:00, 79.96it/s, loss=2.05e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67/100, Loss: 46150.4261\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 68/100: 100%|██████████| 6/6 [00:00<00:00, 98.69it/s, loss=1.93e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68/100, Loss: 44750.4255\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 69/100: 100%|██████████| 6/6 [00:00<00:00, 92.57it/s, loss=2.01e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69/100, Loss: 43776.3197\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 70/100: 100%|██████████| 6/6 [00:00<00:00, 90.99it/s, loss=2.4e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70/100, Loss: 42728.7539\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 71/100: 100%|██████████| 6/6 [00:00<00:00, 92.06it/s, loss=2.15e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71/100, Loss: 41675.0814\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 72/100: 100%|██████████| 6/6 [00:00<00:00, 86.01it/s, loss=2.63e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72/100, Loss: 40755.0560\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 73/100: 100%|██████████| 6/6 [00:00<00:00, 84.84it/s, loss=2.17e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73/100, Loss: 39786.0166\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 74/100: 100%|██████████| 6/6 [00:00<00:00, 79.13it/s, loss=2.39e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74/100, Loss: 38890.6956\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 75/100: 100%|██████████| 6/6 [00:00<00:00, 71.25it/s, loss=2.21e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75/100, Loss: 38174.7100\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 76/100: 100%|██████████| 6/6 [00:00<00:00, 77.14it/s, loss=1.82e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76/100, Loss: 37380.4066\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 77/100: 100%|██████████| 6/6 [00:00<00:00, 76.36it/s, loss=1.71e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77/100, Loss: 36571.8333\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 78/100: 100%|██████████| 6/6 [00:00<00:00, 82.04it/s, loss=2.16e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78/100, Loss: 35875.1862\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 79/100: 100%|██████████| 6/6 [00:00<00:00, 84.06it/s, loss=1.8e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79/100, Loss: 35155.3327\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 80/100: 100%|██████████| 6/6 [00:00<00:00, 80.75it/s, loss=1.57e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80/100, Loss: 34465.4357\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 81/100: 100%|██████████| 6/6 [00:00<00:00, 71.48it/s, loss=1.96e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81/100, Loss: 33816.9616\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 82/100: 100%|██████████| 6/6 [00:00<00:00, 77.71it/s, loss=1.55e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82/100, Loss: 33184.0052\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 83/100: 100%|██████████| 6/6 [00:00<00:00, 71.50it/s, loss=1.84e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83/100, Loss: 32639.7604\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 84/100: 100%|██████████| 6/6 [00:00<00:00, 77.26it/s, loss=1.56e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84/100, Loss: 31944.7549\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 85/100: 100%|██████████| 6/6 [00:00<00:00, 83.83it/s, loss=1.5e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85/100, Loss: 31447.3758\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 86/100: 100%|██████████| 6/6 [00:00<00:00, 66.06it/s, loss=1.2e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86/100, Loss: 30878.4017\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 87/100: 100%|██████████| 6/6 [00:00<00:00, 81.37it/s, loss=1.42e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87/100, Loss: 30201.3438\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 88/100: 100%|██████████| 6/6 [00:00<00:00, 68.89it/s, loss=1.68e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88/100, Loss: 29612.4339\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 89/100: 100%|██████████| 6/6 [00:00<00:00, 78.99it/s, loss=1.2e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89/100, Loss: 29501.9725\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 90/100: 100%|██████████| 6/6 [00:00<00:00, 84.50it/s, loss=1.59e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90/100, Loss: 28635.2629\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 91/100: 100%|██████████| 6/6 [00:00<00:00, 80.83it/s, loss=1.37e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91/100, Loss: 28175.1416\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 92/100: 100%|██████████| 6/6 [00:00<00:00, 90.08it/s, loss=1.4e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92/100, Loss: 27737.5150\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 93/100: 100%|██████████| 6/6 [00:00<00:00, 80.30it/s, loss=1.64e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93/100, Loss: 27284.9798\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 94/100: 100%|██████████| 6/6 [00:00<00:00, 83.94it/s, loss=1.7e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94/100, Loss: 26764.5384\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 95/100: 100%|██████████| 6/6 [00:00<00:00, 88.07it/s, loss=1.33e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95/100, Loss: 26326.0921\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 96/100: 100%|██████████| 6/6 [00:00<00:00, 92.48it/s, loss=1.38e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96/100, Loss: 25885.9212\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 97/100: 100%|██████████| 6/6 [00:00<00:00, 91.90it/s, loss=1.31e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97/100, Loss: 25453.7109\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 98/100: 100%|██████████| 6/6 [00:00<00:00, 71.13it/s, loss=1.25e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98/100, Loss: 25096.5645\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 99/100: 100%|██████████| 6/6 [00:00<00:00, 69.99it/s, loss=1.27e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99/100, Loss: 24671.2078\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 100/100: 100%|██████████| 6/6 [00:00<00:00, 83.35it/s, loss=1.07e+4]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100/100, Loss: 24279.7354\n","SVD refined embeddings (Normalizing Flow) saved in PyTorch format: ./saved_embeddings/embeddings/normalizing_flow_SVD/matrix_factorization_default_loss_normalizing_flow_SVD_refined_embeddings.pt\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/100: 100%|██████████| 6/6 [00:00<00:00, 73.14it/s, loss=2.79e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 5481.5284\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/100: 100%|██████████| 6/6 [00:00<00:00, 64.04it/s, loss=2.77e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100, Loss: 5404.8086\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/100: 100%|██████████| 6/6 [00:00<00:00, 58.94it/s, loss=2.76e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/100, Loss: 5382.3698\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/100: 100%|██████████| 6/6 [00:00<00:00, 63.56it/s, loss=2.76e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/100, Loss: 5372.2974\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/100: 100%|██████████| 6/6 [00:00<00:00, 83.17it/s, loss=2.75e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/100, Loss: 5366.1206\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/100: 100%|██████████| 6/6 [00:00<00:00, 68.75it/s, loss=2.75e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/100, Loss: 5361.5289\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/100: 100%|██████████| 6/6 [00:00<00:00, 77.90it/s, loss=2.75e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/100, Loss: 5357.6661\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/100: 100%|██████████| 6/6 [00:00<00:00, 80.13it/s, loss=2.74e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/100, Loss: 5353.7866\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/100: 100%|██████████| 6/6 [00:00<00:00, 71.88it/s, loss=2.74e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/100, Loss: 5349.8460\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/100: 100%|██████████| 6/6 [00:00<00:00, 87.67it/s, loss=2.74e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/100, Loss: 5346.0431\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/100: 100%|██████████| 6/6 [00:00<00:00, 87.27it/s, loss=2.73e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/100, Loss: 5342.1610\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/100: 100%|██████████| 6/6 [00:00<00:00, 95.36it/s, loss=2.73e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/100, Loss: 5338.1427\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/100: 100%|██████████| 6/6 [00:00<00:00, 94.98it/s, loss=2.72e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/100, Loss: 5333.9820\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/100: 100%|██████████| 6/6 [00:00<00:00, 87.08it/s, loss=2.72e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/100, Loss: 5329.7205\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/100: 100%|██████████| 6/6 [00:00<00:00, 71.42it/s, loss=2.71e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/100, Loss: 5325.4141\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/100: 100%|██████████| 6/6 [00:00<00:00, 80.59it/s, loss=2.71e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/100, Loss: 5320.9227\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/100: 100%|██████████| 6/6 [00:00<00:00, 85.12it/s, loss=2.7e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/100, Loss: 5316.5645\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/100: 100%|██████████| 6/6 [00:00<00:00, 101.20it/s, loss=2.7e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/100, Loss: 5312.2836\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/100: 100%|██████████| 6/6 [00:00<00:00, 98.18it/s, loss=2.69e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/100, Loss: 5308.1126\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/100: 100%|██████████| 6/6 [00:00<00:00, 69.22it/s, loss=2.69e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/100, Loss: 5304.1874\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/100: 100%|██████████| 6/6 [00:00<00:00, 69.24it/s, loss=2.69e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/100, Loss: 5300.5734\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/100: 100%|██████████| 6/6 [00:00<00:00, 58.74it/s, loss=2.68e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/100, Loss: 5297.0206\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/100: 100%|██████████| 6/6 [00:00<00:00, 68.25it/s, loss=2.68e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/100, Loss: 5293.8883\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/100: 100%|██████████| 6/6 [00:00<00:00, 75.82it/s, loss=2.68e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/100, Loss: 5291.0549\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25/100: 100%|██████████| 6/6 [00:00<00:00, 68.18it/s, loss=2.68e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/100, Loss: 5288.3103\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 26/100: 100%|██████████| 6/6 [00:00<00:00, 73.99it/s, loss=2.67e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/100, Loss: 5285.7412\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 27/100: 100%|██████████| 6/6 [00:00<00:00, 63.96it/s, loss=2671.0]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27/100, Loss: 5283.6004\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 28/100: 100%|██████████| 6/6 [00:00<00:00, 74.36it/s, loss=2.67e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28/100, Loss: 5281.5013\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 29/100: 100%|██████████| 6/6 [00:00<00:00, 68.22it/s, loss=2.67e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29/100, Loss: 5279.4812\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 30/100: 100%|██████████| 6/6 [00:00<00:00, 72.18it/s, loss=2.66e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30/100, Loss: 5277.4419\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 31/100: 100%|██████████| 6/6 [00:00<00:00, 72.50it/s, loss=2.66e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/100, Loss: 5275.3955\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 32/100: 100%|██████████| 6/6 [00:00<00:00, 68.08it/s, loss=2.66e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/100, Loss: 5274.0279\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 33/100: 100%|██████████| 6/6 [00:00<00:00, 57.03it/s, loss=2.66e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33/100, Loss: 5272.2230\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 34/100: 100%|██████████| 6/6 [00:00<00:00, 74.10it/s, loss=2.66e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/100, Loss: 5270.9952\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 35/100: 100%|██████████| 6/6 [00:00<00:00, 75.47it/s, loss=2.66e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/100, Loss: 5269.2483\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 36/100: 100%|██████████| 6/6 [00:00<00:00, 78.36it/s, loss=2.66e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36/100, Loss: 5267.7466\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 37/100: 100%|██████████| 6/6 [00:00<00:00, 63.77it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37/100, Loss: 5266.2290\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 38/100: 100%|██████████| 6/6 [00:00<00:00, 62.62it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38/100, Loss: 5264.7682\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 39/100: 100%|██████████| 6/6 [00:00<00:00, 60.70it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/100, Loss: 5263.9369\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 40/100: 100%|██████████| 6/6 [00:00<00:00, 72.14it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/100, Loss: 5262.7376\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 41/100: 100%|██████████| 6/6 [00:00<00:00, 85.72it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41/100, Loss: 5261.9191\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 42/100: 100%|██████████| 6/6 [00:00<00:00, 99.15it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42/100, Loss: 5260.7370\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 43/100: 100%|██████████| 6/6 [00:00<00:00, 83.84it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43/100, Loss: 5260.1261\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 44/100: 100%|██████████| 6/6 [00:00<00:00, 92.98it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44/100, Loss: 5259.3719\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 45/100: 100%|██████████| 6/6 [00:00<00:00, 93.36it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45/100, Loss: 5258.0825\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 46/100: 100%|██████████| 6/6 [00:00<00:00, 82.31it/s, loss=2.65e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46/100, Loss: 5256.9305\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 47/100: 100%|██████████| 6/6 [00:00<00:00, 92.17it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47/100, Loss: 5255.8656\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 48/100: 100%|██████████| 6/6 [00:00<00:00, 93.50it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48/100, Loss: 5254.9724\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 49/100: 100%|██████████| 6/6 [00:00<00:00, 92.43it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49/100, Loss: 5254.1268\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 50/100: 100%|██████████| 6/6 [00:00<00:00, 73.89it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50/100, Loss: 5253.2002\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 51/100: 100%|██████████| 6/6 [00:00<00:00, 91.22it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51/100, Loss: 5252.3311\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 52/100: 100%|██████████| 6/6 [00:00<00:00, 94.59it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52/100, Loss: 5251.4462\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 53/100: 100%|██████████| 6/6 [00:00<00:00, 76.94it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53/100, Loss: 5250.8895\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 54/100: 100%|██████████| 6/6 [00:00<00:00, 78.04it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54/100, Loss: 5249.9297\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 55/100: 100%|██████████| 6/6 [00:00<00:00, 54.49it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55/100, Loss: 5249.3018\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 56/100: 100%|██████████| 6/6 [00:00<00:00, 60.37it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56/100, Loss: 5248.7972\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 57/100: 100%|██████████| 6/6 [00:00<00:00, 79.02it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57/100, Loss: 5248.2872\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 58/100: 100%|██████████| 6/6 [00:00<00:00, 77.09it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58/100, Loss: 5247.6230\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 59/100: 100%|██████████| 6/6 [00:00<00:00, 65.58it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59/100, Loss: 5246.6736\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 60/100: 100%|██████████| 6/6 [00:00<00:00, 78.44it/s, loss=2.64e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60/100, Loss: 5245.9157\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 61/100: 100%|██████████| 6/6 [00:00<00:00, 87.90it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61/100, Loss: 5245.1157\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 62/100: 100%|██████████| 6/6 [00:00<00:00, 80.40it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62/100, Loss: 5244.4133\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 63/100: 100%|██████████| 6/6 [00:00<00:00, 76.92it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63/100, Loss: 5243.6681\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 64/100: 100%|██████████| 6/6 [00:00<00:00, 82.00it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64/100, Loss: 5243.2593\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 65/100: 100%|██████████| 6/6 [00:00<00:00, 73.81it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65/100, Loss: 5242.4785\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 66/100: 100%|██████████| 6/6 [00:00<00:00, 80.08it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66/100, Loss: 5242.2761\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 67/100: 100%|██████████| 6/6 [00:00<00:00, 82.22it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67/100, Loss: 5241.4966\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 68/100: 100%|██████████| 6/6 [00:00<00:00, 81.40it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68/100, Loss: 5241.1039\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 69/100: 100%|██████████| 6/6 [00:00<00:00, 74.35it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69/100, Loss: 5240.3432\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 70/100: 100%|██████████| 6/6 [00:00<00:00, 52.05it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70/100, Loss: 5239.9497\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 71/100: 100%|██████████| 6/6 [00:00<00:00, 50.46it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71/100, Loss: 5239.4091\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 72/100: 100%|██████████| 6/6 [00:00<00:00, 83.70it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72/100, Loss: 5238.9976\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 73/100: 100%|██████████| 6/6 [00:00<00:00, 75.53it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73/100, Loss: 5238.3294\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 74/100: 100%|██████████| 6/6 [00:00<00:00, 71.03it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74/100, Loss: 5237.7444\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 75/100: 100%|██████████| 6/6 [00:00<00:00, 67.13it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75/100, Loss: 5237.0498\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 76/100: 100%|██████████| 6/6 [00:00<00:00, 68.47it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76/100, Loss: 5236.5045\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 77/100: 100%|██████████| 6/6 [00:00<00:00, 54.81it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77/100, Loss: 5236.2478\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 78/100: 100%|██████████| 6/6 [00:00<00:00, 51.66it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78/100, Loss: 5235.8320\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 79/100: 100%|██████████| 6/6 [00:00<00:00, 57.70it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79/100, Loss: 5235.3754\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 80/100: 100%|██████████| 6/6 [00:00<00:00, 73.04it/s, loss=2.63e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80/100, Loss: 5235.5533\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 81/100: 100%|██████████| 6/6 [00:00<00:00, 87.32it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81/100, Loss: 5234.9341\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 82/100: 100%|██████████| 6/6 [00:00<00:00, 67.83it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82/100, Loss: 5234.5599\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 83/100: 100%|██████████| 6/6 [00:00<00:00, 67.34it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83/100, Loss: 5234.6737\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 84/100: 100%|██████████| 6/6 [00:00<00:00, 68.45it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84/100, Loss: 5234.3649\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 85/100: 100%|██████████| 6/6 [00:00<00:00, 59.59it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85/100, Loss: 5233.7415\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 86/100: 100%|██████████| 6/6 [00:00<00:00, 58.64it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86/100, Loss: 5233.3593\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 87/100: 100%|██████████| 6/6 [00:00<00:00, 37.66it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87/100, Loss: 5232.4336\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 88/100: 100%|██████████| 6/6 [00:00<00:00, 82.76it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88/100, Loss: 5231.7578\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 89/100: 100%|██████████| 6/6 [00:00<00:00, 81.42it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89/100, Loss: 5231.1811\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 90/100: 100%|██████████| 6/6 [00:00<00:00, 88.24it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90/100, Loss: 5230.7364\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 91/100: 100%|██████████| 6/6 [00:00<00:00, 69.60it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91/100, Loss: 5230.9087\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 92/100: 100%|██████████| 6/6 [00:00<00:00, 86.77it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92/100, Loss: 5229.3865\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 93/100: 100%|██████████| 6/6 [00:00<00:00, 65.01it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93/100, Loss: 5229.7407\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 94/100: 100%|██████████| 6/6 [00:00<00:00, 90.52it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94/100, Loss: 5229.2914\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 95/100: 100%|██████████| 6/6 [00:00<00:00, 66.63it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95/100, Loss: 5228.6436\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 96/100: 100%|██████████| 6/6 [00:00<00:00, 46.13it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96/100, Loss: 5227.9370\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 97/100: 100%|██████████| 6/6 [00:00<00:00, 52.48it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97/100, Loss: 5228.0457\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 98/100: 100%|██████████| 6/6 [00:00<00:00, 47.49it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98/100, Loss: 5227.9027\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 99/100: 100%|██████████| 6/6 [00:00<00:00, 69.27it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99/100, Loss: 5228.0733\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 100/100: 100%|██████████| 6/6 [00:00<00:00, 90.54it/s, loss=2.62e+3]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100/100, Loss: 5228.5775\n","NMF refined embeddings (Normalizing Flow) saved in PyTorch format: ./saved_embeddings/embeddings/normalizing_flow_NMF/matrix_factorization_default_loss_normalizing_flow_NMF_refined_embeddings.pt\n","Feature extraction and normalizing flow processing complete!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mf82IvkVxtrP"},"execution_count":null,"outputs":[]}]}