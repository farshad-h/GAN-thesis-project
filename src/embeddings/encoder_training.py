# -*- coding: utf-8 -*-
"""encoder_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v-oKUiNNUmNK5kGie_qsBpPFzoJEqUHR
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from torchvision import transforms
import torch.nn.functional as F
from torchvision.transforms import ToTensor
# from encoder_models import IntermediateAutoencoder, EnhancedAutoencoder, VAE, DenoisingAutoencoder, init_weights
# from src.data_utils import preprocess_images, load_data
from skimage.metrics import structural_similarity as ssim
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from torchvision.transforms.functional import resize, hflip


def train_autoencoder(
    model,
    data_loader,
    loss_fn,
    optimizer,
    scheduler=None,
    epochs=10,
    device="cpu",
    noise_factor=0.0,
    augment_fn=None,
    contrastive_loss_fn=None,
    temperature=0.5,
    triplet_data=False,
):
    """
    Train an autoencoder model with support for contrastive learning, noise injection, and augmentations.

    Args:
        model (nn.Module): The autoencoder model.
        data_loader (DataLoader): DataLoader for training data.
        loss_fn (callable): Primary loss function (e.g., reconstruction loss).
        optimizer (torch.optim.Optimizer): Optimizer for the model.
        scheduler (torch.optim.lr_scheduler._LRScheduler, optional): Learning rate scheduler.
        epochs (int): Number of epochs to train.
        device (str): Device to train on ('cpu' or 'cuda').
        noise_factor (float): Factor for adding noise to input images (denoising autoencoder).
        augment_fn (callable, optional): Augmentation function for contrastive learning.
        contrastive_loss_fn (callable, optional): Contrastive loss function (e.g., NT-Xent, triplet loss).
        temperature (float): Temperature parameter for NT-Xent loss.
        triplet_data (bool): Whether the data_loader provides triplets (anchor, positive, negative).

    Returns:
        None: Prints loss values for each epoch.
    """
    model.to(device).train()

    for epoch in range(epochs):
        total_loss = 0
        for batch in data_loader:
            # Prepare data based on whether it's triplet data or not
            if triplet_data:
                anchor, positive, negative = batch
                anchor, positive, negative = (
                    anchor.to(device).float(),
                    positive.to(device).float(),
                    negative.to(device).float(),
                )
                images = anchor  # Use anchor as the primary input for reconstruction
            else:
                images, _ = batch
                images = images.to(device).float()

            # Add noise if specified
            if noise_factor > 0:
                noisy_images = images + noise_factor * torch.randn_like(images)
                noisy_images = torch.clamp(noisy_images, 0.0, 1.0)
                encoded, decoded = model(noisy_images)
            else:
                encoded, decoded = model(images)

            # Compute reconstruction loss
            reconstruction_loss = loss_fn(decoded, images)

            # Compute contrastive loss if specified
            contrastive_loss_value = 0
            if contrastive_loss_fn is not None:
                if triplet_data:
                    # Triplet loss
                    positive_encoded, _ = model(positive)
                    negative_encoded, _ = model(negative)
                    contrastive_loss_value = contrastive_loss_fn(encoded, positive_encoded, negative_encoded)
                else:
                    # NT-Xent or other contrastive loss
                    if augment_fn:
                        augmented_1 = augment_fn(images)
                        augmented_2 = augment_fn(images)
                        z1, _ = model(augmented_1)
                        z2, _ = model(augmented_2)
                    else:
                        z1, z2 = encoded, encoded  # Use the same embeddings if no augmentation
                    contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)

            # Total loss
            total_loss_value = reconstruction_loss + contrastive_loss_value

            # Backpropagation
            optimizer.zero_grad()
            total_loss_value.backward()
            optimizer.step()

            total_loss += total_loss_value.item()

        # Step the scheduler if provided
        if scheduler:
            scheduler.step()

        # Print epoch loss
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")


def train_autoencoder(model, data_loader, loss_fn, optimizer, epochs=10, device="cpu", noise_factor=0.0):
    """
    Train an autoencoder with a given loss function.

    Args:
        model (nn.Module): The autoencoder model.
        data_loader (DataLoader): DataLoader for training data.
        loss_fn (callable): Loss function.
        optimizer (torch.optim.Optimizer): Optimizer.
        epochs (int): Number of epochs.
        device (str): Device to train on.
        noise_factor (float): Factor for adding noise to input images.
    """
    model.to(device).train()
    for epoch in range(epochs):
        total_loss = 0
        for images, _ in data_loader:
            images = images.to(device).float()

            # Add noise if specified
            if noise_factor > 0:
                noisy_images = images + noise_factor * torch.randn_like(images)
                noisy_images = torch.clamp(noisy_images, 0., 1.)
                encoded, decoded = model(noisy_images)
            else:
                encoded, decoded = model(images)

            # Calculate loss
            reconstruction_loss = nn.MSELoss()(decoded, images)
            embedding_loss = loss_fn(encoded, encoded)
            loss = reconstruction_loss + embedding_loss

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")

def train_with_triplet_loss(model, data_loader, triplet_loss_fn, optimizer, scheduler, epochs, device="cpu"):
    """
    Train an autoencoder with triplet loss.

    Args:
        model (nn.Module): The autoencoder model.
        data_loader (DataLoader): DataLoader for triplet data.
        triplet_loss_fn (nn.TripletMarginLoss): Triplet loss function.
        optimizer (torch.optim.Optimizer): Optimizer.
        scheduler (torch.optim.lr_scheduler._LRScheduler): Learning rate scheduler.
        epochs (int): Number of epochs.
        device (str): Device to train on.
    """
    model.to(device).train()
    for epoch in range(epochs):
        total_loss = 0
        for anchor, positive, negative in data_loader:
            anchor, positive, negative = anchor.to(device).float(), positive.to(device).float(), negative.to(device).float()

            # Forward pass
            anchor_encoded, _ = model(anchor)
            positive_encoded, _ = model(positive)
            negative_encoded, _ = model(negative)

            # Triplet loss
            loss = triplet_loss_fn(anchor_encoded, positive_encoded, negative_encoded)

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        scheduler.step()
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")

def train_with_ntxent_loss(model, data_loader, ntxent_loss_fn, optimizer, scheduler, epochs, device="cpu"):
    """
    Train an autoencoder with NT-Xent loss.

    Args:
        model (nn.Module): The autoencoder model.
        data_loader (DataLoader): DataLoader for data.
        ntxent_loss_fn (callable): NT-Xent loss function.
        optimizer (torch.optim.Optimizer): Optimizer.
        scheduler (torch.optim.lr_scheduler._LRScheduler): Learning rate scheduler.
        epochs (int): Number of epochs.
        device (str): Device to train on.
    """
    model.to(device).train()
    for epoch in range(epochs):
        total_loss = 0
        for images, _ in data_loader:
            images = images.to(device).float()

            # Generate augmented views
            augmented_1 = augment(images)
            augmented_2 = augment(images)

            # Forward pass
            z1, _ = model(augmented_1)
            z2, _ = model(augmented_2)

            # NT-Xent loss
            loss = ntxent_loss_fn(z1, z2)

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        scheduler.step()
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")

def train_autoencoder_with_contrastive_loss(
    model,
    data_loader,
    contrastive_loss_fn,
    optimizer,
    epochs=10,
    device="cpu",
    noise_factor=0.0,
    temperature=0.5,
):
    """
    Train an autoencoder model with a given contrastive loss function.

    Args:
        model (nn.Module): The autoencoder model.
        data_loader (DataLoader): DataLoader for training data.
        contrastive_loss_fn (callable): Contrastive loss function (e.g., NT-Xent, InfoNCE).
        optimizer (torch.optim.Optimizer): Optimizer.
        epochs (int): Number of epochs to train.
        device (str): Device to train on ('cpu' or 'cuda').
        noise_factor (float): Factor for adding noise to the input images for training.
        temperature (float): Scaling factor for similarity scores in contrastive learning.

    Returns:
        None: Prints loss values for each epoch.
    """
    model.to(device).train()

    for epoch in range(epochs):
        total_loss = 0
        for images, _ in data_loader:
            images = images.to(device).float()

            # Optionally add noise to the images for denoising autoencoder training
            if noise_factor > 0:
                noisy_images = images + noise_factor * torch.randn_like(images)
                noisy_images = torch.clamp(noisy_images, 0., 1.)
                encoded, decoded = model(noisy_images)
            else:
                encoded, decoded = model(images)

            # Augment images for contrastive learning (using different views of the same image)
            augmented_1 = augment(images)
            augmented_2 = augment(images)

            # Forward pass for contrastive loss
            z1, _ = model(augmented_1)  # Embedding from first augmented view
            z2, _ = model(augmented_2)  # Embedding from second augmented view

            # Compute contrastive loss (e.g., NT-Xent)
            contrastive_loss_value = contrastive_loss_fn(z1, z2, temperature)

            # Reconstruction loss for autoencoder
            reconstruction_loss = nn.MSELoss()(decoded, images)

            # Total loss: Combine reconstruction and contrastive loss
            loss = reconstruction_loss + contrastive_loss_value

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")


def train_autoencoder_with_triplet_loss(
    model,
    data_loader,
    triplet_loss_fn,
    optimizer,
    scheduler,
    epochs=10,
    device="cpu",
):
    """
    Train an autoencoder model with Triplet Loss.

    Args:
        model (nn.Module): The autoencoder model.
        data_loader (DataLoader): DataLoader for training triplet data.
        triplet_loss_fn (nn.Module): Triplet loss function (e.g., nn.TripletMarginLoss).
        optimizer (torch.optim.Optimizer): Optimizer for the model.
        scheduler (torch.optim.lr_scheduler._LRScheduler): Learning rate scheduler.
        epochs (int): Number of epochs to train.
        device (str): Device to train on ('cpu' or 'cuda').

    Returns:
        None: Prints loss values for each epoch.
    """
    model.to(device).train()

    for epoch in range(epochs):
        total_loss = 0
        for anchor, positive, negative in data_loader:
            anchor, positive, negative = (
                anchor.to(device).float(),
                positive.to(device).float(),
                negative.to(device).float(),
            )

            # Forward pass
            anchor_encoded, _ = model(anchor)
            positive_encoded, _ = model(positive)
            negative_encoded, _ = model(negative)

            # Compute triplet loss
            loss = triplet_loss_fn(anchor_encoded, positive_encoded, negative_encoded)

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        scheduler.step()
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")


def train_autoencoder_with_ntxent_loss(
    model,
    data_loader,
    ntxent_loss_fn,
    optimizer,
    scheduler,
    epochs=10,
    device="cpu",
    temperature=0.5,
):
    """
    Train an autoencoder model with NT-Xent loss.

    Args:
        model (nn.Module): The autoencoder model.
        data_loader (DataLoader): DataLoader for training data.
        ntxent_loss_fn (callable): NT-Xent loss function.
        optimizer (torch.optim.Optimizer): Optimizer for the model.
        scheduler (torch.optim.lr_scheduler._LRScheduler): Learning rate scheduler.
        epochs (int): Number of epochs to train.
        device (str): Device to train on ('cpu' or 'cuda').
        temperature (float): Scaling factor for similarity scores in NT-Xent loss.

    Returns:
        None: Prints loss values for each epoch.
    """
    model.to(device).train()

    for epoch in range(epochs):
        total_loss = 0
        for images, _ in data_loader:
            images = images.to(device).float()

            # Generate augmented views of the images
            augmented_1 = augment(images)
            augmented_2 = augment(images)

            # Forward pass for NT-Xent loss
            z1, _ = model(augmented_1)
            z2, _ = model(augmented_2)

            # Compute NT-Xent loss
            loss = ntxent_loss_fn(z1, z2, temperature)

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        scheduler.step()
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")

def vae_loss(recon_x, x, mu, logvar, beta=1):
    """
    Compute the VAE loss with reconstruction and KL divergence terms.

    Args:
        recon_x (torch.Tensor): Reconstructed input.
        x (torch.Tensor): Original input.
        mu (torch.Tensor): Mean from the latent space.
        logvar (torch.Tensor): Log variance from the latent space.
        beta (float): Weight for the KL divergence term.

    Returns:
        torch.Tensor: Total loss (reconstruction + beta * KL divergence).
    """
    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='mean')
    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)
    return recon_loss + beta * kld_loss

def vae_ssim_loss(recon_x, x, mu, logvar, beta=1, ssim_func=ssim):
    """
    Compute the VAE loss with SSIM-based reconstruction and KL divergence terms.

    Args:
        recon_x (torch.Tensor): Reconstructed input.
        x (torch.Tensor): Original input.
        mu (torch.Tensor): Mean from the latent space.
        logvar (torch.Tensor): Log variance from the latent space.
        beta (float): Weight for the KL divergence term.
        ssim_func (callable): SSIM function for image similarity.

    Returns:
        torch.Tensor: Total loss (SSIM + beta * KL divergence).
    """
    if ssim_func is None:
        raise ValueError("A valid SSIM function must be provided for vae_ssim_loss.")
    recon_loss = 1 - ssim_func(recon_x, x)
    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)
    return recon_loss + beta * kld_loss

def train_vae(vae, train_loader, val_loader=None, optimizer=None, scheduler=None,
              loss_fn=vae_loss, epochs=3, device="cpu", save_best=True, save_path="best_vae_model.pth"):
    """
    Train a VAE model with optional validation.

    Args:
        vae (nn.Module): VAE model.
        train_loader (DataLoader): DataLoader for training data.
        val_loader (DataLoader, optional): DataLoader for validation data.
        optimizer (Optimizer): Optimizer for training.
        scheduler (Scheduler, optional): Learning rate scheduler.
        loss_fn (callable): Loss function to use for training.
        epochs (int): Number of training epochs.
        device (str): Device to train on.
        save_best (bool): Whether to save the best model.
        save_path (str): Path to save the best model.
    """
    vae.to(device).train()
    best_val_loss = float('inf') if save_best else None

    for epoch in range(epochs):
        # Training loop
        vae.train()
        total_train_loss = 0
        for images, _ in train_loader:
            images = images.to(device).float()
            mu, logvar, decoded = vae(images)
            loss = loss_fn(decoded, images, mu, logvar)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_train_loss += loss.item()

        avg_train_loss = total_train_loss / len(train_loader)

        # Validation loop
        if val_loader:
            vae.eval()
            total_val_loss = 0
            with torch.no_grad():
                for images, _ in val_loader:
                    images = images.to(device).float()
                    mu, logvar, decoded = vae(images)
                    loss = loss_fn(decoded, images, mu, logvar)
                    total_val_loss += loss.item()

            avg_val_loss = total_val_loss / len(val_loader)
            print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

            # Save the best model
            if save_best and avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                torch.save(vae.state_dict(), save_path)
                print(f"Model saved at epoch {epoch + 1}")
        else:
            print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}")

        if scheduler:
            scheduler.step()

def train_vae_improved(vae, data_loader, optimizer, scheduler=None, loss_fn=vae_loss, epochs=3, beta=1, device="cpu"):
    """
    Train a VAE with an improved loss function and optional scheduler.

    Args:
        vae (nn.Module): VAE model.
        data_loader (DataLoader): DataLoader for training data.
        optimizer (Optimizer): Optimizer for training.
        scheduler (Scheduler, optional): Learning rate scheduler.
        loss_fn (callable): Loss function for training.
        epochs (int): Number of training epochs.
        beta (float): Weight for the KL divergence term.
        device (str): Device to train on.
    """
    vae.to(device).train()
    for epoch in range(epochs):
        total_loss = 0
        for images, _ in data_loader:
            images = images.to(device).float()
            mu, logvar, decoded = vae(images)
            loss = loss_fn(decoded, images, mu, logvar, beta)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        if scheduler:
            scheduler.step()

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")

def train_vae_ssim(vae, train_loader, val_loader=None, optimizer=None, scheduler=None, 
                   loss_fn=vae_ssim_loss, epochs=3, beta=1, device="cpu", save_path="best_vae_model.pth"):
    """
    Train a VAE with SSIM-based loss and optional validation.

    Args:
        vae (nn.Module): VAE model.
        train_loader (DataLoader): DataLoader for training data.
        val_loader (DataLoader, optional): DataLoader for validation data.
        optimizer (Optimizer): Optimizer for training.
        scheduler (Scheduler, optional): Learning rate scheduler.
        loss_fn (callable): Loss function for training.
        epochs (int): Number of training epochs.
        beta (float): Weight for the KL divergence term.
        device (str): Device to train on.
        save_path (str): Path to save the best model.
    """
    best_val_loss = float('inf')
    vae.to(device)

    for epoch in range(epochs):
        # Training
        vae.train()
        train_loss = 0
        for images, _ in train_loader:
            images = images.to(device).float()
            mu, logvar, decoded = vae(images)
            loss = loss_fn(decoded, images, mu, logvar, beta)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        # Validation
        avg_train_loss = train_loss / len(train_loader)
        if val_loader:
            vae.eval()
            val_loss = 0
            with torch.no_grad():
                for images, _ in val_loader:
                    images = images.to(device).float()
                    mu, logvar, decoded = vae(images)
                    val_loss += loss_fn(decoded, images, mu, logvar, beta).item()

            avg_val_loss = val_loss / len(val_loader)
            print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                torch.save(vae.state_dict(), save_path)
                print(f"Model saved at epoch {epoch + 1}")
        else:
            print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}")

        if scheduler:
            scheduler.step()

def train_vae_ssim_contrastive(vae, train_loader, val_loader=None, optimizer=None, scheduler=None, 
                               loss_fn=vae_ssim_loss, epochs=3, beta=1, alpha=0.5, temperature=0.5, 
                               device="cpu", save_path="best_vae_model.pth"):
    """
    Train a VAE with SSIM + contrastive loss and optional validation.

    Args:
        vae (nn.Module): VAE model with optional projection head.
        train_loader (DataLoader): DataLoader for training data.
        val_loader (DataLoader, optional): DataLoader for validation data.
        optimizer (Optimizer): Optimizer for training.
        scheduler (Scheduler, optional): Learning rate scheduler.
        loss_fn (callable): Loss function for training.
        epochs (int): Number of training epochs.
        beta (float): Weight for the KL divergence term.
        alpha (float): Weight for the contrastive loss term.
        temperature (float): Temperature for contrastive loss.
        device (str): Device to train on.
        save_path (str): Path to save the best model.
    """
    best_val_loss = float('inf')
    vae.to(device)

    for epoch in range(epochs):
        # Training
        vae.train()
        train_loss = 0
        for images, _ in train_loader:
            images = images.to(device).float()
            mu, logvar, decoded = vae(images)
            recon_loss = loss_fn(decoded, images, mu, logvar, beta)

            # Add contrastive loss if the model supports it
            if hasattr(vae, 'projection_head'):
                indices = torch.randperm(mu.size(0)).to(device)
                z1, z2 = mu, mu[indices]
                contrastive_loss = nt_xent_loss(z1, z2, temperature)
                loss = recon_loss + alpha * contrastive_loss
            else:
                loss = recon_loss

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        # Validation
        avg_train_loss = train_loss / len(train_loader)
        if val_loader:
            vae.eval()
            val_loss = 0
            with torch.no_grad():
                for images, _ in val_loader:
                    images = images.to(device).float()
                    mu, logvar, decoded = vae(images)
                    val_loss += loss_fn(decoded, images, mu, logvar, beta).item()

            avg_val_loss = val_loss / len(val_loader)
            print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                torch.save(vae.state_dict(), save_path)
                print(f"Model saved at epoch {epoch + 1}")
        else:
            print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}")

        if scheduler:
            scheduler.step()

def add_noise(inputs, noise_factor=0.1):
    """
    Add Gaussian noise to the input tensor.

    Args:
        inputs (torch.Tensor): Input tensor.
        noise_factor (float): Scaling factor for noise.

    Returns:
        torch.Tensor: Noisy tensor with values clamped between 0 and 1.
    """
    noisy_inputs = inputs + noise_factor * torch.randn_like(inputs)
    return torch.clamp(noisy_inputs, 0., 1.)

def train_denoising_autoencoder(dae, data_loader, criterion, optimizer, scheduler=None, noise_factor=0.1, epochs=3, device="cpu"):
    """
    Train a denoising autoencoder (DAE) with a specified loss criterion.

    Args:
        dae (nn.Module): The denoising autoencoder model.
        data_loader (DataLoader): DataLoader for training data.
        criterion (callable): Loss function.
        optimizer (Optimizer): Optimizer for training.
        scheduler (Scheduler, optional): Learning rate scheduler.
        noise_factor (float): Noise scaling factor.
        epochs (int): Number of training epochs.
        device (str): Device to train on.
    """
    dae.to(device).train()
    for epoch in range(epochs):
        total_loss = 0
        for images, _ in data_loader:
            images = images.to(device).float()
            noisy_images = add_noise(images, noise_factor)
            encoded, decoded = dae(noisy_images)
            loss = criterion(decoded, images)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        if scheduler:
            scheduler.step()

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(data_loader):.4f}")

def train_dae_with_triplet(dae, train_loader, optimizer, scheduler=None, triplet_criterion=None, 
                           noise_factor=0.1, alpha=0.5, epochs=3, device="cpu"):
    """
    Train a denoising autoencoder with triplet loss.

    Args:
        dae (nn.Module): The denoising autoencoder model.
        train_loader (DataLoader): DataLoader for training data.
        optimizer (Optimizer): Optimizer for training.
        scheduler (Scheduler, optional): Learning rate scheduler.
        triplet_criterion (callable): Triplet loss function.
        noise_factor (float): Noise scaling factor.
        alpha (float): Weight for triplet loss term.
        epochs (int): Number of training epochs.
        device (str): Device to train on.
    """
    dae.to(device).train()
    for epoch in range(epochs):
        total_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device).float(), labels.to(device)
            noisy_images = add_noise(images, noise_factor)
            encoded, decoded = dae(noisy_images)

            # Reconstruction loss
            recon_loss = nn.MSELoss()(decoded, images)

            # Triplet loss
            triplets = []
            for i in range(len(labels)):
                anchor_label = labels[i]
                positive_indices = torch.where(labels == anchor_label)[0]
                if len(positive_indices) > 1:
                    positive_index = positive_indices[positive_indices != i][torch.randint(len(positive_indices) - 1, (1,))].item()
                    negative_label = labels[labels != anchor_label][torch.randint(len(labels[labels != anchor_label]), (1,))].item()
                    negative_index = torch.where(labels == negative_label)[0][torch.randint(len(labels[labels == negative_label]), (1,))].item()
                    triplets.append((encoded[i], encoded[positive_index], encoded[negative_index]))

            if triplets:
                anchor_embeddings, positive_embeddings, negative_embeddings = zip(*triplets)
                anchor_embeddings = torch.stack(anchor_embeddings)
                positive_embeddings = torch.stack(positive_embeddings)
                negative_embeddings = torch.stack(negative_embeddings)
                triplet_loss_val = triplet_criterion(anchor_embeddings, positive_embeddings, negative_embeddings)
            else:
                triplet_loss_val = torch.tensor(0.0, device=device)

            # Total loss
            loss = recon_loss + alpha * triplet_loss_val

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        if scheduler:
            scheduler.step()

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}")

def loss_function_dae_ssim(recon_x, x, ssim_func):
    """
    Compute SSIM-based loss for denoising autoencoder.

    Args:
        recon_x (torch.Tensor): Reconstructed input.
        x (torch.Tensor): Original input.
        ssim_func (callable): SSIM function.

    Returns:
        torch.Tensor: SSIM-based reconstruction loss.
    """
    recon_loss = 1 - ssim_func(recon_x, x)
    return recon_loss

def train_dae_ssim_contrastive(dae, train_loader, optimizer, scheduler=None, noise_factor=0.1, 
                               alpha=0.5, temperature=0.2, epochs=3, device="cpu"):
    """
    Train a denoising autoencoder with SSIM and contrastive loss.

    Args:
        dae (nn.Module): The denoising autoencoder model.
        train_loader (DataLoader): DataLoader for training data.
        optimizer (Optimizer): Optimizer for training.
        scheduler (Scheduler, optional): Learning rate scheduler.
        noise_factor (float): Noise scaling factor.
        alpha (float): Weight for contrastive loss term.
        temperature (float): Temperature for contrastive loss.
        epochs (int): Number of training epochs.
        device (str): Device to train on.
    """
    dae.to(device).train()
    for epoch in range(epochs):
        total_loss = 0
        for images, _ in train_loader:
            images = images.to(device).float()
            noisy_images = add_noise(images, noise_factor)
            projected_encoded, decoded, _ = dae(noisy_images)

            # SSIM loss
            recon_loss = loss_function_dae_ssim(decoded, images, ssim_func)

            # Contrastive loss
            indices = torch.randperm(len(projected_encoded)).to(device)
            z1, z2 = projected_encoded, projected_encoded[indices]
            contrastive_loss = nt_xent_loss(z1, z2, temperature)

            # Total loss
            loss = recon_loss + alpha * contrastive_loss

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        if scheduler:
            scheduler.step()

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}")