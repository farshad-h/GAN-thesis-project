{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Plan 2: GAN Training with Embeddings\n","\n","## Objective\n","The goal of this plan is to train GANs using embeddings generated from Plan 1. This involves:\n","1. Setting up a GAN architecture that incorporates embeddings.\n","2. Training the GAN to generate high-quality synthetic embeddings or data.\n","3. Evaluating the GAN's performance using relevant metrics.\n","\n","## Key Steps\n","\n","### 1. Define GAN Architecture\n","- **Generator**: Accepts embeddings and noise as inputs, producing synthetic data.\n","- **Discriminator**: Evaluates the authenticity of generated data, optionally conditioned on embeddings.\n","\n","### 2. Load Pre-Generated Embeddings\n","- Load embeddings created in Plan 1 from their respective directories.\n","- Normalize and preprocess embeddings for GAN training.\n","\n","### 3. Train the GAN\n","- Set up training loops for the generator and discriminator.\n","- Use appropriate loss functions, such as adversarial loss (e.g., Wasserstein loss).\n","- Optionally, include auxiliary tasks (e.g., reconstruction loss) for better embedding alignment.\n","\n","### 4. Save Outputs\n","- Save trained GAN models.\n","- Save generated embeddings or data for downstream evaluation.\n","\n","### 5. Evaluate GAN Performance\n","- Use metrics like FID, IS, and qualitative visualization.\n","- Compare performance with baseline models or methods.\n","\n","---\n","\n","## Starting Point\n","\n","**Files Available**:\n","- `plan2_gan_models.py`: Contains the GAN architecture.\n","- `plan2_gan_training.py`: Implements the training pipeline.\n","- `main_plan2_gan_training.ipynb`: High-level control notebook.\n","- `plan2_experiments.ipynb`: For experimentation and evaluation.\n","\n","## Next Steps\n","1. **Review Architecture**:\n","   - Inspect `plan2_gan_models.py` to understand the generator and discriminator setup.\n","2. **Pipeline Setup**:\n","   - Review and prepare the training pipeline in `plan2_gan_training.py`.\n","3. **Experimentation**:\n","   - Use `plan2_experiments.ipynb` for controlled experiments.\n"],"metadata":{"id":"6aVzhiUvYnnh"}},{"cell_type":"code","source":["# Plan 2 GAN Training Notebook\n","\n","import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import logging\n","from datetime import datetime\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Repository path (adjust if needed)\n","repo_path = \"/content/drive/MyDrive/GAN-thesis-project\"\n","\n","# Add repository path to sys.path for module imports\n","if repo_path not in sys.path:\n","    sys.path.append(repo_path)\n","\n","# Change working directory to the repository\n","os.chdir(repo_path)\n","\n","# Verify the working directory\n","print(f\"Current working directory: {os.getcwd()}\")\n","\n","# GAN Models and Training Functions\n","from src.gan_workflows.plan2.plan2_gan_models import (\n","    SimpleGANGenerator, SimpleGANDiscriminator,\n","    ContrastiveGANGenerator, ContrastiveGANDiscriminator,\n","    VAEGANEncoder, VAEGANGenerator, VAEGANDiscriminator,\n","    WGANGenerator, WGANCritic,\n","    CrossDomainGenerator, CrossDomainDiscriminator,\n","    CycleGenerator, CycleDiscriminator,\n","    DualGANGenerator, DualGANDiscriminator,\n","    ContrastiveDualGANGenerator, ContrastiveDualGANDiscriminator,\n","    SemiSupervisedGANDiscriminator,\n","    ConditionalGANGenerator, ConditionalGANDiscriminator,\n","    InfoGANGenerator, InfoGANDiscriminator,\n","    compute_gradient_penalty\n",")\n","from src.gan_workflows.plan2.plan2_gan_training import (\n","    train_wgan_gp, train_vae_gan, train_contrastive_gan,\n","    train_cross_domain_gan, train_cycle_gan,\n","    train_dual_gan, train_contrastive_dual_gan,\n","    train_semi_supervised_gan,\n","    train_conditional_gan,\n","    train_infogan\n",")\n","\n","from src.data_utils import (\n","    load_embeddings, analyze_embeddings\n",")\n","\n","\n","# Set random seed and device\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3fgL_75bNh_","executionInfo":{"status":"ok","timestamp":1737292387960,"user_tz":-210,"elapsed":109232,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"80c7f5fb-f8e8-41ba-d189-f04a18e1b052"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Current working directory: /content/drive/MyDrive/GAN-thesis-project\n","Using device: cpu\n"]}]},{"cell_type":"code","source":["embedding_dir = \"./saved_embeddings/embeddings/autoencoders_BasicAutoencoder\"  # Example embedding path\n","embedding_file = os.path.join(embedding_dir, \"BasicAutoencoder_embeddings.pt\")\n","\n","# Load embeddings and labels using the new function\n","embeddings, labels, data_loader = load_embeddings(embedding_file, device)\n","\n","# Analyze the embeddings (optional: set expected_dim if necessary)\n","analyze_embeddings(embeddings, expected_dim=50, labels=labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ww8mcFrOzsG_","executionInfo":{"status":"ok","timestamp":1737292392540,"user_tz":-210,"elapsed":4583,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"9ea75be2-0839-444d-9750-5778b55be10c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading embeddings from: ./saved_embeddings/embeddings/autoencoders_BasicAutoencoder/BasicAutoencoder_embeddings.pt\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/GAN-thesis-project/src/data_utils.py:140: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(embedding_file)\n","INFO - Embeddings are of shape: torch.Size([7000, 50])\n","INFO - Data type: torch.float32\n","INFO - Device: cpu\n","INFO - Mean: -0.10591454058885574\n","INFO - Standard Deviation: 4.491614818572998\n","INFO - Min: -22.35531997680664\n","INFO - Max: 15.808435440063477\n","INFO - Median: 0.15539658069610596\n","INFO - Mean L2 Norm: 31.488544464111328\n","INFO - Standard Deviation of L2 Norms: 4.21454381942749\n","INFO - Each embedding has 50 dimensions.\n","INFO - Sparsity (proportion of non-zero elements): 1.0\n","INFO - Skewness of embeddings: -0.6672645237194799\n","INFO - Kurtosis of embeddings: 1.5908177243367119\n","INFO - Pairwise distance (mean): 25.41992176637177\n","INFO - Average Cosine similarity with true labels: -0.00153539318125695\n","INFO - Number of outliers detected in embeddings: 30\n","INFO - Embeddings analysis completed.\n"]}]},{"cell_type":"code","source":["# ## OLD VERSION\n","\n","# def validate_embeddings(embeddings):\n","#     \"\"\"\n","#     Validate and provide information about the shape and data type of embeddings.\n","#     \"\"\"\n","#     if embeddings is None or len(embeddings) == 0:\n","#         raise ValueError(\"Embeddings are empty or not properly generated.\")\n","#     print(f\"Embeddings are of shape: {embeddings.shape}\")\n","#     print(f\"Data type: {embeddings.dtype}\")\n","#     print(f\"Device: {embeddings.device}\")\n","#     if torch.isnan(embeddings).any():\n","#         raise ValueError(\"Embeddings contain NaN values.\")\n","#     if torch.isinf(embeddings).any():\n","#         raise ValueError(\"Embeddings contain infinite values.\")\n","#     if embeddings.ndim != 2:\n","#         raise ValueError(\"Embeddings should be a 2D tensor.\")\n","#     print(\"Embeddings validation passed.\")\n","\n","# validate_embeddings(embeddings)"],"metadata":{"id":"584Xs4_8EGLV","executionInfo":{"status":"ok","timestamp":1737292392540,"user_tz":-210,"elapsed":11,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Get a batch of training data\n","embedding_batch = next(iter(data_loader))\n","print('embedding batches', embedding_batch.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IXt_LRiEfWo","executionInfo":{"status":"ok","timestamp":1737292392541,"user_tz":-210,"elapsed":12,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"aafb5ae7-2226-4526-93ad-e65ff2d5812b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["embedding batches torch.Size([64, 50])\n"]}]},{"cell_type":"code","source":["# GAN Configuration Dictionary\n","gan_configurations = {\n","    \"WGAN-GP\": {\n","        \"generator\": WGANGenerator,\n","        \"critic\": WGANCritic,\n","        \"train_function\": train_wgan_gp,\n","        \"train_kwargs\": {\"lambda_gp\": 10}\n","    },\n","    \"VAE-GAN\": {\n","        \"encoder\": VAEGANEncoder,\n","        \"generator\": VAEGANGenerator,\n","        \"discriminator\": VAEGANDiscriminator,\n","        \"train_function\": train_vae_gan\n","    },\n","    \"Contrastive-GAN\": {\n","        \"generator\": ContrastiveGANGenerator,\n","        \"discriminator\": ContrastiveGANDiscriminator,\n","        \"train_function\": train_contrastive_gan\n","    },\n","    \"Cross-Domain-GAN\": {\n","        \"generator\": CrossDomainGenerator,\n","        \"discriminator\": CrossDomainDiscriminator,\n","        \"train_function\": train_cross_domain_gan\n","    },\n","    \"Cycle-GAN\": {\n","        \"generator_a\": CycleGenerator,\n","        \"generator_b\": CycleGenerator,\n","        \"discriminator_a\": CycleDiscriminator,\n","        \"discriminator_b\": CycleDiscriminator,\n","        \"train_function\": train_cycle_gan\n","    },\n","    \"Dual-GAN\": {\n","        \"generator_a\": DualGANGenerator,\n","        \"generator_b\": DualGANGenerator,\n","        \"discriminator_a\": DualGANDiscriminator,\n","        \"discriminator_b\": DualGANDiscriminator,\n","        \"train_function\": train_dual_gan\n","    },\n","    \"Contrastive-Dual-GAN\": {\n","        \"generator_a\": ContrastiveDualGANGenerator,\n","        \"generator_b\": ContrastiveDualGANGenerator,\n","        \"discriminator_a\": ContrastiveDualGANDiscriminator,\n","        \"discriminator_b\": ContrastiveDualGANDiscriminator,\n","        \"train_function\": train_contrastive_dual_gan\n","    },\n","    \"Semi-Supervised-GAN\": {\n","        \"generator\": SimpleGANGenerator,\n","        \"discriminator\": SemiSupervisedGANDiscriminator,\n","        \"train_function\": train_semi_supervised_gan\n","    },\n","    \"Conditional-GAN\": {\n","        \"generator\": ConditionalGANGenerator,\n","        \"discriminator\": ConditionalGANDiscriminator,\n","        \"train_function\": train_conditional_gan\n","    },\n","    \"InfoGAN\": {\n","        \"generator\": InfoGANGenerator,\n","        \"discriminator\": InfoGANDiscriminator,\n","        \"train_function\": train_infogan\n","    }\n","}"],"metadata":{"id":"b4gSo_7Z6vMk","executionInfo":{"status":"ok","timestamp":1737292392541,"user_tz":-210,"elapsed":8,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Cycle-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)  # Use CycleDiscriminator for CycleGAN\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)  # Same for second domain\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            generator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Discriminator initialization for other GAN types\n","    if gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (WGAN-GP, VAE-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\"] else None,  # Add only for Conditional and InfoGAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": data_loader,  # Two loaders for these models\n","            \"data_loader_b\": data_loader\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": data_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6ArBHybakng","executionInfo":{"status":"ok","timestamp":1737292455872,"user_tz":-210,"elapsed":63339,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"98e744a6-6bc4-467d-9231-dbbd9978c56e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Cycle-GAN configuration: {'generator_a': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleGenerator'>, 'generator_b': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleGenerator'>, 'discriminator_a': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleDiscriminator'>, 'discriminator_b': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleDiscriminator'>, 'train_function': <function train_cycle_gan at 0x7c0ebbc672e0>}\n","CycleGAN generators and discriminators initialized on CycleGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), CycleGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), CycleDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n","), CycleDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n",")\n","Epoch [1/20], D Loss A: 0.9797, D Loss B: 0.7251, G Loss: 11.1319\n","Epoch [2/20], D Loss A: 0.8108, D Loss B: 0.9489, G Loss: 8.8286\n","Epoch [3/20], D Loss A: 1.0727, D Loss B: 1.2267, G Loss: 6.9502\n","Epoch [4/20], D Loss A: 1.0497, D Loss B: 1.2460, G Loss: 6.4463\n","Epoch [5/20], D Loss A: 1.1810, D Loss B: 1.1200, G Loss: 5.6330\n","Epoch [6/20], D Loss A: 1.1741, D Loss B: 1.3614, G Loss: 5.1570\n","Epoch [7/20], D Loss A: 1.2931, D Loss B: 1.3022, G Loss: 4.5739\n","Epoch [8/20], D Loss A: 1.2062, D Loss B: 1.2963, G Loss: 4.5784\n","Epoch [9/20], D Loss A: 1.3077, D Loss B: 1.2585, G Loss: 4.2125\n","Epoch [10/20], D Loss A: 1.3823, D Loss B: 1.2649, G Loss: 3.9716\n","Epoch [11/20], D Loss A: 1.1190, D Loss B: 1.1611, G Loss: 3.8779\n","Epoch [12/20], D Loss A: 1.2735, D Loss B: 1.1574, G Loss: 3.7906\n","Epoch [13/20], D Loss A: 1.1536, D Loss B: 1.0895, G Loss: 3.6857\n","Epoch [14/20], D Loss A: 1.0033, D Loss B: 1.0389, G Loss: 3.7434\n","Epoch [15/20], D Loss A: 0.9906, D Loss B: 0.9949, G Loss: 3.7993\n","Epoch [16/20], D Loss A: 1.1587, D Loss B: 1.0437, G Loss: 3.8155\n","Epoch [17/20], D Loss A: 1.0859, D Loss B: 1.1561, G Loss: 3.4951\n","Epoch [18/20], D Loss A: 1.2477, D Loss B: 1.0571, G Loss: 3.4612\n","Epoch [19/20], D Loss A: 1.0612, D Loss B: 0.9522, G Loss: 3.5463\n","Epoch [20/20], D Loss A: 0.9772, D Loss B: 0.9999, G Loss: 3.6506\n","Cycle-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Cycle-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwugPzYMqkkB","executionInfo":{"status":"ok","timestamp":1737292521312,"user_tz":-210,"elapsed":65446,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"675b92c0-3576-4990-eac5-70d75c40f777"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Cycle-GAN configuration: {'generator_a': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleGenerator'>, 'generator_b': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleGenerator'>, 'discriminator_a': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleDiscriminator'>, 'discriminator_b': <class 'src.gan_workflows.plan2.plan2_gan_models.CycleDiscriminator'>, 'train_function': <function train_cycle_gan at 0x7c0ebbc672e0>}\n","CycleGAN generators and discriminators initialized on CycleGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), CycleGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), CycleDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n","), CycleDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n",")\n","Discriminators initialized on CycleDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n","), CycleDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n",")\n","Epoch [1/20], D Loss A: 0.9726, D Loss B: 0.9946, G Loss: 11.2781\n","Epoch [2/20], D Loss A: 1.0096, D Loss B: 0.9906, G Loss: 9.0449\n","Epoch [3/20], D Loss A: 1.1779, D Loss B: 1.1799, G Loss: 6.9110\n","Epoch [4/20], D Loss A: 1.4224, D Loss B: 1.3173, G Loss: 6.0187\n","Epoch [5/20], D Loss A: 1.3030, D Loss B: 1.2985, G Loss: 5.7772\n","Epoch [6/20], D Loss A: 1.2751, D Loss B: 1.2264, G Loss: 5.2919\n","Epoch [7/20], D Loss A: 1.2150, D Loss B: 1.2472, G Loss: 5.1045\n","Epoch [8/20], D Loss A: 1.0551, D Loss B: 0.9867, G Loss: 4.7831\n","Epoch [9/20], D Loss A: 1.2182, D Loss B: 1.1935, G Loss: 4.5309\n","Epoch [10/20], D Loss A: 1.3742, D Loss B: 1.2939, G Loss: 4.0181\n","Epoch [11/20], D Loss A: 1.0956, D Loss B: 1.0835, G Loss: 4.1177\n","Epoch [12/20], D Loss A: 1.0009, D Loss B: 0.9852, G Loss: 4.4692\n","Epoch [13/20], D Loss A: 1.1505, D Loss B: 1.1505, G Loss: 3.8415\n","Epoch [14/20], D Loss A: 1.1282, D Loss B: 1.0664, G Loss: 3.7756\n","Epoch [15/20], D Loss A: 1.1309, D Loss B: 1.0756, G Loss: 3.6158\n","Epoch [16/20], D Loss A: 1.1373, D Loss B: 1.1379, G Loss: 3.5749\n","Epoch [17/20], D Loss A: 1.1892, D Loss B: 1.1198, G Loss: 3.5723\n","Epoch [18/20], D Loss A: 1.2560, D Loss B: 1.2211, G Loss: 3.5285\n","Epoch [19/20], D Loss A: 0.9314, D Loss B: 0.9723, G Loss: 3.5471\n","Epoch [20/20], D Loss A: 1.3050, D Loss B: 1.1080, G Loss: 3.2494\n","Cycle-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"WGAN-GP\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            generator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (WGAN-GP, VAE-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\"] else None,  # Add only for Conditional and InfoGAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": data_loader,  # Two loaders for these models\n","            \"data_loader_b\": data_loader\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": data_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, critic if gan_type == \"WGAN-GP\" else discriminator, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MS2mKkEabK4f","executionInfo":{"status":"ok","timestamp":1737292551175,"user_tz":-210,"elapsed":29869,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"5861d2d1-eea4-4c14-c110-2116673e951c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing WGAN-GP configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.WGANGenerator'>, 'critic': <class 'src.gan_workflows.plan2.plan2_gan_models.WGANCritic'>, 'train_function': <function train_wgan_gp at 0x7c0ebbc66a20>, 'train_kwargs': {'lambda_gp': 10}}\n","Generator initialized on WGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Critic initialized on WGANCritic(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")\n","Epoch [1/20], Loss Critic: -38.8869, Loss Generator: -6.2024\n","Epoch [2/20], Loss Critic: -37.4483, Loss Generator: -10.6168\n","Epoch [3/20], Loss Critic: -37.1718, Loss Generator: -13.2149\n","Epoch [4/20], Loss Critic: -30.8929, Loss Generator: -15.6178\n","Epoch [5/20], Loss Critic: -32.1100, Loss Generator: -15.2638\n","Epoch [6/20], Loss Critic: -23.1121, Loss Generator: -14.1725\n","Epoch [7/20], Loss Critic: -19.7469, Loss Generator: -13.3349\n","Epoch [8/20], Loss Critic: -16.3295, Loss Generator: -13.3811\n","Epoch [9/20], Loss Critic: -12.9329, Loss Generator: -13.7712\n","Epoch [10/20], Loss Critic: -9.5292, Loss Generator: -12.8992\n","Epoch [11/20], Loss Critic: -9.4296, Loss Generator: -11.7860\n","Epoch [12/20], Loss Critic: -9.3191, Loss Generator: -9.3525\n","Epoch [13/20], Loss Critic: -5.9132, Loss Generator: -10.0674\n","Epoch [14/20], Loss Critic: -5.0885, Loss Generator: -8.0323\n","Epoch [15/20], Loss Critic: -4.8795, Loss Generator: -4.6616\n","Epoch [16/20], Loss Critic: -3.5135, Loss Generator: -0.3070\n","Epoch [17/20], Loss Critic: -3.5008, Loss Generator: 1.8291\n","Epoch [18/20], Loss Critic: -0.9120, Loss Generator: -1.7002\n","Epoch [19/20], Loss Critic: -1.9907, Loss Generator: -1.9198\n","Epoch [20/20], Loss Critic: -2.7153, Loss Generator: -2.5956\n","WGAN-GP training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"WGAN-GP\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEoExkQlqpP7","executionInfo":{"status":"ok","timestamp":1737292582959,"user_tz":-210,"elapsed":31791,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"f11c7754-e9ed-43c3-fc4b-2fdf0fbb3c2b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing WGAN-GP configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.WGANGenerator'>, 'critic': <class 'src.gan_workflows.plan2.plan2_gan_models.WGANCritic'>, 'train_function': <function train_wgan_gp at 0x7c0ebbc66a20>, 'train_kwargs': {'lambda_gp': 10, 'latent_dim': 100, 'epochs': 20, 'device': device(type='cpu'), 'learning_rate': 0.0001, 'num_classes': None, 'categorical_dim': None, 'data_loader': <torch.utils.data.dataloader.DataLoader object at 0x7c0eac70da50>}}\n","Generator initialized on WGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Critic initialized on WGANCritic(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")\n","Epoch [1/20], Loss Critic: -35.7774, Loss Generator: -6.0856\n","Epoch [2/20], Loss Critic: -37.2186, Loss Generator: -10.6226\n","Epoch [3/20], Loss Critic: -36.7841, Loss Generator: -14.1521\n","Epoch [4/20], Loss Critic: -31.3454, Loss Generator: -16.3164\n","Epoch [5/20], Loss Critic: -25.3912, Loss Generator: -15.9861\n","Epoch [6/20], Loss Critic: -24.4866, Loss Generator: -13.5322\n","Epoch [7/20], Loss Critic: -23.1181, Loss Generator: -13.9310\n","Epoch [8/20], Loss Critic: -21.1467, Loss Generator: -13.1262\n","Epoch [9/20], Loss Critic: -15.5005, Loss Generator: -13.7697\n","Epoch [10/20], Loss Critic: -10.2927, Loss Generator: -12.6548\n","Epoch [11/20], Loss Critic: -10.9891, Loss Generator: -11.6584\n","Epoch [12/20], Loss Critic: -9.9393, Loss Generator: -10.0473\n","Epoch [13/20], Loss Critic: -5.1512, Loss Generator: -9.6763\n","Epoch [14/20], Loss Critic: -4.7708, Loss Generator: -7.9475\n","Epoch [15/20], Loss Critic: -4.1793, Loss Generator: -5.1070\n","Epoch [16/20], Loss Critic: -2.1141, Loss Generator: -1.4774\n","Epoch [17/20], Loss Critic: -2.5933, Loss Generator: 0.8737\n","Epoch [18/20], Loss Critic: -1.6936, Loss Generator: -2.2398\n","Epoch [19/20], Loss Critic: -2.9735, Loss Generator: -2.0432\n","Epoch [20/20], Loss Critic: -2.8400, Loss Generator: -3.1283\n","WGAN-GP training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"VAE-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            generator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Discriminator initialization for other GAN types\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\"] else None,  # Add only for Conditional and InfoGAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": data_loader,  # Two loaders for these models\n","            \"data_loader_b\": data_loader\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": data_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0didxsdTdCKu","executionInfo":{"status":"ok","timestamp":1737292612970,"user_tz":-210,"elapsed":30015,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"a28c1473-570c-467d-ec31-2784e2ae75e4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing VAE-GAN configuration: {'encoder': <class 'src.gan_workflows.plan2.plan2_gan_models.VAEGANEncoder'>, 'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.VAEGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.VAEGANDiscriminator'>, 'train_function': <function train_vae_gan at 0x7c0ebbc67100>}\n","Generator initialized on VAEGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=256, bias=True)\n","        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Discriminator initialized on VAEGANDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=128, out_features=1, bias=True)\n","    (4): Sigmoid()\n","  )\n",")\n","Encoder initialized on VAEGANEncoder(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","  )\n","  (mu): Linear(in_features=256, out_features=100, bias=True)\n","  (logvar): Linear(in_features=256, out_features=100, bias=True)\n",")\n","Epoch [1/20], D Loss: 0.3058, G Loss: 229.0202\n","Epoch [2/20], D Loss: 0.0466, G Loss: 125.3461\n","Epoch [3/20], D Loss: 0.0106, G Loss: 79.4482\n","Epoch [4/20], D Loss: 0.0298, G Loss: 66.2979\n","Epoch [5/20], D Loss: 0.1169, G Loss: 51.8728\n","Epoch [6/20], D Loss: 0.0978, G Loss: 44.0510\n","Epoch [7/20], D Loss: 0.0764, G Loss: 39.2415\n","Epoch [8/20], D Loss: 0.3586, G Loss: 27.5751\n","Epoch [9/20], D Loss: 0.2798, G Loss: 25.6267\n","Epoch [10/20], D Loss: 0.0731, G Loss: 28.6198\n","Epoch [11/20], D Loss: 0.4679, G Loss: 21.8439\n","Epoch [12/20], D Loss: 0.1555, G Loss: 26.9243\n","Epoch [13/20], D Loss: 0.4186, G Loss: 22.7520\n","Epoch [14/20], D Loss: 0.3409, G Loss: 20.0814\n","Epoch [15/20], D Loss: 0.4666, G Loss: 18.3058\n","Epoch [16/20], D Loss: 0.2814, G Loss: 20.0506\n","Epoch [17/20], D Loss: 0.3831, G Loss: 21.3102\n","Epoch [18/20], D Loss: 0.5803, G Loss: 16.6486\n","Epoch [19/20], D Loss: 0.5731, G Loss: 19.5552\n","Epoch [20/20], D Loss: 0.3847, G Loss: 16.0501\n","VAE-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"VAE-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iB9aeVxwq03v","executionInfo":{"status":"ok","timestamp":1737292642815,"user_tz":-210,"elapsed":29851,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"c68a6430-70ea-417f-a9f1-f88565858429"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing VAE-GAN configuration: {'encoder': <class 'src.gan_workflows.plan2.plan2_gan_models.VAEGANEncoder'>, 'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.VAEGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.VAEGANDiscriminator'>, 'train_function': <function train_vae_gan at 0x7c0ebbc67100>}\n","Generator initialized on VAEGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=256, bias=True)\n","        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Discriminator initialized on VAEGANDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=128, out_features=1, bias=True)\n","    (4): Sigmoid()\n","  )\n",")\n","Encoder initialized on VAEGANEncoder(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","  )\n","  (mu): Linear(in_features=256, out_features=100, bias=True)\n","  (logvar): Linear(in_features=256, out_features=100, bias=True)\n",")\n","Epoch [1/20], D Loss: 0.3520, G Loss: 159.5361\n","Epoch [2/20], D Loss: 0.0489, G Loss: 118.5115\n","Epoch [3/20], D Loss: 0.0221, G Loss: 58.7038\n","Epoch [4/20], D Loss: 0.0765, G Loss: 48.6314\n","Epoch [5/20], D Loss: 0.0797, G Loss: 42.6573\n","Epoch [6/20], D Loss: 0.0940, G Loss: 39.2106\n","Epoch [7/20], D Loss: 0.3463, G Loss: 28.5145\n","Epoch [8/20], D Loss: 0.1263, G Loss: 29.0749\n","Epoch [9/20], D Loss: 0.2390, G Loss: 23.6519\n","Epoch [10/20], D Loss: 0.0926, G Loss: 26.9904\n","Epoch [11/20], D Loss: 0.1778, G Loss: 22.3706\n","Epoch [12/20], D Loss: 0.4927, G Loss: 22.7005\n","Epoch [13/20], D Loss: 0.3769, G Loss: 24.4916\n","Epoch [14/20], D Loss: 0.3636, G Loss: 20.4122\n","Epoch [15/20], D Loss: 0.3504, G Loss: 18.9299\n","Epoch [16/20], D Loss: 0.5386, G Loss: 21.6421\n","Epoch [17/20], D Loss: 0.5437, G Loss: 15.7590\n","Epoch [18/20], D Loss: 0.4548, G Loss: 18.7676\n","Epoch [19/20], D Loss: 0.3558, G Loss: 14.2361\n","Epoch [20/20], D Loss: 0.5326, G Loss: 14.7587\n","VAE-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Contrastive-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            generator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Discriminator initialization for other GAN types\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\"] else None,  # Add only for Conditional and InfoGAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": data_loader,  # Two loaders for these models\n","            \"data_loader_b\": data_loader\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": data_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBKSdkTkfRKl","executionInfo":{"status":"ok","timestamp":1737292686588,"user_tz":-210,"elapsed":43778,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"160625ef-cdd8-4c01-c1fd-df2a0a307440"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Contrastive-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.ContrastiveGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.ContrastiveGANDiscriminator'>, 'train_function': <function train_contrastive_gan at 0x7c0ebbc671a0>}\n","Generator initialized on ContrastiveGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=512, bias=True)\n","        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Discriminator initialized on ContrastiveGANDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=128, out_features=1, bias=True)\n","    (4): Sigmoid()\n","  )\n",")\n","Epoch [1/20], D Loss: 0.0219, G Loss: -119.7762\n","Epoch [2/20], D Loss: 0.0009, G Loss: -264.7991\n","Epoch [3/20], D Loss: 0.0001, G Loss: -382.0185\n","Epoch [4/20], D Loss: 0.0001, G Loss: -584.0962\n","Epoch [5/20], D Loss: 0.0001, G Loss: -807.1037\n","Epoch [6/20], D Loss: 0.0000, G Loss: -888.8688\n","Epoch [7/20], D Loss: 0.0004, G Loss: -1044.6561\n","Epoch [8/20], D Loss: 0.0001, G Loss: -1368.1104\n","Epoch [9/20], D Loss: 0.0121, G Loss: -1664.6439\n","Epoch [10/20], D Loss: 0.0108, G Loss: -1717.8788\n","Epoch [11/20], D Loss: 0.0001, G Loss: -2081.2803\n","Epoch [12/20], D Loss: 0.0000, G Loss: -2443.2239\n","Epoch [13/20], D Loss: 0.0000, G Loss: -3074.6074\n","Epoch [14/20], D Loss: 0.0013, G Loss: -2787.7854\n","Epoch [15/20], D Loss: 0.0002, G Loss: -3662.1313\n","Epoch [16/20], D Loss: 0.0000, G Loss: -3864.8779\n","Epoch [17/20], D Loss: 0.0013, G Loss: -4114.3672\n","Epoch [18/20], D Loss: 0.0001, G Loss: -4163.5483\n","Epoch [19/20], D Loss: 0.0000, G Loss: -5043.9766\n","Epoch [20/20], D Loss: 0.0000, G Loss: -5434.6211\n","Contrastive-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Contrastive-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9iKQAgdFq5hs","executionInfo":{"status":"ok","timestamp":1737292730513,"user_tz":-210,"elapsed":43929,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"fef02753-c91e-4c29-8fe9-fe707094bb50"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Contrastive-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.ContrastiveGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.ContrastiveGANDiscriminator'>, 'train_function': <function train_contrastive_gan at 0x7c0ebbc671a0>}\n","Generator initialized on ContrastiveGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=512, bias=True)\n","        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Discriminator initialized on ContrastiveGANDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=128, out_features=1, bias=True)\n","    (4): Sigmoid()\n","  )\n",")\n","Epoch [1/20], D Loss: 0.0181, G Loss: -154.2273\n","Epoch [2/20], D Loss: 0.0006, G Loss: -295.1485\n","Epoch [3/20], D Loss: 0.0001, G Loss: -419.2675\n","Epoch [4/20], D Loss: 0.0000, G Loss: -559.4766\n","Epoch [5/20], D Loss: 0.0001, G Loss: -714.4061\n","Epoch [6/20], D Loss: 0.0000, G Loss: -1011.5626\n","Epoch [7/20], D Loss: 0.0001, G Loss: -1256.8906\n","Epoch [8/20], D Loss: 0.0058, G Loss: -1322.7163\n","Epoch [9/20], D Loss: 0.0060, G Loss: -1615.2444\n","Epoch [10/20], D Loss: 0.0000, G Loss: -1879.8688\n","Epoch [11/20], D Loss: 0.0001, G Loss: -2056.7725\n","Epoch [12/20], D Loss: 0.0014, G Loss: -2717.0977\n","Epoch [13/20], D Loss: 0.0004, G Loss: -2613.7007\n","Epoch [14/20], D Loss: 0.0004, G Loss: -2950.3870\n","Epoch [15/20], D Loss: 0.0000, G Loss: -3473.5361\n","Epoch [16/20], D Loss: 0.0005, G Loss: -4153.2065\n","Epoch [17/20], D Loss: 0.0000, G Loss: -4489.5176\n","Epoch [18/20], D Loss: 0.0000, G Loss: -4541.7305\n","Epoch [19/20], D Loss: 0.0000, G Loss: -5016.6958\n","Epoch [20/20], D Loss: 0.0003, G Loss: -4987.7109\n","Contrastive-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Cross-Domain-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            generator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Discriminator initialization for other GAN types\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\"] else None,  # Add only for Conditional and InfoGAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": data_loader,  # Two loaders for these models\n","            \"data_loader_b\": data_loader\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": data_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4I4eldnf9c8","executionInfo":{"status":"ok","timestamp":1737292755254,"user_tz":-210,"elapsed":24745,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"0678504e-276a-4f26-ba5a-c5077679750f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Cross-Domain-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.CrossDomainGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.CrossDomainDiscriminator'>, 'train_function': <function train_cross_domain_gan at 0x7c0ebbc67240>}\n","Generator initialized on CrossDomainGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Discriminator initialized on CrossDomainDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n",")\n","Epoch [1/20], D Loss: 0.7209, G Loss: 0.8925\n","Epoch [2/20], D Loss: 0.4688, G Loss: 1.4272\n","Epoch [3/20], D Loss: 0.2141, G Loss: 2.3404\n","Epoch [4/20], D Loss: 0.1638, G Loss: 2.7952\n","Epoch [5/20], D Loss: 0.1317, G Loss: 3.1884\n","Epoch [6/20], D Loss: 0.0666, G Loss: 3.7971\n","Epoch [7/20], D Loss: 0.2464, G Loss: 3.1403\n","Epoch [8/20], D Loss: 0.1556, G Loss: 5.0271\n","Epoch [9/20], D Loss: 0.1300, G Loss: 3.1753\n","Epoch [10/20], D Loss: 0.1444, G Loss: 3.9002\n","Epoch [11/20], D Loss: 0.2042, G Loss: 3.6552\n","Epoch [12/20], D Loss: 0.3886, G Loss: 3.0716\n","Epoch [13/20], D Loss: 0.4192, G Loss: 4.0265\n","Epoch [14/20], D Loss: 0.4073, G Loss: 2.4267\n","Epoch [15/20], D Loss: 0.5957, G Loss: 2.3735\n","Epoch [16/20], D Loss: 0.3113, G Loss: 2.9772\n","Epoch [17/20], D Loss: 0.3861, G Loss: 2.4077\n","Epoch [18/20], D Loss: 0.5841, G Loss: 3.1465\n","Epoch [19/20], D Loss: 0.3570, G Loss: 2.5573\n","Epoch [20/20], D Loss: 0.5368, G Loss: 2.5158\n","Cross-Domain-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Cross-Domain-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zuJbolWqrD8g","executionInfo":{"status":"ok","timestamp":1737292784674,"user_tz":-210,"elapsed":29422,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"cc8b4ab0-4ba1-4c03-94ac-e16aee7abd7f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Cross-Domain-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.CrossDomainGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.CrossDomainDiscriminator'>, 'train_function': <function train_cross_domain_gan at 0x7c0ebbc67240>}\n","Generator initialized on CrossDomainGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Discriminator initialized on CrossDomainDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n",")\n","Epoch [1/20], D Loss: 0.5506, G Loss: 1.0794\n","Epoch [2/20], D Loss: 0.3476, G Loss: 1.6815\n","Epoch [3/20], D Loss: 0.2485, G Loss: 2.3224\n","Epoch [4/20], D Loss: 0.1969, G Loss: 2.8637\n","Epoch [5/20], D Loss: 0.2000, G Loss: 4.0712\n","Epoch [6/20], D Loss: 0.0920, G Loss: 3.9217\n","Epoch [7/20], D Loss: 0.0940, G Loss: 4.2426\n","Epoch [8/20], D Loss: 0.0706, G Loss: 4.5771\n","Epoch [9/20], D Loss: 0.1310, G Loss: 4.4926\n","Epoch [10/20], D Loss: 0.1195, G Loss: 3.2878\n","Epoch [11/20], D Loss: 0.7853, G Loss: 7.2396\n","Epoch [12/20], D Loss: 0.4594, G Loss: 3.4758\n","Epoch [13/20], D Loss: 0.2564, G Loss: 2.5754\n","Epoch [14/20], D Loss: 0.2481, G Loss: 3.3211\n","Epoch [15/20], D Loss: 0.3613, G Loss: 3.0442\n","Epoch [16/20], D Loss: 0.3261, G Loss: 3.2438\n","Epoch [17/20], D Loss: 0.3983, G Loss: 2.4850\n","Epoch [18/20], D Loss: 0.4777, G Loss: 2.0450\n","Epoch [19/20], D Loss: 0.5660, G Loss: 1.7907\n","Epoch [20/20], D Loss: 0.5779, G Loss: 2.2762\n","Cross-Domain-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# interesting way to load the embeddings...\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","def load_embeddings(embedding_file, device, batch_size=64, return_labels=True):\n","    \"\"\"\n","    Loads embeddings and their associated labels from a specified file and\n","    creates a DataLoader for batching the embeddings (and optionally labels).\n","\n","    Args:\n","        embedding_file (str): Path to the file containing embeddings and labels.\n","        device (torch.device): The device (CPU/GPU) to load the tensors onto.\n","        batch_size (int, optional): The batch size for DataLoader. Default is 64.\n","        return_labels (bool, optional): Whether to include labels in the DataLoader. Default is True.\n","\n","    Returns:\n","        tuple: A tuple containing:\n","            - embeddings (torch.Tensor): Loaded embeddings.\n","            - labels (torch.Tensor, optional): Corresponding labels for the embeddings (if return_labels=True).\n","            - data_loader (DataLoader): DataLoader for batching embeddings (and labels if required).\n","    \"\"\"\n","    print(f\"Loading embeddings from: {embedding_file}\")\n","    data = torch.load(embedding_file)\n","    embeddings = data[\"embeddings\"].to(device)\n","\n","    # Initialize the DataLoader only with embeddings if labels are not required\n","    if return_labels:\n","        labels = data[\"labels\"].to(device)\n","        # Create a TensorDataset containing both embeddings and labels\n","        dataset = TensorDataset(embeddings, labels)\n","        return embeddings, labels, DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    else:\n","        # Create DataLoader for embeddings only\n","        dataset = TensorDataset(embeddings)  # Just embeddings\n","        return embeddings, DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","embeddings, labels, data_loader_v2 = load_embeddings(embedding_file, device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4O5feayRXbjm","executionInfo":{"status":"ok","timestamp":1737292784674,"user_tz":-210,"elapsed":7,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"1f3e6ba8-6c5f-4712-f4a7-07df44f73bf2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading embeddings from: ./saved_embeddings/embeddings/autoencoders_BasicAutoencoder/BasicAutoencoder_embeddings.pt\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-2ba908293933>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(embedding_file)\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"InfoGAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader_v2\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1a6MJ8iBgK0S","executionInfo":{"status":"error","timestamp":1737292785513,"user_tz":-210,"elapsed":845,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"95babf09-5344-4d79-b00d-fa9cadecd5dc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing InfoGAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.InfoGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.InfoGANDiscriminator'>, 'train_function': <function train_infogan at 0x7c0ebbc67600>}\n","Generator initialized on InfoGANGenerator(\n","  (model): Sequential(\n","    (0): Linear(in_features=110, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Linear(in_features=512, out_features=256, bias=True)\n","    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (4): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","InfoGAN discriminator initialized on InfoGANDiscriminator(\n","  (model): Sequential(\n","    (0): Linear(in_features=50, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Linear(in_features=512, out_features=256, bias=True)\n","    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (4): Linear(in_features=256, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n","  (classifier): Linear(in_features=256, out_features=10, bias=True)\n",")\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"all elements of input should be between 0 and 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-8b85b692aca3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# For other models, pass the appropriate generator/discriminator/critic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgan_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Cycle-GAN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dual-GAN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Contrastive-Dual-GAN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"discriminator\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{gan_type} training test passed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/GAN-thesis-project/src/gan_workflows/plan2/plan2_gan_training.py\u001b[0m in \u001b[0;36mtrain_infogan\u001b[0;34m(generator, discriminator, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0mfake_validity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_validity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_validity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m                      \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_validity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_validity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                      \u001b[0mce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add categorical loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         return F.binary_cross_entropy(\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3552\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3554\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Conditional-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 20\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader_v2\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        if gan_type == \"Conditional-GAN\":\n","            # Conditional-GAN generator requires num_classes\n","            generator_args[\"num_classes\"] = num_classes\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"Conditional-GAN\":\n","        # Conditional-GAN discriminator requires embedding_dim and num_classes\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Conditional-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":741},"id":"zMFweDi0uQo5","executionInfo":{"status":"error","timestamp":1737294103669,"user_tz":-210,"elapsed":674,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"8313f977-8945-4c40-9a0d-fa910288c696"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Conditional-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.ConditionalGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.ConditionalGANDiscriminator'>, 'train_function': <function train_conditional_gan at 0x7c0ebbc67560>}\n","Generator initialized on ConditionalGANGenerator(\n","  (model): Sequential(\n","    (0): Linear(in_features=110, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Linear(in_features=512, out_features=256, bias=True)\n","    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (4): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Conditional-GAN discriminator initialized on ConditionalGANDiscriminator(\n","  (model): Sequential(\n","    (0): Linear(in_features=60, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Linear(in_features=512, out_features=256, bias=True)\n","    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (4): Linear(in_features=256, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Tensors must have same number of dimensions: got 2 and 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-e6ad38e34807>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# For other models, pass the appropriate generator/discriminator/critic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgan_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Cycle-GAN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dual-GAN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Contrastive-Dual-GAN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"discriminator\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{gan_type} training test passed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/GAN-thesis-project/src/gan_workflows/plan2/plan2_gan_training.py\u001b[0m in \u001b[0;36mtrain_conditional_gan\u001b[0;34m(generator, discriminator, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mfake_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mreal_validity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/GAN-thesis-project/src/gan_workflows/plan2/plan2_gan_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, labels)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGenerated\u001b[0m \u001b[0membedding\u001b[0m \u001b[0mconditioned\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatent\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \"\"\"\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;31m# Ensure labels are one-hot encoded if they are class indices (1D tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If `labels` is a 1D vector (e.g., class indices), make it one-hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to one-hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9haSFw8cuX9-"},"execution_count":null,"outputs":[]}]}