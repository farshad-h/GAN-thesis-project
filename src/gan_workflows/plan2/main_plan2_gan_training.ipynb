{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Plan 2: GAN Training with Embeddings\n","\n","## Objective\n","The goal of this plan is to train GANs using embeddings generated from Plan 1. This involves:\n","1. Setting up a GAN architecture that incorporates embeddings.\n","2. Training the GAN to generate high-quality synthetic embeddings or data.\n","3. Evaluating the GAN's performance using relevant metrics.\n","\n","## Key Steps\n","\n","### 1. Define GAN Architecture\n","- **Generator**: Accepts embeddings and noise as inputs, producing synthetic data.\n","- **Discriminator**: Evaluates the authenticity of generated data, optionally conditioned on embeddings.\n","\n","### 2. Load Pre-Generated Embeddings\n","- Load embeddings created in Plan 1 from their respective directories.\n","- Normalize and preprocess embeddings for GAN training.\n","\n","### 3. Train the GAN\n","- Set up training loops for the generator and discriminator.\n","- Use appropriate loss functions, such as adversarial loss (e.g., Wasserstein loss).\n","- Optionally, include auxiliary tasks (e.g., reconstruction loss) for better embedding alignment.\n","\n","### 4. Save Outputs\n","- Save trained GAN models.\n","- Save generated embeddings or data for downstream evaluation.\n","\n","### 5. Evaluate GAN Performance\n","- Use metrics like FID, IS, and qualitative visualization.\n","- Compare performance with baseline models or methods.\n","\n","---\n","\n","## Starting Point\n","\n","**Files Available**:\n","- `plan2_gan_models.py`: Contains the GAN architecture.\n","- `plan2_gan_training.py`: Implements the training pipeline.\n","- `main_plan2_gan_training.ipynb`: High-level control notebook.\n","- `plan2_experiments.ipynb`: For experimentation and evaluation.\n","\n","## Next Steps\n","1. **Review Architecture**:\n","   - Inspect `plan2_gan_models.py` to understand the generator and discriminator setup.\n","2. **Pipeline Setup**:\n","   - Review and prepare the training pipeline in `plan2_gan_training.py`.\n","3. **Experimentation**:\n","   - Use `plan2_experiments.ipynb` for controlled experiments.\n"],"metadata":{"id":"6aVzhiUvYnnh"}},{"cell_type":"code","source":["# Plan 2 GAN Training Notebook\n","\n","import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import logging\n","from datetime import datetime\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Repository path (adjust if needed)\n","repo_path = \"/content/drive/MyDrive/GAN-thesis-project\"\n","\n","# Add repository path to sys.path for module imports\n","if repo_path not in sys.path:\n","    sys.path.append(repo_path)\n","\n","# Change working directory to the repository\n","os.chdir(repo_path)\n","\n","# Verify the working directory\n","print(f\"Current working directory: {os.getcwd()}\")\n","\n","\n","# Set random seed and device\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3fgL_75bNh_","executionInfo":{"status":"ok","timestamp":1738137231903,"user_tz":-210,"elapsed":79645,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"368ad808-dd42-4b8b-8d26-d5948cbbd591"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Current working directory: /content/drive/MyDrive/GAN-thesis-project\n","Using device: cpu\n"]}]},{"cell_type":"code","source":["# just for you to see what are the implemented function and classes that have been coded up...\n","\n","import inspect\n","\n","# Import the entire modules\n","import src.data_utils as data_utils\n","import src.cl_loss_function as cl_loss\n","import src.losses as losses\n","import src.gan_workflows.plan2.plan2_gan_models as gan_models\n","import src.gan_workflows.plan2.plan2_gan_training as gan_training\n","\n","# Function to list functions and classes in a module\n","def list_functions_and_classes(module):\n","    members = inspect.getmembers(module)\n","    functions = [name for name, obj in members if inspect.isfunction(obj)]\n","    classes = [name for name, obj in members if inspect.isclass(obj)]\n","    return functions, classes\n","\n","# Function to print functions and classes in a readable format\n","def print_functions_and_classes(module_name, module):\n","    functions, classes = list_functions_and_classes(module)\n","    print(f\"Module: {module_name}\")\n","    print(\"  Functions:\")\n","    for func in functions:\n","        print(f\"    - {func}\")\n","    print(\"  Classes:\")\n","    for cls in classes:\n","        print(f\"    - {cls}\")\n","    print()  # Add a blank line for separation\n","\n","# Print functions and classes for each module\n","print_functions_and_classes(\"src.data_utils\", data_utils)\n","print_functions_and_classes(\"src.cl_loss_function\", cl_loss)\n","print_functions_and_classes(\"src.losses\", losses)\n","print_functions_and_classes(\"src.embeddings.encoder_models\", gan_models)\n","print_functions_and_classes(\"src.embeddings.encoder_training\", gan_training)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMNOlaoUC4c7","executionInfo":{"status":"ok","timestamp":1738137529502,"user_tz":-210,"elapsed":13552,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"5e55f0b3-fa1f-4b11-9388-fc22026ae273"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Module: src.data_utils\n","  Functions:\n","    - analyze_embeddings\n","    - analyze_embeddings_v2\n","    - create_dataloader\n","    - create_embedding_loaders\n","    - generate_embeddings\n","    - kurtosis\n","    - load_data\n","    - load_embeddings\n","    - load_mnist_data\n","    - pdist\n","    - preprocess_images\n","    - save_embeddings\n","    - skew\n","    - split_dataset\n","    - train_test_split\n","    - visualize_embeddings\n","  Classes:\n","    - DataLoader\n","    - LocalOutlierFactor\n","    - TensorDataset\n","\n","Module: src.cl_loss_function\n","  Functions:\n","    - augment\n","    - compute_nt_xent_loss_with_augmentation\n","    - compute_triplet_loss_with_augmentation\n","    - contrastive_loss\n","    - hflip\n","    - info_nce_loss\n","    - resize\n","  Classes:\n","    - BYOLLoss\n","    - BarlowTwinsLoss\n","    - ContrastiveHead\n","    - DataLoader\n","    - NTXentLoss\n","    - PCA\n","    - Predictor\n","    - TensorDataset\n","    - TripletLoss\n","    - VicRegLoss\n","\n","Module: src.losses\n","  Functions:\n","    - add_noise\n","    - cyclical_beta_schedule\n","    - linear_beta_schedule\n","    - loss_function_dae_ssim\n","    - vae_loss\n","    - vae_ssim_loss\n","  Classes:\n","\n","Module: src.embeddings.encoder_models\n","  Functions:\n","    - compute_gradient_penalty\n","    - nt_xent_loss\n","  Classes:\n","    - ConditionalGANDiscriminator\n","    - ConditionalGANGenerator\n","    - ContrastiveDualGANDiscriminator\n","    - ContrastiveDualGANGenerator\n","    - ContrastiveGANDiscriminator\n","    - ContrastiveGANGenerator\n","    - CrossDomainDiscriminator\n","    - CrossDomainGenerator\n","    - CycleDiscriminator\n","    - CycleGenerator\n","    - DualGANDiscriminator\n","    - DualGANGenerator\n","    - InfoGANDiscriminator\n","    - InfoGANGenerator\n","    - LinearBlock\n","    - SemiSupervisedGANDiscriminator\n","    - SimpleGANDiscriminator\n","    - SimpleGANGenerator\n","    - VAEGANDiscriminator\n","    - VAEGANEncoder\n","    - VAEGANGenerator\n","    - WGANCritic\n","    - WGANGenerator\n","\n","Module: src.embeddings.encoder_training\n","  Functions:\n","    - compute_gradient_penalty\n","    - train_conditional_gan\n","    - train_contrastive_dual_gan\n","    - train_contrastive_gan\n","    - train_cross_domain_gan\n","    - train_cycle_gan\n","    - train_dual_gan\n","    - train_infogan\n","    - train_semi_supervised_gan\n","    - train_vae_gan\n","    - train_wgan_gp\n","  Classes:\n","\n"]}]},{"cell_type":"code","source":["# GAN Models and Training Functions\n","from src.gan_workflows.plan2.plan2_gan_models import (\n","    SimpleGANGenerator, SimpleGANDiscriminator,\n","    ContrastiveGANGenerator, ContrastiveGANDiscriminator,\n","    VAEGANEncoder, VAEGANGenerator, VAEGANDiscriminator,\n","    WGANGenerator, WGANCritic,\n","    CrossDomainGenerator, CrossDomainDiscriminator,\n","    CycleGenerator, CycleDiscriminator,\n","    DualGANGenerator, DualGANDiscriminator,\n","    ContrastiveDualGANGenerator, ContrastiveDualGANDiscriminator,\n","    SemiSupervisedGANDiscriminator,\n","    ConditionalGANGenerator, ConditionalGANDiscriminator,\n","    InfoGANGenerator, InfoGANDiscriminator,\n","    compute_gradient_penalty\n",")\n","\n","from src.gan_workflows.plan2.plan2_gan_training import (\n","    train_wgan_gp, train_vae_gan, train_contrastive_gan,\n","    train_cross_domain_gan, train_cycle_gan,\n","    train_dual_gan, train_contrastive_dual_gan,\n","    train_semi_supervised_gan,\n","    train_conditional_gan,\n","    train_infogan\n",")\n","\n","from src.data_utils import (\n","    load_embeddings, analyze_embeddings\n",")"],"metadata":{"id":"weigTIkfEl2N","executionInfo":{"status":"ok","timestamp":1738137571037,"user_tz":-210,"elapsed":384,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["embedding_dir = \"./saved_embeddings/embeddings/autoencoders_BasicAutoencoder\"  # Example embedding path\n","embedding_file = os.path.join(embedding_dir, \"BasicAutoencoder_embeddings.pt\")\n","\n","# Load embeddings and labels using the new function\n","embeddings, labels, data_loader = load_embeddings(embedding_file, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ww8mcFrOzsG_","executionInfo":{"status":"ok","timestamp":1738146682630,"user_tz":-210,"elapsed":355,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"3a9a337a-a165-424c-adb3-802281fc2251"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO - Loading embeddings from: ./saved_embeddings/embeddings/autoencoders_BasicAutoencoder/BasicAutoencoder_embeddings.pt\n","/content/drive/MyDrive/GAN-thesis-project/src/data_utils.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(embedding_file)\n"]}]},{"cell_type":"code","source":["# ## OLD VERSION\n","\n","# def validate_embeddings(embeddings):\n","#     \"\"\"\n","#     Validate and provide information about the shape and data type of embeddings.\n","#     \"\"\"\n","#     if embeddings is None or len(embeddings) == 0:\n","#         raise ValueError(\"Embeddings are empty or not properly generated.\")\n","#     print(f\"Embeddings are of shape: {embeddings.shape}\")\n","#     print(f\"Data type: {embeddings.dtype}\")\n","#     print(f\"Device: {embeddings.device}\")\n","#     if torch.isnan(embeddings).any():\n","#         raise ValueError(\"Embeddings contain NaN values.\")\n","#     if torch.isinf(embeddings).any():\n","#         raise ValueError(\"Embeddings contain infinite values.\")\n","#     if embeddings.ndim != 2:\n","#         raise ValueError(\"Embeddings should be a 2D tensor.\")\n","#     print(\"Embeddings validation passed.\")\n","\n","# validate_embeddings(embeddings)"],"metadata":{"id":"584Xs4_8EGLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a batch of training data\n","embedding_batch = next(iter(data_loader))\n","print('embedding batches', embedding_batch.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IXt_LRiEfWo","executionInfo":{"status":"ok","timestamp":1738144553844,"user_tz":-210,"elapsed":304,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"a6c89db9-7687-4cb0-e38c-8bfcdbc931b8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["embedding batches torch.Size([64, 50])\n"]}]},{"cell_type":"code","source":["# GAN Configuration Dictionary\n","gan_configurations = {\n","    \"WGAN-GP\": {\n","        \"generator\": WGANGenerator,\n","        \"critic\": WGANCritic,\n","        \"train_function\": train_wgan_gp,\n","        \"train_kwargs\": {\"lambda_gp\": 10}\n","    },\n","    \"VAE-GAN\": {\n","        \"encoder\": VAEGANEncoder,\n","        \"generator\": VAEGANGenerator,\n","        \"discriminator\": VAEGANDiscriminator,\n","        \"train_function\": train_vae_gan\n","    },\n","    \"Contrastive-GAN\": {\n","        \"generator\": ContrastiveGANGenerator,\n","        \"discriminator\": ContrastiveGANDiscriminator,\n","        \"train_function\": train_contrastive_gan\n","    },\n","    \"Cross-Domain-GAN\": {\n","        \"generator\": CrossDomainGenerator,\n","        \"discriminator\": CrossDomainDiscriminator,\n","        \"train_function\": train_cross_domain_gan\n","    },\n","    \"Cycle-GAN\": {\n","        \"generator_a\": CycleGenerator,\n","        \"generator_b\": CycleGenerator,\n","        \"discriminator_a\": CycleDiscriminator,\n","        \"discriminator_b\": CycleDiscriminator,\n","        \"train_function\": train_cycle_gan\n","    },\n","    \"Dual-GAN\": {\n","        \"generator_a\": DualGANGenerator,\n","        \"generator_b\": DualGANGenerator,\n","        \"discriminator_a\": DualGANDiscriminator,\n","        \"discriminator_b\": DualGANDiscriminator,\n","        \"train_function\": train_dual_gan\n","    },\n","    \"Contrastive-Dual-GAN\": {\n","        \"generator_a\": ContrastiveDualGANGenerator,\n","        \"generator_b\": ContrastiveDualGANGenerator,\n","        \"discriminator_a\": ContrastiveDualGANDiscriminator,\n","        \"discriminator_b\": ContrastiveDualGANDiscriminator,\n","        \"train_function\": train_contrastive_dual_gan\n","    },\n","    \"Semi-Supervised-GAN\": {\n","        \"generator\": SimpleGANGenerator,\n","        \"discriminator\": SemiSupervisedGANDiscriminator,\n","        \"train_function\": train_semi_supervised_gan\n","    },\n","    \"Conditional-GAN\": {\n","        \"generator\": ConditionalGANGenerator,\n","        \"discriminator\": ConditionalGANDiscriminator,\n","        \"train_function\": train_conditional_gan\n","    },\n","    \"InfoGAN\": {\n","        \"generator\": InfoGANGenerator,\n","        \"discriminator\": InfoGANDiscriminator,\n","        \"train_function\": train_infogan\n","    }\n","}"],"metadata":{"id":"b4gSo_7Z6vMk","executionInfo":{"status":"ok","timestamp":1738161275563,"user_tz":-210,"elapsed":320,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["gan_configurations.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ6ohBk4r-2k","executionInfo":{"status":"ok","timestamp":1738147905176,"user_tz":-210,"elapsed":740,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"78f576fd-334d-4314-d8c0-bb6a737d8fcd"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['WGAN-GP', 'VAE-GAN', 'Contrastive-GAN', 'Cross-Domain-GAN', 'Cycle-GAN', 'Dual-GAN', 'Contrastive-Dual-GAN', 'Semi-Supervised-GAN', 'Conditional-GAN', 'InfoGAN'])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["import os\n","\n","# Base directory where embeddings are stored\n","embedding_base_dir = \"./saved_embeddings/embeddings/\"\n","\n","def list_available_embeddings(base_dir, filter_by=None):\n","    \"\"\"\n","    List available embedding directories and files, optionally filtered by method.\n","\n","    Args:\n","        base_dir (str): The base directory containing embeddings.\n","        filter_by (str or list, optional): Method(s) to filter by (e.g., \"autoencoder\", \"vae\").\n","                                           If None, all embeddings are displayed.\n","    \"\"\"\n","    print(\"\\n📂 Available Embeddings:\\n\")\n","\n","    if isinstance(filter_by, str):\n","        filter_by = [filter_by]  # Convert single filter to list\n","\n","    for method in sorted(os.listdir(base_dir)):\n","        method_path = os.path.join(base_dir, method)\n","\n","        # Check if it's a directory\n","        if os.path.isdir(method_path):\n","            if filter_by is None or any(f.lower() in method.lower() for f in filter_by):\n","                pt_files = [f for f in sorted(os.listdir(method_path)) if f.endswith(\".pt\")]\n","                if pt_files:\n","                    print(f\"\\n🔹 {method}\")  # Show only the category\n","                    for file in pt_files:\n","                        print(f\"   📄 {method}/{file}\")  # Show category + filename\n","\n","# Default: Show everything\n","list_available_embeddings(embedding_base_dir)\n","\n","# Example: Show only autoencoder-related embeddings\n","# list_available_embeddings(embedding_base_dir, filter_by=\"vae\")\n","\n","# Example: Show both autoencoder and VAE embeddings\n","# list_available_embeddings(embedding_base_dir, filter_by=[\"autoencoder\", \"vae\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YIuHE2TvHW4","executionInfo":{"status":"ok","timestamp":1738165551761,"user_tz":-210,"elapsed":306,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"4bbb9322-5540-4d2e-b0a6-03ec4288faa1"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","📂 Available Embeddings:\n","\n","\n","🔹 autoencoder_AdvancedAutoencoder_barlow_twins\n","   📄 autoencoder_AdvancedAutoencoder_barlow_twins/AdvancedAutoencoder_barlow_twins_embeddings.pt\n","\n","🔹 autoencoder_AdvancedAutoencoder_contrastive\n","   📄 autoencoder_AdvancedAutoencoder_contrastive/AdvancedAutoencoder_contrastive_embeddings.pt\n","\n","🔹 autoencoder_AdvancedAutoencoder_info_nce\n","   📄 autoencoder_AdvancedAutoencoder_info_nce/AdvancedAutoencoder_info_nce_embeddings.pt\n","\n","🔹 autoencoder_AdvancedAutoencoder_mse\n","   📄 autoencoder_AdvancedAutoencoder_mse/AdvancedAutoencoder_mse_embeddings.pt\n","\n","🔹 autoencoder_AdvancedAutoencoder_ntxent\n","   📄 autoencoder_AdvancedAutoencoder_ntxent/AdvancedAutoencoder_ntxent_embeddings.pt\n","\n","🔹 autoencoder_AdvancedAutoencoder_vicreg\n","   📄 autoencoder_AdvancedAutoencoder_vicreg/AdvancedAutoencoder_vicreg_embeddings.pt\n","\n","🔹 autoencoder_EnhancedAutoencoder_barlow_twins\n","   📄 autoencoder_EnhancedAutoencoder_barlow_twins/EnhancedAutoencoder_barlow_twins_embeddings.pt\n","\n","🔹 autoencoder_EnhancedAutoencoder_contrastive\n","   📄 autoencoder_EnhancedAutoencoder_contrastive/EnhancedAutoencoder_contrastive_embeddings.pt\n","\n","🔹 autoencoder_EnhancedAutoencoder_info_nce\n","   📄 autoencoder_EnhancedAutoencoder_info_nce/EnhancedAutoencoder_info_nce_embeddings.pt\n","\n","🔹 autoencoder_EnhancedAutoencoder_mse\n","   📄 autoencoder_EnhancedAutoencoder_mse/EnhancedAutoencoder_mse_embeddings.pt\n","\n","🔹 autoencoder_EnhancedAutoencoder_ntxent\n","   📄 autoencoder_EnhancedAutoencoder_ntxent/EnhancedAutoencoder_ntxent_embeddings.pt\n","\n","🔹 autoencoder_EnhancedAutoencoder_vicreg\n","   📄 autoencoder_EnhancedAutoencoder_vicreg/EnhancedAutoencoder_vicreg_embeddings.pt\n","\n","🔹 autoencoder_IntermediateAutoencoder_barlow_twins\n","   📄 autoencoder_IntermediateAutoencoder_barlow_twins/IntermediateAutoencoder_barlow_twins_embeddings.pt\n","\n","🔹 autoencoder_IntermediateAutoencoder_contrastive\n","   📄 autoencoder_IntermediateAutoencoder_contrastive/IntermediateAutoencoder_contrastive_embeddings.pt\n","\n","🔹 autoencoder_IntermediateAutoencoder_info_nce\n","   📄 autoencoder_IntermediateAutoencoder_info_nce/IntermediateAutoencoder_info_nce_embeddings.pt\n","\n","🔹 autoencoder_IntermediateAutoencoder_mse\n","   📄 autoencoder_IntermediateAutoencoder_mse/IntermediateAutoencoder_mse_embeddings.pt\n","\n","🔹 autoencoder_IntermediateAutoencoder_ntxent\n","   📄 autoencoder_IntermediateAutoencoder_ntxent/IntermediateAutoencoder_ntxent_embeddings.pt\n","\n","🔹 autoencoder_IntermediateAutoencoder_vicreg\n","   📄 autoencoder_IntermediateAutoencoder_vicreg/IntermediateAutoencoder_vicreg_embeddings.pt\n","\n","🔹 autoencoders_AdvancedAutoencoder\n","   📄 autoencoders_AdvancedAutoencoder/AdvancedAutoencoder_embeddings.pt\n","\n","🔹 autoencoders_AdvancedAutoencoder_mse\n","   📄 autoencoders_AdvancedAutoencoder_mse/AdvancedAutoencoder_mse_embeddings.pt\n","\n","🔹 autoencoders_BasicAutoencoder\n","   📄 autoencoders_BasicAutoencoder/BasicAutoencoder_embeddings.pt\n","\n","🔹 autoencoders_BasicAutoencoder_mse\n","   📄 autoencoders_BasicAutoencoder_mse/BasicAutoencoder_mse_embeddings.pt\n","\n","🔹 autoencoders_IntermediateAutoencoder_mse\n","   📄 autoencoders_IntermediateAutoencoder_mse/IntermediateAutoencoder_mse_embeddings.pt\n","\n","🔹 kernel_pca_Kernel PCA\n","   📄 kernel_pca_Kernel PCA/Kernel PCA_embeddings.pt\n","   📄 kernel_pca_Kernel PCA/matrix_factorization_default_loss_kernel_pca_Kernel PCA_embeddings.pt\n","\n","🔹 kernel_pca_SIFT\n","   📄 kernel_pca_SIFT/SIFT_embeddings.pt\n","   📄 kernel_pca_SIFT/matrix_factorization_default_loss_kernel_pca_SIFT_embeddings.pt\n","\n","🔹 matrix_factorization_NMF\n","   📄 matrix_factorization_NMF/NMF_embeddings.pt\n","   📄 matrix_factorization_NMF/matrix_factorization_default_loss_NMF_embeddings.pt\n","\n","🔹 matrix_factorization_PCA\n","   📄 matrix_factorization_PCA/PCA_embeddings.pt\n","   📄 matrix_factorization_PCA/matrix_factorization_default_loss_PCA_embeddings.pt\n","\n","🔹 matrix_factorization_SVD\n","   📄 matrix_factorization_SVD/SVD_embeddings.pt\n","   📄 matrix_factorization_SVD/matrix_factorization_default_loss_SVD_embeddings.pt\n","\n","🔹 normalizing_flow_NMF\n","   📄 normalizing_flow_NMF/NMF_refined_embeddings.pt\n","   📄 normalizing_flow_NMF/matrix_factorization_default_loss_normalizing_flow_NMF_refined_embeddings.pt\n","\n","🔹 normalizing_flow_PCA\n","   📄 normalizing_flow_PCA/PCA_refined_embeddings.pt\n","   📄 normalizing_flow_PCA/matrix_factorization_default_loss_normalizing_flow_PCA_refined_embeddings.pt\n","\n","🔹 normalizing_flow_SVD\n","   📄 normalizing_flow_SVD/SVD_refined_embeddings.pt\n","   📄 normalizing_flow_SVD/matrix_factorization_default_loss_normalizing_flow_SVD_refined_embeddings.pt\n","\n","🔹 sift_features\n","   📄 sift_features/matrix_factorization_default_loss_sift_embeddings.pt\n","   📄 sift_features/sift_embeddings.pt\n","\n","🔹 vae_BasicVAE_mse\n","   📄 vae_BasicVAE_mse/BasicVAE_mse_embeddings.pt\n","\n","🔹 vae_FlexibleVAE_mse\n","   📄 vae_FlexibleVAE_mse/FlexibleVAE_mse_embeddings.pt\n","\n","🔹 vae_ImprovedFlexibleVAE_mse\n","   📄 vae_ImprovedFlexibleVAE_mse/ImprovedFlexibleVAE_mse_embeddings.pt\n","\n","🔹 vae_ImprovedVAE_mse\n","   📄 vae_ImprovedVAE_mse/ImprovedVAE_mse_embeddings.pt\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","from torchvision.models import inception_v3\n","from scipy.linalg import sqrtm\n","import matplotlib.pyplot as plt\n","from scipy.stats import entropy, spearmanr\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.neighbors import NearestNeighbors\n","from scipy.stats import wasserstein_distance\n","import json\n","\n","# ==========================\n","# CONFIGURATION & EMBEDDING LOADING\n","# ==========================\n","embedding_dir = \"./saved_embeddings/embeddings/\"\n","embedding_file = os.path.join(embedding_dir, \"autoencoder_EnhancedAutoencoder_barlow_twins/EnhancedAutoencoder_barlow_twins_embeddings.pt\")\n","\n","# Configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","config = {\n","    \"gan_type\": \"WGAN-GP\",\n","    \"latent_dim\": 100,\n","    \"embedding_dim\": None,  # Will be set after loading embeddings\n","    \"num_classes\": 10,\n","    \"categorical_dim\": 10,\n","    \"epochs\": 1,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-4,\n","    \"device\": device,\n","    \"lambda_gp\": 10,\n","    \"beta1\": 0.5,\n","    \"beta2\": 0.999,\n","    \"save_path\": \"gan_model.pth\",\n","    \"eval_fraction\": 0.1,  # Fraction of embeddings used for evaluation\n","    \"show_model_architecture\": True\n","}\n","\n","def load_embeddings(embedding_file, device, batch_size=64):\n","    \"\"\"Loads embeddings and labels from a specified file.\"\"\"\n","    data = torch.load(embedding_file)\n","    embeddings = data[\"embeddings\"].to(device)\n","    labels = data[\"labels\"].to(device)\n","    data_loader = DataLoader(embeddings, batch_size=batch_size, shuffle=True)\n","    return embeddings, labels, data_loader\n","\n","def split_embeddings(embeddings, labels, eval_fraction=0.1, batch_size=64):\n","    \"\"\"Splits embeddings into training and evaluation sets.\"\"\"\n","    num_samples = embeddings.size(0)\n","    num_eval = int(num_samples * eval_fraction)\n","    num_train = num_samples - num_eval\n","\n","    train_embeddings, eval_embeddings = random_split(embeddings, [num_train, num_eval])\n","    train_labels, eval_labels = random_split(labels, [num_train, num_eval])\n","\n","    train_loader = DataLoader(train_embeddings, batch_size=batch_size, shuffle=True)\n","    eval_loader = DataLoader(eval_embeddings, batch_size=batch_size, shuffle=False)\n","    return train_loader, eval_loader, train_embeddings, eval_embeddings\n","\n","# Load embeddings and split\n","embeddings, labels, full_data_loader = load_embeddings(embedding_file, device)\n","config[\"embedding_dim\"] = embeddings.size(1)\n","train_loader, eval_loader, train_embeddings, eval_embeddings = split_embeddings(embeddings, labels, config[\"eval_fraction\"], config[\"batch_size\"])\n","\n","# Update config with data loaders\n","config.update({\n","    \"data_loader\": train_loader,\n","    \"data_loader_a\": train_loader,\n","    \"data_loader_b\": train_loader,\n","    \"eval_loader\": eval_loader,\n","    \"original_embeddings\": embeddings  # Store original embeddings for evaluation\n","})\n","\n","# ==========================\n","# MODEL INITIALIZATION\n","# ==========================\n","\n","def initialize_gan_components(config, gan_configurations):\n","    \"\"\"Initialize GAN components based on type.\"\"\"\n","    components = {}\n","    gan_type = config[\"gan_type\"]\n","    multi_gan_types = [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]\n","\n","    if gan_type in multi_gan_types:\n","        gen_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type != \"Cycle-GAN\":\n","            gen_args[\"latent_dim\"] = config[\"latent_dim\"]\n","\n","        components.update({\n","            \"generator_a\": gan_configurations[\"generator_a\"](**gen_args).to(config[\"device\"]),\n","            \"generator_b\": gan_configurations[\"generator_b\"](**gen_args).to(config[\"device\"]),\n","            \"discriminator_a\": gan_configurations[\"discriminator_a\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"]),\n","            \"discriminator_b\": gan_configurations[\"discriminator_b\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","        })\n","    else:\n","        gen_args = {\"latent_dim\": config[\"latent_dim\"], \"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            gen_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            gen_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"generator\"] = gan_configurations[\"generator\"](**gen_args).to(config[\"device\"])\n","\n","    if gan_type == \"WGAN-GP\":\n","        components[\"critic\"] = gan_configurations[\"critic\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type == \"VAE-GAN\":\n","        components[\"encoder\"] = gan_configurations[\"encoder\"](embedding_dim=config[\"embedding_dim\"], latent_dim=config[\"latent_dim\"]).to(config[\"device\"])\n","        components[\"discriminator\"] = gan_configurations[\"discriminator\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type not in multi_gan_types:\n","        disc_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"]:\n","            disc_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            disc_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"discriminator\"] = gan_configurations[\"discriminator\"](**disc_args).to(config[\"device\"])\n","\n","    if config[\"show_model_architecture\"]:\n","        print(f\"Initialized components: {components}\")\n","\n","    return components\n","\n","# ==========================\n","# EVALUATION METRICS\n","# ==========================\n","\n","def calculate_fid(real_embeddings, generated_embeddings):\n","    \"\"\"Compute Fréchet Inception Distance (FID).\"\"\"\n","    mu1, sigma1 = np.mean(real_embeddings, axis=0), np.cov(real_embeddings, rowvar=False)\n","    mu2, sigma2 = np.mean(generated_embeddings, axis=0), np.cov(generated_embeddings, rowvar=False)\n","    diff = mu1 - mu2\n","    covmean = sqrtm(sigma1 @ sigma2)\n","    if np.iscomplexobj(covmean):\n","        covmean = covmean.real\n","    return np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2 * covmean)\n","\n","def calculate_kl_divergence(real_embeddings, generated_embeddings):\n","    \"\"\"Compute KL divergence between real and generated embeddings.\"\"\"\n","    real_prob = np.histogram(real_embeddings, bins=50, density=True)[0]\n","    gen_prob = np.histogram(generated_embeddings, bins=50, density=True)[0]\n","    real_prob += 1e-10  # Prevent division by zero\n","    gen_prob += 1e-10\n","    return entropy(real_prob, gen_prob)\n","\n","def calculate_cosine_similarity(real_embeddings, generated_embeddings):\n","    \"\"\"Compute cosine similarity between real and generated embeddings.\"\"\"\n","    return np.mean(cosine_similarity(real_embeddings, generated_embeddings))\n","\n","def rank_similarity(real_embeddings, generated_embeddings):\n","    \"\"\"Compute Spearman Rank Correlation between real and generated embeddings, ensuring matched dimensions.\"\"\"\n","    min_size = min(real_embeddings.shape[0], generated_embeddings.shape[0])\n","\n","    # Randomly sample real embeddings if larger\n","    if real_embeddings.shape[0] > min_size:\n","        real_embeddings = real_embeddings[np.random.choice(real_embeddings.shape[0], min_size, replace=False)]\n","\n","    # Randomly sample generated embeddings if larger\n","    if generated_embeddings.shape[0] > min_size:\n","        generated_embeddings = generated_embeddings[np.random.choice(generated_embeddings.shape[0], min_size, replace=False)]\n","\n","    # Ensure the shapes are aligned for ranking\n","    real_rank = np.argsort(real_embeddings, axis=0)\n","    gen_rank = np.argsort(generated_embeddings, axis=0)\n","\n","    return spearmanr(real_rank.flatten(), gen_rank.flatten()).correlation\n","\n","def unique_embedding_ratio(generated_embeddings):\n","    \"\"\"Compute the ratio of unique embeddings in the generated set.\"\"\"\n","    unique_embeddings = np.unique(generated_embeddings, axis=0)\n","    return len(unique_embeddings) / len(generated_embeddings)\n","\n","def aggregate_quality_score(fid, kl, cosine, rank_corr):\n","    \"\"\"Compute a weighted quality score based on multiple metrics.\"\"\"\n","    # Normalize metrics (assuming lower is better for FID & KL)\n","    fid_norm = 1 / (1 + fid)\n","    kl_norm = 1 / (1 + kl)\n","    cosine_norm = cosine  # Higher is better, no need to invert\n","    rank_norm = (rank_corr + 1) / 2  # Convert [-1,1] to [0,1]\n","\n","    # Compute final weighted score\n","    return (0.4 * fid_norm) + (0.2 * kl_norm) + (0.2 * cosine_norm) + (0.2 * rank_norm)\n","\n","def calculate_wasserstein_distance(real_embeddings, generated_embeddings):\n","    \"\"\"Compute Wasserstein Distance between real and generated embeddings.\"\"\"\n","    return wasserstein_distance(real_embeddings.flatten(), generated_embeddings.flatten())\n","\n","def calculate_coverage_score(real_embeddings, generated_embeddings, n_neighbors=5):\n","    \"\"\"Compute Coverage Score: Percentage of real embeddings with at least one close match in generated embeddings.\"\"\"\n","    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n","    neigh.fit(generated_embeddings)\n","    distances, _ = neigh.kneighbors(real_embeddings)\n","    return np.mean(distances[:, 0] < 0.1)  # Adjust threshold as needed\n","\n","def calculate_memorization_score(real_embeddings, generated_embeddings, n_neighbors=1, tolerance=1e-3):\n","    \"\"\"Compute Memorization Score: Percentage of generated embeddings that are close to real embeddings within a small tolerance.\"\"\"\n","    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n","    neigh.fit(real_embeddings)\n","    distances, _ = neigh.kneighbors(generated_embeddings)\n","\n","    return np.mean(distances[:, 0] < tolerance)  # Allow small tolerance for near-exact matches\n","\n","def generate_synthetic_samples(generator, num_samples=1000, latent_dim=100, device=\"cuda\"):\n","    \"\"\"Generate synthetic samples using a trained GAN generator.\"\"\"\n","    generator.eval()\n","    with torch.no_grad():\n","        latent_vectors = torch.randn(num_samples, latent_dim).to(device)\n","        generated_samples = generator(latent_vectors)\n","    return generated_samples.cpu()\n","\n","def create_dataloader_from_samples(samples, batch_size=64):\n","    return DataLoader(samples, batch_size=batch_size, shuffle=False)\n","\n","def convert_to_float(metrics):\n","    \"\"\"Ensure all values in the dictionary are JSON serializable.\"\"\"\n","    return {k: float(v) for k, v in metrics.items()}\n","\n","def evaluate_gan(gan_components, config):\n","    \"\"\"Evaluate GAN with multiple metrics, ensuring JSON serialization.\"\"\"\n","    device = config[\"device\"]\n","    generator = gan_components[\"generator\"]\n","\n","    generated_samples = generate_synthetic_samples(generator, num_samples=1000, latent_dim=config[\"latent_dim\"], device=device)\n","    generated_dataloader = create_dataloader_from_samples(generated_samples, batch_size=config[\"batch_size\"])\n","\n","    real_embeddings = config[\"original_embeddings\"].cpu().numpy()\n","    eval_embeddings = torch.cat([batch for batch in config[\"eval_loader\"]], dim=0).cpu().numpy()\n","    gen_embeddings = torch.cat([batch for batch in generated_dataloader], dim=0).cpu().numpy()\n","\n","    metrics = {\n","        \"FID (Original vs Generated)\": calculate_fid(real_embeddings, gen_embeddings),\n","        \"FID (Original vs Eval)\": calculate_fid(real_embeddings, eval_embeddings),\n","        \"KL Divergence\": calculate_kl_divergence(real_embeddings, gen_embeddings),\n","        \"Cosine Similarity\": calculate_cosine_similarity(real_embeddings, gen_embeddings),\n","        \"Spearman Rank Correlation\": rank_similarity(real_embeddings, gen_embeddings),\n","        \"Wasserstein Distance\": calculate_wasserstein_distance(real_embeddings, gen_embeddings),\n","        \"Coverage Score\": calculate_coverage_score(real_embeddings, gen_embeddings),\n","        \"Memorization Score\": calculate_memorization_score(real_embeddings, gen_embeddings),\n","        \"Unique Embedding Ratio\": unique_embedding_ratio(gen_embeddings)\n","    }\n","\n","    # Convert to native Python floats for JSON compatibility\n","    metrics = convert_to_float(metrics)\n","\n","    # Compute aggregate quality score\n","    metrics[\"Aggregate Quality Score\"] = aggregate_quality_score(\n","        metrics[\"FID (Original vs Generated)\"],\n","        metrics[\"KL Divergence\"],\n","        metrics[\"Cosine Similarity\"],\n","        metrics[\"Spearman Rank Correlation\"]\n","    )\n","\n","    # Print results\n","    print(json.dumps(metrics, indent=4))\n","\n","    # Save results\n","    with open(\"evaluation_results.json\", \"w\") as f:\n","        json.dump(metrics, f, indent=4)\n","\n","# Initialize GAN components\n","gan_components = initialize_gan_components(config, gan_configurations[config[\"gan_type\"]])\n","\n","# Run training\n","run_gan_training(config)\n","\n","# Evaluate using the original embeddings and evaluation set\n","evaluate_gan(gan_components, config)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1x9jVAZxs0Yl","executionInfo":{"status":"ok","timestamp":1738169792762,"user_tz":-210,"elapsed":17430,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"2963fed2-8a16-437a-83c2-2cb1fd272149"},"execution_count":152,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-152-09c831e9396f>:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(embedding_file)\n"]},{"output_type":"stream","name":"stdout","text":["Initialized components: {'generator': WGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), 'critic': WGANCritic(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")}\n","Initialized components: {'generator': WGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), 'critic': WGANCritic(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")}\n","🚀 Training WGAN-GP...\n","Epoch [1/1], Loss Critic: -91.7825, Loss Generator: -23.4880\n","✅ WGAN-GP training completed!\n","{\n","    \"FID (Original vs Generated)\": 3168.3837326412527,\n","    \"FID (Original vs Eval)\": 4.648423069190201,\n","    \"KL Divergence\": 0.852465560331745,\n","    \"Cosine Similarity\": -0.029200231656432152,\n","    \"Spearman Rank Correlation\": -0.001026911586911587,\n","    \"Wasserstein Distance\": 5.337305017162924,\n","    \"Coverage Score\": 0.0,\n","    \"Memorization Score\": 0.0,\n","    \"Unique Embedding Ratio\": 1.0,\n","    \"Aggregate Quality Score\": 0.20214769038974234\n","}\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split, TensorDataset\n","from torchvision.models import inception_v3\n","from scipy.linalg import sqrtm\n","import matplotlib.pyplot as plt\n","from scipy.stats import entropy, spearmanr, wasserstein_distance\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.neighbors import NearestNeighbors\n","import json\n","import datetime\n","\n","# ==========================\n","# CONFIGURATION & EMBEDDING LOADING\n","# ==========================\n","embedding_dir = \"./saved_embeddings/embeddings/\"\n","embedding_file = os.path.join(embedding_dir, \"autoencoder_EnhancedAutoencoder_barlow_twins/EnhancedAutoencoder_barlow_twins_embeddings.pt\")\n","\n","# Report directory\n","report_dir = \"./reports/\"\n","os.makedirs(report_dir, exist_ok=True)\n","\n","# Configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","config = {\n","    \"gan_type\": \"Semi-Supervised-GAN\",\n","    \"latent_dim\": 100,\n","    \"embedding_dim\": None,  # Will be set after loading embeddings\n","    \"num_classes\": 10,\n","    \"categorical_dim\": 10,\n","    \"epochs\": 1,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-4,\n","    \"device\": device,\n","    \"lambda_gp\": 10,\n","    \"beta1\": 0.5,\n","    \"beta2\": 0.999,\n","    \"save_path\": \"gan_model.pth\",\n","    \"eval_fraction\": 0.1,  # Fraction of embeddings used for evaluation\n","    \"show_model_architecture\": True\n","}\n","\n","# ==========================\n","# EMBEDDING LOADING\n","# ==========================\n","def load_embeddings(embedding_file, device, batch_size=64, return_labels=True):\n","    \"\"\"Loads embeddings and their associated labels from a file and creates a DataLoader.\"\"\"\n","    print(f\"Loading embeddings from: {embedding_file}\")\n","    data = torch.load(embedding_file)\n","    embeddings = data[\"embeddings\"].to(device)\n","\n","    if return_labels:\n","        labels = data[\"labels\"].to(device)\n","        dataset = TensorDataset(embeddings, labels)\n","        return embeddings, labels, DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    else:\n","        dataset = TensorDataset(embeddings)\n","        return embeddings, DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Load embeddings and select appropriate DataLoader\n","embeddings, labels, data_loader = load_embeddings(embedding_file, device)\n","embeddings, labels, data_loader_v2 = load_embeddings(embedding_file, device)  # Alternative loader for Semi-Supervised-GAN\n","\n","config[\"embedding_dim\"] = embeddings.size(1)\n","\n","# Use data_loader_v2 for Semi-Supervised-GAN\n","if config[\"gan_type\"] == \"Semi-Supervised-GAN\":\n","    config[\"data_loader\"] = data_loader_v2\n","else:\n","    config[\"data_loader\"] = data_loader\n","\n","# ==========================\n","# REPORT SAVING\n","# ==========================\n","def save_report(metrics, gan_type):\n","    \"\"\"Saves evaluation metrics as a JSON file with a unique name.\"\"\"\n","    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    report_filename = f\"evaluation_{gan_type}_{timestamp}.json\"\n","    report_path = os.path.join(report_dir, report_filename)\n","\n","    with open(report_path, \"w\") as f:\n","        json.dump(metrics, f, indent=4)\n","\n","    print(f\"✅ Report saved: {report_path}\")\n","\n","# ==========================\n","# GAN INITIALIZATION & TRAINING\n","# ==========================\n","def initialize_gan_components(config, gan_configurations):\n","    \"\"\"Initialize GAN components based on type.\"\"\"\n","    components = {}\n","    gan_type = config[\"gan_type\"]\n","    multi_gan_types = [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]\n","\n","    if gan_type in multi_gan_types:\n","        gen_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type != \"Cycle-GAN\":\n","            gen_args[\"latent_dim\"] = config[\"latent_dim\"]\n","\n","        components.update({\n","            \"generator_a\": gan_configurations[\"generator_a\"](**gen_args).to(config[\"device\"]),\n","            \"generator_b\": gan_configurations[\"generator_b\"](**gen_args).to(config[\"device\"]),\n","            \"discriminator_a\": gan_configurations[\"discriminator_a\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"]),\n","            \"discriminator_b\": gan_configurations[\"discriminator_b\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","        })\n","    else:\n","        gen_args = {\"latent_dim\": config[\"latent_dim\"], \"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            gen_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            gen_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"generator\"] = gan_configurations[\"generator\"](**gen_args).to(config[\"device\"])\n","\n","    if gan_type == \"WGAN-GP\":\n","        components[\"critic\"] = gan_configurations[\"critic\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type == \"VAE-GAN\":\n","        components[\"encoder\"] = gan_configurations[\"encoder\"](embedding_dim=config[\"embedding_dim\"], latent_dim=config[\"latent_dim\"]).to(config[\"device\"])\n","        components[\"discriminator\"] = gan_configurations[\"discriminator\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type not in multi_gan_types:\n","        disc_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"]:\n","            disc_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            disc_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"discriminator\"] = gan_configurations[\"discriminator\"](**disc_args).to(config[\"device\"])\n","\n","    if config[\"show_model_architecture\"]:\n","        print(f\"Initialized components: {components}\")\n","\n","    return components\n","\n","def run_gan_training(config):\n","    \"\"\"Runs GAN training based on selected model.\"\"\"\n","    gan_type = config[\"gan_type\"]\n","    if gan_type not in gan_configurations:\n","        raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n","\n","    gan_config = gan_configurations[gan_type]\n","    components = initialize_gan_components(config, gan_config)\n","    train_function = gan_config[\"train_function\"]\n","\n","    print(f\"🚀 Training {gan_type}...\")\n","\n","    if gan_type == \"VAE-GAN\":\n","        train_function(components[\"encoder\"], components[\"generator\"], components[\"discriminator\"], **config)\n","    elif gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        train_function(components[\"generator_a\"], components[\"generator_b\"], components[\"discriminator_a\"], components[\"discriminator_b\"], **config)\n","    else:\n","        discriminator = components.get(\"discriminator\", components.get(\"critic\", None))\n","        train_function(components[\"generator\"], discriminator, **config)\n","\n","    print(f\"✅ {gan_type} training completed!\")\n","\n","# Run Training\n","run_gan_training(config)\n","\n","evaluate_gan(gan_components, config)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wmzsUXlXIx7N","executionInfo":{"status":"error","timestamp":1738172283165,"user_tz":-210,"elapsed":27955,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"d0129d0e-0ec5-4d7f-acc9-17191f47f986"},"execution_count":157,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading embeddings from: ./saved_embeddings/embeddings/autoencoder_EnhancedAutoencoder_barlow_twins/EnhancedAutoencoder_barlow_twins_embeddings.pt\n","Loading embeddings from: ./saved_embeddings/embeddings/autoencoder_EnhancedAutoencoder_barlow_twins/EnhancedAutoencoder_barlow_twins_embeddings.pt\n","Initialized components: {'generator': SimpleGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=1024, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=1024, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=256, out_features=50, bias=True)\n","    (4): Tanh()\n","  )\n","), 'discriminator': SemiSupervisedGANDiscriminator(\n","  (shared_model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","  )\n","  (adv_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=1, bias=True)\n","    (2): Sigmoid()\n","  )\n","  (class_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")}\n","🚀 Training Semi-Supervised-GAN...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-157-bad6da850c5c>:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(embedding_file)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/1], D Loss: 0.0937, G Loss: 8.5292\n","✅ Semi-Supervised-GAN training completed!\n"]},{"output_type":"error","ename":"KeyError","evalue":"'original_embeddings'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-157-bad6da850c5c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0mrun_gan_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mevaluate_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-152-09c831e9396f>\u001b[0m in \u001b[0;36mevaluate_gan\u001b[0;34m(gan_components, config)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mgenerated_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataloader_from_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mreal_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0meval_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_loader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mgen_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated_dataloader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'original_embeddings'"]}]},{"cell_type":"code","source":["import torch\n","\n","# ========================\n","# MAIN CONFIGURATION\n","# ========================\n","config = {\n","    \"gan_type\": \"Semi-Supervised-GAN\",  # Change this to switch models\n","    \"latent_dim\": 100,  # Latent space dimension\n","    \"embedding_dim\": embeddings.size(1),  # Embedding dimension\n","    \"num_classes\": 10,  # For conditional models\n","    \"categorical_dim\": 10,  # For InfoGAN\n","    \"epochs\": 1,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-4,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"lambda_gp\": 10,  # For WGAN-GP\n","    \"beta1\": 0.5,  # Adam optimizer beta1\n","    \"beta2\": 0.999,  # Adam optimizer beta2\n","    \"save_path\": \"gan_model.pth\",  # Path to save the model\n","    \"data_loader\": data_loader_v2,  # Main data loader\n","    \"data_loader_a\": data_loader,  # For cross-domain models\n","    \"data_loader_b\": data_loader,  # For cross-domain models\n","    \"show_model_architecture\": True  # Toggle to print model architectures\n","}\n","\n","# ========================\n","# MODEL INITIALIZATION\n","# ========================\n","\n","def initialize_gan_components(config, gan_config):\n","    \"\"\"Initialize all components for the specified GAN type\"\"\"\n","    components = {}\n","    gan_type = config[\"gan_type\"]\n","    multi_gan_types = [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]\n","\n","    if gan_type in multi_gan_types:\n","        gen_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type != \"Cycle-GAN\":\n","            gen_args[\"latent_dim\"] = config[\"latent_dim\"]\n","\n","        components.update({\n","            \"generator_a\": gan_config[\"generator_a\"](**gen_args).to(config[\"device\"]),\n","            \"generator_b\": gan_config[\"generator_b\"](**gen_args).to(config[\"device\"]),\n","            \"discriminator_a\": gan_config[\"discriminator_a\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"]),\n","            \"discriminator_b\": gan_config[\"discriminator_b\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","        })\n","    else:\n","        gen_args = {\n","            \"latent_dim\": config[\"latent_dim\"],\n","            \"embedding_dim\": config[\"embedding_dim\"]\n","        }\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            gen_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            gen_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"generator\"] = gan_config[\"generator\"](**gen_args).to(config[\"device\"])\n","\n","    if gan_type == \"WGAN-GP\":\n","        components[\"critic\"] = gan_config[\"critic\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type == \"VAE-GAN\":\n","        components[\"encoder\"] = gan_config[\"encoder\"](embedding_dim=config[\"embedding_dim\"], latent_dim=config[\"latent_dim\"]).to(config[\"device\"])\n","        components[\"discriminator\"] = gan_config[\"discriminator\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type not in multi_gan_types:\n","        disc_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"]:\n","            disc_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            disc_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"discriminator\"] = gan_config[\"discriminator\"](**disc_args).to(config[\"device\"])\n","\n","    if config[\"show_model_architecture\"]:\n","        print(f\"Initialized components: {components}\")\n","\n","    return components\n","\n","# ========================\n","# MAIN EXECUTION\n","# ========================\n","\n","def run_gan_training(config):\n","    \"\"\"Main function to initialize and train the GAN\"\"\"\n","    gan_type = config[\"gan_type\"]\n","    if gan_type not in gan_configurations:\n","        raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n","\n","    gan_config = gan_configurations[gan_type]\n","    components = initialize_gan_components(config, gan_config)\n","    train_function = gan_config[\"train_function\"]\n","\n","    print(f\"🚀 Training {gan_type}...\")\n","\n","    if gan_type == \"VAE-GAN\":\n","        train_function(components[\"encoder\"], components[\"generator\"], components[\"discriminator\"], **config)\n","    elif gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        train_function(components[\"generator_a\"], components[\"generator_b\"], components[\"discriminator_a\"], components[\"discriminator_b\"], **config)\n","    else:\n","        discriminator = components.get(\"discriminator\", components.get(\"critic\", None))\n","        train_function(components[\"generator\"], discriminator, **config)\n","\n","    print(f\"✅ {gan_type} training completed!\")\n","\n","# ========================\n","# EXECUTION\n","# ========================\n","run_gan_training(config)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVxxi3hMtJwP","executionInfo":{"status":"ok","timestamp":1738171305231,"user_tz":-210,"elapsed":27072,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"7251b83e-a199-48f7-edc7-16551ea3f7f2"},"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized components: {'generator': SimpleGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=1024, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=1024, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=256, out_features=50, bias=True)\n","    (4): Tanh()\n","  )\n","), 'discriminator': SemiSupervisedGANDiscriminator(\n","  (shared_model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","  )\n","  (adv_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=1, bias=True)\n","    (2): Sigmoid()\n","  )\n","  (class_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")}\n","🚀 Training Semi-Supervised-GAN...\n","Epoch [1/1], D Loss: 0.0584, G Loss: 8.6814\n","✅ Semi-Supervised-GAN training completed!\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# ========================\n","# MAIN CONFIGURATION\n","# ========================\n","config = {\n","    \"gan_types\": ['WGAN-GP', 'VAE-GAN', 'Contrastive-GAN', 'Cross-Domain-GAN', 'Cycle-GAN', 'Dual-GAN', 'Contrastive-Dual-GAN', 'Semi-Supervised-GAN', 'Conditional-GAN', 'InfoGAN'],  # List of GAN types to test\n","    \"latent_dim\": 100,  # Latent space dimension\n","    \"embedding_dim\": embeddings.size(1),  # Embedding dimension\n","    \"num_classes\": 10,  # For conditional models\n","    \"categorical_dim\": 10,  # For InfoGAN\n","    \"epochs\": 2,  # Short training for quick verification\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-4,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"lambda_gp\": 10,  # For WGAN-GP\n","    \"beta1\": 0.5,  # Adam optimizer beta1\n","    \"beta2\": 0.999,  # Adam optimizer beta2\n","    \"save_path\": \"gan_model.pth\",  # Path to save the model\n","    \"data_loader\": data_loader,  # Main data loader\n","    \"data_loader_a\": data_loader,  # For cross-domain models\n","    \"data_loader_b\": data_loader,  # For cross-domain models\n","    \"show_model_architecture\": False  # Toggle to print model architectures\n","}\n","\n","# ========================\n","# MODEL INITIALIZATION\n","# ========================\n","\n","def initialize_gan_components(config, gan_config):\n","    \"\"\"Initialize all components for the specified GAN type\"\"\"\n","    components = {}\n","    gan_type = config[\"gan_type\"]\n","    multi_gan_types = [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]\n","\n","    if gan_type in multi_gan_types:\n","        gen_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type != \"Cycle-GAN\":\n","            gen_args[\"latent_dim\"] = config[\"latent_dim\"]\n","\n","        components.update({\n","            \"generator_a\": gan_config[\"generator_a\"](**gen_args).to(config[\"device\"]),\n","            \"generator_b\": gan_config[\"generator_b\"](**gen_args).to(config[\"device\"]),\n","            \"discriminator_a\": gan_config[\"discriminator_a\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"]),\n","            \"discriminator_b\": gan_config[\"discriminator_b\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","        })\n","    else:\n","        gen_args = {\n","            \"latent_dim\": config[\"latent_dim\"],\n","            \"embedding_dim\": config[\"embedding_dim\"]\n","        }\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            gen_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            gen_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"generator\"] = gan_config[\"generator\"](**gen_args).to(config[\"device\"])\n","\n","    if gan_type == \"WGAN-GP\":\n","        components[\"critic\"] = gan_config[\"critic\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type == \"VAE-GAN\":\n","        components[\"encoder\"] = gan_config[\"encoder\"](embedding_dim=config[\"embedding_dim\"], latent_dim=config[\"latent_dim\"]).to(config[\"device\"])\n","        components[\"discriminator\"] = gan_config[\"discriminator\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type not in multi_gan_types:\n","        disc_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"]:\n","            disc_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            disc_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"discriminator\"] = gan_config[\"discriminator\"](**disc_args).to(config[\"device\"])\n","\n","    if config[\"show_model_architecture\"]:\n","        print(f\"Initialized components for {gan_type}: {components}\")\n","\n","    return components\n","\n","# ========================\n","# MAIN EXECUTION\n","# ========================\n","\n","def test_all_gans(config):\n","    \"\"\"Function to test all GAN models for a short number of epochs with improved error handling\"\"\"\n","    for gan_type in config[\"gan_types\"]:\n","        print(f\"\\n🚀 Testing {gan_type}...\")\n","        config[\"gan_type\"] = gan_type\n","\n","        try:\n","            if gan_type not in gan_configurations:\n","                raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n","\n","            gan_config = gan_configurations[gan_type]\n","            components = initialize_gan_components(config, gan_config)\n","            train_function = gan_config[\"train_function\"]\n","\n","            if gan_type == \"VAE-GAN\":\n","                train_function(components[\"encoder\"], components[\"generator\"], components[\"discriminator\"], **config)\n","            elif gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","                train_function(components[\"generator_a\"], components[\"generator_b\"], components[\"discriminator_a\"], components[\"discriminator_b\"], **config)\n","            else:\n","                discriminator = components.get(\"discriminator\", components.get(\"critic\", None))\n","                train_function(components[\"generator\"], discriminator, **config)\n","\n","            print(f\"✅ {gan_type} training successful!\")\n","        except Exception as e:\n","            print(f\"❌ Error testing {gan_type}: {str(e)}\")\n","\n","# ========================\n","# EXECUTION\n","# ========================\n","test_all_gans(config)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6BWMBlqHEZ7","executionInfo":{"status":"ok","timestamp":1738171999327,"user_tz":-210,"elapsed":188419,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"03505c06-2454-44e7-9001-e69498a568dd"},"execution_count":156,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🚀 Testing WGAN-GP...\n","Epoch [1/2], Loss Critic: -88.1208, Loss Generator: -24.3678\n","Epoch [2/2], Loss Critic: -55.1855, Loss Generator: -37.9971\n","✅ WGAN-GP training successful!\n","\n","🚀 Testing VAE-GAN...\n","Epoch [1/2], D Loss: 0.0235, G Loss: 2166.8838\n","Epoch [2/2], D Loss: 0.0059, G Loss: 1393.7501\n","✅ VAE-GAN training successful!\n","\n","🚀 Testing Contrastive-GAN...\n","Epoch [1/2], D Loss: 0.0000, G Loss: -216.4480\n","Epoch [2/2], D Loss: 0.0001, G Loss: -1216.6046\n","✅ Contrastive-GAN training successful!\n","\n","🚀 Testing Cross-Domain-GAN...\n","Epoch [1/2], D Loss: 0.0126, G Loss: 5.7212\n","Epoch [2/2], D Loss: 0.0806, G Loss: 4.9677\n","✅ Cross-Domain-GAN training successful!\n","\n","🚀 Testing Cycle-GAN...\n","Epoch [1/2], D Loss A: 1.2441, D Loss B: 1.0757, G Loss: 9.2320\n","Epoch [2/2], D Loss A: 0.4399, D Loss B: 0.4349, G Loss: 7.3315\n","✅ Cycle-GAN training successful!\n","\n","🚀 Testing Dual-GAN...\n","❌ Error testing Dual-GAN: mat1 and mat2 shapes cannot be multiplied (64x50 and 100x512)\n","\n","🚀 Testing Contrastive-Dual-GAN...\n","❌ Error testing Contrastive-Dual-GAN: mat1 and mat2 shapes cannot be multiplied (64x50 and 100x512)\n","\n","🚀 Testing Semi-Supervised-GAN...\n","❌ Error testing Semi-Supervised-GAN: too many values to unpack (expected 2)\n","\n","🚀 Testing Conditional-GAN...\n","❌ Error testing Conditional-GAN: super(type, obj): obj must be an instance or subtype of type\n","\n","🚀 Testing InfoGAN...\n","❌ Error testing InfoGAN: InfoGANGenerator.__init__() got an unexpected keyword argument 'num_classes'\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","def load_embeddings_v2(embedding_file, device, batch_size=64):\n","    \"\"\"\n","    Loads embeddings and their associated labels from a specified file and\n","    creates a DataLoader for batching the embeddings.\n","\n","    Args:\n","        embedding_file (str): Path to the file containing embeddings and labels.\n","        device (torch.device): The device (CPU/GPU) to load the tensors onto.\n","        batch_size (int, optional): The batch size for DataLoader. Default is 64.\n","\n","    Returns:\n","        tuple: A tuple containing:\n","            - embeddings (torch.Tensor): Loaded embeddings.\n","            - labels (torch.Tensor): Corresponding labels for the embeddings.\n","            - data_loader (DataLoader): DataLoader for batching embeddings.\n","    \"\"\"\n","    logger.info(f\"Loading embeddings from: {embedding_file}\")\n","    data = torch.load(embedding_file)\n","    embeddings = data[\"embeddings\"].to(device)\n","    labels = data[\"labels\"].to(device)\n","\n","    # Create a TensorDataset and DataLoader\n","    dataset = TensorDataset(embeddings, labels)\n","    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    return embeddings, labels, data_loader\n","\n","# Now it will work correctly!\n","embeddings, labels, data_loader = load_embeddings_v2(embedding_file, device)\n","\n","\n","# interesting way to load the embeddings...\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","def load_embeddings(embedding_file, device, batch_size=64, return_labels=True):\n","    \"\"\"\n","    Loads embeddings and their associated labels from a specified file and\n","    creates a DataLoader for batching the embeddings (and optionally labels).\n","\n","    Args:\n","        embedding_file (str): Path to the file containing embeddings and labels.\n","        device (torch.device): The device (CPU/GPU) to load the tensors onto.\n","        batch_size (int, optional): The batch size for DataLoader. Default is 64.\n","        return_labels (bool, optional): Whether to include labels in the DataLoader. Default is True.\n","\n","    Returns:\n","        tuple: A tuple containing:\n","            - embeddings (torch.Tensor): Loaded embeddings.\n","            - labels (torch.Tensor, optional): Corresponding labels for the embeddings (if return_labels=True).\n","            - data_loader (DataLoader): DataLoader for batching embeddings (and labels if required).\n","    \"\"\"\n","    print(f\"Loading embeddings from: {embedding_file}\")\n","    data = torch.load(embedding_file)\n","    embeddings = data[\"embeddings\"].to(device)\n","\n","    # Initialize the DataLoader only with embeddings if labels are not required\n","    if return_labels:\n","        labels = data[\"labels\"].to(device)\n","        # Create a TensorDataset containing both embeddings and labels\n","        dataset = TensorDataset(embeddings, labels)\n","        return embeddings, labels, DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    else:\n","        # Create DataLoader for embeddings only\n","        dataset = TensorDataset(embeddings)  # Just embeddings\n","        return embeddings, DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","embeddings, labels, data_loader_v2 = load_embeddings(embedding_file, device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPZn0htEf73X","executionInfo":{"status":"ok","timestamp":1738145087430,"user_tz":-210,"elapsed":318,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"9f9993a1-fe49-451d-c49f-014a35e424e3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO - Loading embeddings from: ./saved_embeddings/embeddings/autoencoders_BasicAutoencoder/BasicAutoencoder_embeddings.pt\n","<ipython-input-24-23dfe1fe608b>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(embedding_file)\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Cross-Domain-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 2\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zuJbolWqrD8g","executionInfo":{"status":"ok","timestamp":1738169549956,"user_tz":-210,"elapsed":25521,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"e8a2f33d-e43c-4ac0-daed-a12a0c021bfa"},"execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Cross-Domain-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.CrossDomainGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.CrossDomainDiscriminator'>, 'train_function': <function train_cross_domain_gan at 0x7d7ef691db20>}\n","Generator initialized on CrossDomainGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n",")\n","Discriminator initialized on CrossDomainDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=1, bias=True)\n","    (3): Sigmoid()\n","  )\n",")\n","Epoch [1/2], D Loss: 0.0212, G Loss: 4.7309\n","Epoch [2/2], D Loss: 0.0298, G Loss: 4.6684\n","Cross-Domain-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Semi-Supervised-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 1\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader_v2\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcjjCT8Hj-55","executionInfo":{"status":"ok","timestamp":1738169316040,"user_tz":-210,"elapsed":27066,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"377b2ce8-6605-4d74-b1d2-599283f01008"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Semi-Supervised-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.SimpleGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.SemiSupervisedGANDiscriminator'>, 'train_function': <function train_semi_supervised_gan at 0x7d7ef691dda0>}\n","Generator initialized on SimpleGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=1024, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=1024, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=256, out_features=50, bias=True)\n","    (4): Tanh()\n","  )\n",")\n","Semi-Supervised-GAN discriminator initialized on SemiSupervisedGANDiscriminator(\n","  (shared_model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","  )\n","  (adv_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=1, bias=True)\n","    (2): Sigmoid()\n","  )\n","  (class_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")\n","Epoch [1/1], D Loss: 0.1193, G Loss: 8.1044\n","Semi-Supervised-GAN training test passed!\n"]}]},{"cell_type":"code","source":["# GAN Configuration\n","gan_type = \"Semi-Supervised-GAN\"  # Change to the desired GAN type\n","latent_dim = 100  # Latent dimension for the generator\n","embedding_dim = embeddings.size(1)  # Embedding dimension based on loaded embeddings\n","num_classes = 10  # For Conditional GAN and InfoGAN (e.g., 10 classes for MNIST)\n","categorical_dim = 10\n","epochs = 1\n","learning_rate = 0.0001\n","# Ensure device is properly set up\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the data loaders before the GAN models\n","embedding_loader_a = data_loader\n","embedding_loader_b = data_loader\n","embedding_loader = data_loader_v2\n","\n","# Initialize the correct GAN models based on `gan_type`\n","if gan_type in gan_configurations:\n","    config = gan_configurations[gan_type]\n","    print(f\"Initializing {gan_type} configuration: {config}\")\n","\n","    # Generator initialization for Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        if gan_type == \"Cycle-GAN\":\n","            # Cycle-GAN requires two generators and two discriminators\n","            generator_a = config[\"generator_a\"](embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"CycleGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","        else:\n","            # Dual-GAN or Contrastive-Dual-GAN requires both latent_dim and embedding_dim for generators\n","            generator_a = config[\"generator_a\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            generator_b = config[\"generator_b\"](latent_dim=latent_dim, embedding_dim=embedding_dim).to(device)\n","            discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","            discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","            print(f\"DualGAN/ContrastiveDualGAN generators and discriminators initialized on {generator_a}, {generator_b}, {discriminator_a}, {discriminator_b}\")\n","    else:\n","        # For other GANs (WGAN-GP, VAE-GAN, etc.), initialize a single generator\n","        generator_args = {\"latent_dim\": latent_dim, \"embedding_dim\": embedding_dim}\n","        if gan_type == \"InfoGAN\":\n","            # Correctly initialize InfoGAN generator with latent_dim and categorical_dim\n","            generator_args[\"categorical_dim\"] = categorical_dim\n","        if gan_type == \"Conditional-GAN\":\n","            # Conditional-GAN generator requires num_classes\n","            generator_args[\"num_classes\"] = num_classes\n","        generator = config[\"generator\"](**generator_args).to(device)\n","        print(f\"Generator initialized on {generator}\")\n","\n","    # Handle critic/discriminator initialization conditionally\n","    if gan_type == \"WGAN-GP\":\n","        # WGAN-GP uses a critic instead of a discriminator\n","        critic = config[\"critic\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Critic initialized on {critic}\")\n","    elif gan_type == \"Semi-Supervised-GAN\":\n","        # Semi-Supervised-GAN requires num_classes for the discriminator\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Semi-Supervised-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"InfoGAN\":\n","        # InfoGAN discriminator requires embedding_dim and categorical_dim\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, categorical_dim=categorical_dim).to(device)\n","        print(f\"InfoGAN discriminator initialized on {discriminator}\")\n","    elif gan_type == \"Conditional-GAN\":\n","        # Conditional-GAN discriminator requires embedding_dim and num_classes\n","        discriminator = config[\"discriminator\"](embedding_dim=embedding_dim, num_classes=num_classes).to(device)\n","        print(f\"Conditional-GAN discriminator initialized on {discriminator}\")\n","    elif gan_type not in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # For other models (VAE-GAN, Conditional-GAN, etc.), initialize a single discriminator\n","        discriminator_args = {\"embedding_dim\": embedding_dim}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            discriminator_args[\"num_classes\"] = num_classes\n","        if gan_type == \"InfoGAN\":\n","            discriminator_args[\"categorical_dim\"] = categorical_dim\n","        discriminator = config[\"discriminator\"](**discriminator_args).to(device)\n","        print(f\"Discriminator initialized on {discriminator}\")\n","    else:\n","        # If discriminator is part of the configuration (Cycle-GAN, Dual-GAN, etc.), use the ones in the config\n","        discriminator_a = config[\"discriminator_a\"](embedding_dim=embedding_dim).to(device)\n","        discriminator_b = config[\"discriminator_b\"](embedding_dim=embedding_dim).to(device)\n","        print(f\"Discriminators initialized on {discriminator_a}, {discriminator_b}\")\n","\n","    # Initialize encoder for VAE-GAN\n","    if gan_type == \"VAE-GAN\":\n","        encoder = config[\"encoder\"](embedding_dim=embedding_dim, latent_dim=latent_dim).to(device)\n","        print(f\"Encoder initialized on {encoder}\")\n","\n","    # Select the appropriate training function\n","    train_function = config[\"train_function\"]\n","\n","    # Handle any additional configurations (like learning rate, lambda_gp)\n","    train_kwargs = config.get(\"train_kwargs\", {})  # Default to empty dict if not specified\n","    train_kwargs.update({\n","        \"latent_dim\": latent_dim,\n","        \"epochs\": epochs,  # Pass epochs as part of train_kwargs\n","        \"device\": device,\n","        \"learning_rate\": learning_rate,\n","        \"num_classes\": num_classes if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"] else None,  # Add for Conditional, InfoGAN, and Semi-Supervised-GAN\n","        \"categorical_dim\": categorical_dim if gan_type == \"InfoGAN\" else None,  # Add only for InfoGAN\n","        \"lambda_gp\": 10 if gan_type == \"WGAN-GP\" else None,  # Add only for WGAN-GP\n","    })\n","\n","    # Add data loaders conditionally\n","    if gan_type in [\"Dual-GAN\", \"Cycle-GAN\", \"Contrastive-Dual-GAN\"]:\n","        # Dual-GAN, Cycle-GAN, and Contrastive-Dual-GAN: pass two data loaders\n","        train_kwargs.update({\n","            \"data_loader_a\": embedding_loader_a,  # Two loaders for these models\n","            \"data_loader_b\": embedding_loader_b\n","        })\n","    else:\n","        # For all other models (WGAN-GP, VAE-GAN, etc.), use a single loader\n","        train_kwargs.update({\n","            \"data_loader\": embedding_loader  # Single data loader for other models\n","        })\n","\n","    # Training loop (now handled inside the train_function)\n","    if gan_type == \"VAE-GAN\":\n","        # VAE-GAN requires encoder, generator, and discriminator\n","        train_function(encoder, generator, discriminator, **train_kwargs)\n","    else:\n","        # For other models, pass the appropriate generator/discriminator/critic\n","        train_function(generator_a, generator_b, discriminator_a, discriminator_b, **train_kwargs) if gan_type in [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"] else train_function(generator, discriminator if \"discriminator\" in locals() else critic, **train_kwargs)\n","\n","    print(f\"{gan_type} training test passed!\")\n","\n","else:\n","    raise ValueError(f\"Unsupported GAN type: {gan_type}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMFweDi0uQo5","executionInfo":{"status":"ok","timestamp":1738169050587,"user_tz":-210,"elapsed":28153,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"46d354a4-da6b-48c3-9733-5076f80069c8"},"execution_count":144,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Semi-Supervised-GAN configuration: {'generator': <class 'src.gan_workflows.plan2.plan2_gan_models.SimpleGANGenerator'>, 'discriminator': <class 'src.gan_workflows.plan2.plan2_gan_models.SemiSupervisedGANDiscriminator'>, 'train_function': <function train_semi_supervised_gan at 0x7d7ef691dda0>}\n","Generator initialized on SimpleGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=1024, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=1024, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=256, out_features=50, bias=True)\n","    (4): Tanh()\n","  )\n",")\n","Semi-Supervised-GAN discriminator initialized on SemiSupervisedGANDiscriminator(\n","  (shared_model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","  )\n","  (adv_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=1, bias=True)\n","    (2): Sigmoid()\n","  )\n","  (class_head): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")\n","Epoch [1/1], D Loss: 0.1360, G Loss: 6.9575\n","Semi-Supervised-GAN training test passed!\n"]}]},{"cell_type":"markdown","source":["# Evaluating the GANs"],"metadata":{"id":"AmSIw3Gr5XQB"}},{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","from torchvision.models import inception_v3\n","from scipy.linalg import sqrtm\n","import matplotlib.pyplot as plt\n","from scipy.stats import entropy, spearmanr\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.neighbors import NearestNeighbors\n","from scipy.stats import wasserstein_distance\n","import json\n","\n","# ==========================\n","# CONFIGURATION & EMBEDDING LOADING\n","# ==========================\n","embedding_dir = \"./saved_embeddings/embeddings/\"\n","embedding_file = os.path.join(embedding_dir, \"autoencoder_EnhancedAutoencoder_barlow_twins/EnhancedAutoencoder_barlow_twins_embeddings.pt\")\n","\n","# Configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","config = {\n","    \"gan_type\": \"Contrastive-GAN\",\n","    \"latent_dim\": 100,\n","    \"embedding_dim\": None,  # Will be set after loading embeddings\n","    \"num_classes\": 10,\n","    \"categorical_dim\": 10,\n","    \"epochs\": 1,\n","    \"batch_size\": 64,\n","    \"learning_rate\": 1e-4,\n","    \"device\": device,\n","    \"lambda_gp\": 10,\n","    \"beta1\": 0.5,\n","    \"beta2\": 0.999,\n","    \"save_path\": \"gan_model.pth\",\n","    \"eval_fraction\": 0.1,  # Fraction of embeddings used for evaluation\n","    \"show_model_architecture\": True\n","}\n","\n","def load_embeddings(embedding_file, device, batch_size=64):\n","    \"\"\"Loads embeddings and labels from a specified file.\"\"\"\n","    data = torch.load(embedding_file)\n","    embeddings = data[\"embeddings\"].to(device)\n","    labels = data[\"labels\"].to(device)\n","    data_loader = DataLoader(embeddings, batch_size=batch_size, shuffle=True)\n","    return embeddings, labels, data_loader\n","\n","def split_embeddings(embeddings, labels, eval_fraction=0.1, batch_size=64):\n","    \"\"\"Splits embeddings into training and evaluation sets.\"\"\"\n","    num_samples = embeddings.size(0)\n","    num_eval = int(num_samples * eval_fraction)\n","    num_train = num_samples - num_eval\n","\n","    train_embeddings, eval_embeddings = random_split(embeddings, [num_train, num_eval])\n","    train_labels, eval_labels = random_split(labels, [num_train, num_eval])\n","\n","    train_loader = DataLoader(train_embeddings, batch_size=batch_size, shuffle=True)\n","    eval_loader = DataLoader(eval_embeddings, batch_size=batch_size, shuffle=False)\n","    return train_loader, eval_loader, train_embeddings, eval_embeddings\n","\n","# Load embeddings and split\n","embeddings, labels, full_data_loader = load_embeddings(embedding_file, device)\n","config[\"embedding_dim\"] = embeddings.size(1)\n","train_loader, eval_loader, train_embeddings, eval_embeddings = split_embeddings(embeddings, labels, config[\"eval_fraction\"], config[\"batch_size\"])\n","\n","# Update config with data loaders\n","config.update({\n","    \"data_loader\": train_loader,\n","    \"data_loader_a\": train_loader,\n","    \"data_loader_b\": train_loader,\n","    \"eval_loader\": eval_loader,\n","    \"original_embeddings\": embeddings  # Store original embeddings for evaluation\n","})\n","\n","# ==========================\n","# MODEL INITIALIZATION\n","# ==========================\n","\n","def initialize_gan_components(config, gan_configurations):\n","    \"\"\"Initialize GAN components based on type.\"\"\"\n","    components = {}\n","    gan_type = config[\"gan_type\"]\n","    multi_gan_types = [\"Cycle-GAN\", \"Dual-GAN\", \"Contrastive-Dual-GAN\"]\n","\n","    if gan_type in multi_gan_types:\n","        gen_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type != \"Cycle-GAN\":\n","            gen_args[\"latent_dim\"] = config[\"latent_dim\"]\n","\n","        components.update({\n","            \"generator_a\": gan_configurations[\"generator_a\"](**gen_args).to(config[\"device\"]),\n","            \"generator_b\": gan_configurations[\"generator_b\"](**gen_args).to(config[\"device\"]),\n","            \"discriminator_a\": gan_configurations[\"discriminator_a\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"]),\n","            \"discriminator_b\": gan_configurations[\"discriminator_b\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","        })\n","    else:\n","        gen_args = {\"latent_dim\": config[\"latent_dim\"], \"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\"]:\n","            gen_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            gen_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"generator\"] = gan_configurations[\"generator\"](**gen_args).to(config[\"device\"])\n","\n","    if gan_type == \"WGAN-GP\":\n","        components[\"critic\"] = gan_configurations[\"critic\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type == \"VAE-GAN\":\n","        components[\"encoder\"] = gan_configurations[\"encoder\"](embedding_dim=config[\"embedding_dim\"], latent_dim=config[\"latent_dim\"]).to(config[\"device\"])\n","        components[\"discriminator\"] = gan_configurations[\"discriminator\"](embedding_dim=config[\"embedding_dim\"]).to(config[\"device\"])\n","    elif gan_type not in multi_gan_types:\n","        disc_args = {\"embedding_dim\": config[\"embedding_dim\"]}\n","        if gan_type in [\"Conditional-GAN\", \"InfoGAN\", \"Semi-Supervised-GAN\"]:\n","            disc_args[\"num_classes\"] = config[\"num_classes\"]\n","        if gan_type == \"InfoGAN\":\n","            disc_args[\"categorical_dim\"] = config[\"categorical_dim\"]\n","\n","        components[\"discriminator\"] = gan_configurations[\"discriminator\"](**disc_args).to(config[\"device\"])\n","\n","    if config[\"show_model_architecture\"]:\n","        print(f\"Initialized components: {components}\")\n","\n","    return components\n","\n","# ==========================\n","# EVALUATION METRICS\n","# ==========================\n","\n","def calculate_fid(real_embeddings, generated_embeddings):\n","    \"\"\"Compute Fréchet Inception Distance (FID).\"\"\"\n","    mu1, sigma1 = np.mean(real_embeddings, axis=0), np.cov(real_embeddings, rowvar=False)\n","    mu2, sigma2 = np.mean(generated_embeddings, axis=0), np.cov(generated_embeddings, rowvar=False)\n","    diff = mu1 - mu2\n","    covmean = sqrtm(sigma1 @ sigma2)\n","    if np.iscomplexobj(covmean):\n","        covmean = covmean.real\n","    return np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2 * covmean)\n","\n","def calculate_kl_divergence(real_embeddings, generated_embeddings):\n","    \"\"\"Compute KL divergence between real and generated embeddings.\"\"\"\n","    real_prob = np.histogram(real_embeddings, bins=50, density=True)[0]\n","    gen_prob = np.histogram(generated_embeddings, bins=50, density=True)[0]\n","    real_prob += 1e-10  # Prevent division by zero\n","    gen_prob += 1e-10\n","    return entropy(real_prob, gen_prob)\n","\n","def calculate_cosine_similarity(real_embeddings, generated_embeddings):\n","    \"\"\"Compute cosine similarity between real and generated embeddings.\"\"\"\n","    return np.mean(cosine_similarity(real_embeddings, generated_embeddings))\n","\n","def rank_similarity(real_embeddings, generated_embeddings):\n","    \"\"\"Compute Spearman Rank Correlation between real and generated embeddings, ensuring matched dimensions.\"\"\"\n","    min_size = min(real_embeddings.shape[0], generated_embeddings.shape[0])\n","\n","    # Randomly sample real embeddings if larger\n","    if real_embeddings.shape[0] > min_size:\n","        real_embeddings = real_embeddings[np.random.choice(real_embeddings.shape[0], min_size, replace=False)]\n","\n","    # Randomly sample generated embeddings if larger\n","    if generated_embeddings.shape[0] > min_size:\n","        generated_embeddings = generated_embeddings[np.random.choice(generated_embeddings.shape[0], min_size, replace=False)]\n","\n","    # Ensure the shapes are aligned for ranking\n","    real_rank = np.argsort(real_embeddings, axis=0)\n","    gen_rank = np.argsort(generated_embeddings, axis=0)\n","\n","    return spearmanr(real_rank.flatten(), gen_rank.flatten()).correlation\n","\n","def unique_embedding_ratio(generated_embeddings):\n","    \"\"\"Compute the ratio of unique embeddings in the generated set.\"\"\"\n","    unique_embeddings = np.unique(generated_embeddings, axis=0)\n","    return len(unique_embeddings) / len(generated_embeddings)\n","\n","def aggregate_quality_score(fid, kl, cosine, rank_corr):\n","    \"\"\"Compute a weighted quality score based on multiple metrics.\"\"\"\n","    # Normalize metrics (assuming lower is better for FID & KL)\n","    fid_norm = 1 / (1 + fid)\n","    kl_norm = 1 / (1 + kl)\n","    cosine_norm = cosine  # Higher is better, no need to invert\n","    rank_norm = (rank_corr + 1) / 2  # Convert [-1,1] to [0,1]\n","\n","    # Compute final weighted score\n","    return (0.4 * fid_norm) + (0.2 * kl_norm) + (0.2 * cosine_norm) + (0.2 * rank_norm)\n","\n","def calculate_wasserstein_distance(real_embeddings, generated_embeddings):\n","    \"\"\"Compute Wasserstein Distance between real and generated embeddings.\"\"\"\n","    return wasserstein_distance(real_embeddings.flatten(), generated_embeddings.flatten())\n","\n","def calculate_coverage_score(real_embeddings, generated_embeddings, n_neighbors=5):\n","    \"\"\"Compute Coverage Score: Percentage of real embeddings with at least one close match in generated embeddings.\"\"\"\n","    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n","    neigh.fit(generated_embeddings)\n","    distances, _ = neigh.kneighbors(real_embeddings)\n","    return np.mean(distances[:, 0] < 0.1)  # Adjust threshold as needed\n","\n","def calculate_memorization_score(real_embeddings, generated_embeddings, n_neighbors=1, tolerance=1e-3):\n","    \"\"\"Compute Memorization Score: Percentage of generated embeddings that are close to real embeddings within a small tolerance.\"\"\"\n","    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n","    neigh.fit(real_embeddings)\n","    distances, _ = neigh.kneighbors(generated_embeddings)\n","\n","    return np.mean(distances[:, 0] < tolerance)  # Allow small tolerance for near-exact matches\n","\n","def generate_synthetic_samples(generator, num_samples=1000, latent_dim=100, device=\"cuda\"):\n","    \"\"\"Generate synthetic samples using a trained GAN generator.\"\"\"\n","    generator.eval()\n","    with torch.no_grad():\n","        latent_vectors = torch.randn(num_samples, latent_dim).to(device)\n","        generated_samples = generator(latent_vectors)\n","    return generated_samples.cpu()\n","\n","def create_dataloader_from_samples(samples, batch_size=64):\n","    return DataLoader(samples, batch_size=batch_size, shuffle=False)\n","\n","def convert_to_float(metrics):\n","    \"\"\"Ensure all values in the dictionary are JSON serializable.\"\"\"\n","    return {k: float(v) for k, v in metrics.items()}\n","\n","def evaluate_gan(gan_components, config):\n","    \"\"\"Evaluate GAN with multiple metrics, ensuring JSON serialization.\"\"\"\n","    device = config[\"device\"]\n","    generator = gan_components[\"generator\"]\n","\n","    generated_samples = generate_synthetic_samples(generator, num_samples=1000, latent_dim=config[\"latent_dim\"], device=device)\n","    generated_dataloader = create_dataloader_from_samples(generated_samples, batch_size=config[\"batch_size\"])\n","\n","    real_embeddings = config[\"original_embeddings\"].cpu().numpy()\n","    eval_embeddings = torch.cat([batch for batch in config[\"eval_loader\"]], dim=0).cpu().numpy()\n","    gen_embeddings = torch.cat([batch for batch in generated_dataloader], dim=0).cpu().numpy()\n","\n","    metrics = {\n","        \"FID (Original vs Generated)\": calculate_fid(real_embeddings, gen_embeddings),\n","        \"FID (Original vs Eval)\": calculate_fid(real_embeddings, eval_embeddings),\n","        \"KL Divergence\": calculate_kl_divergence(real_embeddings, gen_embeddings),\n","        \"Cosine Similarity\": calculate_cosine_similarity(real_embeddings, gen_embeddings),\n","        \"Spearman Rank Correlation\": rank_similarity(real_embeddings, gen_embeddings),\n","        \"Wasserstein Distance\": calculate_wasserstein_distance(real_embeddings, gen_embeddings),\n","        \"Coverage Score\": calculate_coverage_score(real_embeddings, gen_embeddings),\n","        \"Memorization Score\": calculate_memorization_score(real_embeddings, gen_embeddings),\n","        \"Unique Embedding Ratio\": unique_embedding_ratio(gen_embeddings)\n","    }\n","\n","    # Convert to native Python floats for JSON compatibility\n","    metrics = convert_to_float(metrics)\n","\n","    # Compute aggregate quality score\n","    metrics[\"Aggregate Quality Score\"] = aggregate_quality_score(\n","        metrics[\"FID (Original vs Generated)\"],\n","        metrics[\"KL Divergence\"],\n","        metrics[\"Cosine Similarity\"],\n","        metrics[\"Spearman Rank Correlation\"]\n","    )\n","\n","    # Print results\n","    print(json.dumps(metrics, indent=4))\n","\n","    # Save results\n","    with open(\"evaluation_results.json\", \"w\") as f:\n","        json.dump(metrics, f, indent=4)\n","\n","# Initialize GAN components\n","gan_components = initialize_gan_components(config, gan_configurations[config[\"gan_type\"]])\n","\n","# Run training\n","run_gan_training(config)\n","\n","# Evaluate using the original embeddings and evaluation set\n","evaluate_gan(gan_components, config)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUGzKDlAkdFk","executionInfo":{"status":"ok","timestamp":1738164842321,"user_tz":-210,"elapsed":17307,"user":{"displayName":"Farshad H","userId":"17155898055621377416"}},"outputId":"202d08b3-3eff-4747-b3c3-94d27d23c33f"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-100-d013e3d867e7>:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(embedding_file)\n"]},{"output_type":"stream","name":"stdout","text":["Initialized components: {'generator': ContrastiveGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=512, bias=True)\n","        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), 'discriminator': ContrastiveGANDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=128, out_features=1, bias=True)\n","    (4): Sigmoid()\n","  )\n",")}\n","Initialized components: {'generator': ContrastiveGANGenerator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=100, out_features=512, bias=True)\n","        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): Linear(in_features=256, out_features=50, bias=True)\n","  )\n","), 'discriminator': ContrastiveGANDiscriminator(\n","  (model): Sequential(\n","    (0): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=50, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (1): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=512, out_features=256, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (2): LinearBlock(\n","      (block): Sequential(\n","        (0): Linear(in_features=256, out_features=128, bias=True)\n","        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","      )\n","    )\n","    (3): Linear(in_features=128, out_features=1, bias=True)\n","    (4): Sigmoid()\n","  )\n",")}\n","🚀 Training Contrastive-GAN...\n","Epoch [1/1], D Loss: 0.0001, G Loss: -153.7373\n","✅ Contrastive-GAN training completed!\n","{\n","    \"FID (Original vs Generated)\": 3248.5601787509086,\n","    \"FID (Original vs Eval)\": 4.751906014401044,\n","    \"KL Divergence\": 0.8972525601994814,\n","    \"Cosine Similarity\": 0.018708517774939537,\n","    \"Spearman Rank Correlation\": 0.0006115774915774917,\n","    \"Wasserstein Distance\": 5.451407582439637,\n","    \"Coverage Score\": 0.0,\n","    \"Memorization Score\": 0.0,\n","    \"Unique Embedding Ratio\": 1.0,\n","    \"Aggregate Quality Score\": 0.20934154593302923\n","}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5lALnrRMoRIK"},"execution_count":null,"outputs":[]}]}